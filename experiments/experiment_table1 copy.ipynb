{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import go here\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))  # Add parent directory to path\n",
    "\n",
    "from environment.knapsackgym import KnapsackEnv, _1_positive_reward, _1_negative_reward, v_i_positive_reward, vr_i_positive_reward, w_i_negative_reward, wr_i_negative_reward\n",
    "from typing import List, Callable, Optional, Union, Tuple, Dict, Any\n",
    "from models.DP_Knapsack import solve_knapsack_dp, solve_KP_instances_with_DP\n",
    "from models.Greedy_Knapsack import solve_problem_instances_greedy\n",
    "from models.KnapsackPPO import KnapsackPPOSolver\n",
    "from models.KnapsackA2C import KnapsackA2C\n",
    "from models.KnapsackQLearning import KnapsackDQN\n",
    "from util.instance_gen import KnapsackInstanceGenerator\n",
    "from util.metrics import evaluate_knapsack_performance\n",
    "from models.KnapsackDRLSolver import KnapsackDRLSolver, run_KPSolver\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Any, Tuple, Callable\n",
    "import time\n",
    "import itertools\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Code\n",
    "\n",
    "This is here that runs our experiment for testing rewards functions and generating plots and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_reward_functions_single_run(\n",
    "    KPSolver_A2C: KnapsackA2C,\n",
    "    KPSolver_DQN: KnapsackDQN,\n",
    "    KPSolver_PPO: KnapsackPPOSolver,\n",
    "    M: int = 10,\n",
    "    instance_type: str = \"RI\",\n",
    "    N: int = 50,\n",
    "    r_range: int = 500,\n",
    "    seed: int = 42,\n",
    "    t_max: int = None,\n",
    "    use_state_aggregation: bool = False,\n",
    "    n_test_instances: int = 5,\n",
    "    verbose: bool = True\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Test different reward function combinations across multiple RL models for the Knapsack problem.\n",
    "    \n",
    "    Args:\n",
    "        M (int): Number of problem instances to generate for training\n",
    "        instance_type (str): Type of knapsack instances to generate ('RI', 'FI', 'HI', 'SS')\n",
    "        N (int): Maximum number of items per problem instance\n",
    "        r_range (int): Range parameter for instance generation\n",
    "        seed (int): Random seed for reproducibility\n",
    "        t_max (int): Maximum training steps (if None, will use default 3*N*10000)\n",
    "        use_state_aggregation (bool): Whether to use state aggregation\n",
    "        n_test_instances (int): Number of test instances to evaluate on\n",
    "        verbose (bool): Whether to print detailed progress information\n",
    "        \n",
    "    Returns:\n",
    "        Dict: Results and metrics for all experiments\n",
    "    \"\"\"\n",
    "    # Set random seeds for reproducibility\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Define the reward function combinations to test\n",
    "    positive_reward_functions = {\n",
    "        'v_i': v_i_positive_reward,\n",
    "        'vr_i': vr_i_positive_reward,\n",
    "        '_1': _1_positive_reward\n",
    "    }\n",
    "    \n",
    "    negative_reward_functions = {\n",
    "        'w_i': w_i_negative_reward,\n",
    "        'wr_i': wr_i_negative_reward,\n",
    "        '_1': _1_negative_reward\n",
    "    }\n",
    "    \n",
    "    # Generate problem instances\n",
    "    gen = KnapsackInstanceGenerator(seed=seed)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Generating {M} {instance_type} training instances with N={N}, R={r_range}\")\n",
    "    \n",
    "    if instance_type == \"RI\":\n",
    "        training_instances = gen.generate_random_instances(M, N, r_range, seed=seed)\n",
    "        test_instances = gen.generate_random_instances(n_test_instances, N, r_range, seed=seed+100)\n",
    "    elif instance_type == \"FI\":\n",
    "        training_instances = gen.generate_fixed_instances(M, N, seed=seed)\n",
    "        test_instances = gen.generate_fixed_instances(n_test_instances, N, seed=seed+100)\n",
    "    elif instance_type == \"HI\":\n",
    "        training_instances = gen.generate_hard_instances(M, N, r_range, seed=seed)\n",
    "        test_instances = gen.generate_hard_instances(n_test_instances, N, r_range, seed=seed+100)\n",
    "    elif instance_type == \"SS\":\n",
    "        training_instances = gen.generate_subset_sum_instances(M, N, r_range, seed=seed)\n",
    "        test_instances = gen.generate_subset_sum_instances(n_test_instances, N, r_range, seed=seed+100)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown instance type: {instance_type}\")\n",
    "    \n",
    "    # Solve instances with DP and Greedy for baselines\n",
    "    if verbose: print(\"Computing DP optimal solutions for training instances...\")\n",
    "    dp_sols_items_train, dp_values_train, dp_weight_train = solve_KP_instances_with_DP(training_instances)\n",
    "\n",
    "    if verbose: print(\"Computing Greedy solutions for training instances...\")\n",
    "    greedy_values_train, greedy_sols_items_train, greedy_weights_train = solve_problem_instances_greedy(training_instances)\n",
    "    \n",
    "    if verbose: print(\"Computing DP optimal solutions for test instances...\")\n",
    "    dp_sols_items_test, dp_values_test, dp_weight_test = solve_KP_instances_with_DP(test_instances)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Computing Greedy solutions for test instances...\")\n",
    "    greedy_values_test, greedy_sols_items_test, greedy_weights_test = solve_problem_instances_greedy(test_instances)\n",
    "    \n",
    "    # Define models to test\n",
    "    model_constructors = {}\n",
    "    if KPSolver_A2C is not None: model_constructors[\"A2C\"] = KPSolver_A2C\n",
    "    if KPSolver_DQN is not None: model_constructors[\"DQN\"] = KPSolver_DQN\n",
    "    if KPSolver_PPO is not None: model_constructors[\"PPO\"] = KPSolver_PPO\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    results = {\n",
    "        'training': {},\n",
    "        'test': {},\n",
    "        'metrics': {},\n",
    "        'config': {\n",
    "            'num_instances': M,\n",
    "            'instance_type': instance_type,\n",
    "            'n_items': N,\n",
    "            'r_range': r_range,\n",
    "            'seed': seed,\n",
    "            't_max': t_max,\n",
    "            'use_state_aggregation': use_state_aggregation\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create all combinations of reward functions and models\n",
    "    reward_combinations = list(itertools.product(\n",
    "        positive_reward_functions.items(),\n",
    "        negative_reward_functions.items()\n",
    "    ))\n",
    "    \n",
    "    # Total count of experiments\n",
    "    total_experiments = len(reward_combinations) * len(model_constructors)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Running {total_experiments} experiments...\")\n",
    "    \n",
    "    experiment_counter = 0\n",
    "    \n",
    "    # Run experiments for each model and reward function combination\n",
    "    for model_name, model in model_constructors.items():\n",
    "        results['training'][model_name] = {}\n",
    "        results['test'][model_name] = {}\n",
    "        results['metrics'][model_name] = {}\n",
    "        \n",
    "        for (pos_name, pos_func), (neg_name, neg_func) in reward_combinations:\n",
    "            experiment_counter += 1\n",
    "            reward_combo_name = f\"(+{pos_name} -{neg_name})\"\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"\\nExperiment {experiment_counter}/{total_experiments}: Testing {model_name} with {reward_combo_name}\")\n",
    "                print(f\"Positive reward: {pos_name}, Negative reward: {neg_name}\")\n",
    "            \n",
    "            # Create environment with specific reward functions\n",
    "            env = KnapsackEnv(\n",
    "                problem_instance=None,\n",
    "                N=N,\n",
    "                positive_reward_function=pos_func,\n",
    "                negative_reward_function=neg_func\n",
    "            )\n",
    "            \n",
    "            # Initialize the model\n",
    "            kp_solver = model\n",
    "            \n",
    "            # Train the model\n",
    "            start_time = time.time()\n",
    "            \n",
    "            solver, solution_values = run_KPSolver(\n",
    "                env=env,\n",
    "                KPSolver=kp_solver,\n",
    "                training_problem_instances=training_instances,\n",
    "                t_max=t_max,\n",
    "                use_state_aggregation=use_state_aggregation,\n",
    "                verbose=verbose\n",
    "            )\n",
    "            \n",
    "            training_time = time.time() - start_time\n",
    "            \n",
    "            # Store training results\n",
    "            results['training'][model_name][reward_combo_name] = {\n",
    "                'solution_values': solution_values,\n",
    "                'training_time': training_time\n",
    "            }\n",
    "            \n",
    "            # Evaluate on test instances\n",
    "            test_values = []\n",
    "            for instance in test_instances:\n",
    "                env.change_problem_instance(instance)\n",
    "                # value, weight, _ = kp_solver.solve(instance)\n",
    "                value, weight, _ = solver.solve(instance)\n",
    "                test_values.append(value)\n",
    "            \n",
    "            # Calculate performance metrics\n",
    "            \n",
    "            # For training instances\n",
    "            train_best_values = solution_values['instance_best_values']\n",
    "            train_metrics = evaluate_knapsack_performance(\n",
    "                train_best_values, \n",
    "                dp_values_train, \n",
    "                greedy_values_train\n",
    "            )\n",
    "            \n",
    "            # For test instances\n",
    "            test_metrics = evaluate_knapsack_performance(\n",
    "                test_values,\n",
    "                dp_values_test,\n",
    "                greedy_values_test\n",
    "            )\n",
    "            \n",
    "            # Store test results and metrics\n",
    "            results['test'][model_name][reward_combo_name] = {\n",
    "                'values': test_values,\n",
    "                'metrics': test_metrics\n",
    "            }\n",
    "            \n",
    "            results['metrics'][model_name][reward_combo_name] = {\n",
    "                'train': train_metrics,\n",
    "                'test': test_metrics\n",
    "            }\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Training metrics for {model_name} with {reward_combo_name}:\")\n",
    "                print(f\"  Val/Opt Ratio: {train_metrics['ValOptRatio']:.2f}%\")\n",
    "                print(f\"  #opt: {train_metrics['#opt']}/{M}\")\n",
    "                print(f\"  Mean percentage error: {train_metrics['mean_percentage_error']:.4f}\")\n",
    "                print(f\"  Mean improvement over greedy: {train_metrics['mean_improvement_over_greedy']:.4f}\")\n",
    "                \n",
    "                print(f\"Test metrics for {model_name} with {reward_combo_name}:\")\n",
    "                print(f\"  Val/Opt Ratio: {test_metrics['ValOptRatio']:.2f}%\")\n",
    "                print(f\"  #opt: {test_metrics['#opt']}/{n_test_instances}\")\n",
    "                print(f\"  Mean percentage error: {test_metrics['mean_percentage_error']:.4f}\")\n",
    "                print(f\"  Mean improvement over greedy: {test_metrics['mean_improvement_over_greedy']:.4f}\")\n",
    "    \n",
    "    # Generate summary table\n",
    "    summary = create_summary_table(results)\n",
    "    results['summary'] = summary\n",
    "    \n",
    "    # Generate visualizations\n",
    "    visualize_results(results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def create_summary_table(results: Dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a summary table of all experiments.\n",
    "    \n",
    "    Args:\n",
    "        results: Results dictionary from test_reward_functions\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Summary table\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for model_name in results['metrics']:\n",
    "        for reward_combo_name, metrics in results['metrics'][model_name].items():\n",
    "            train_metrics = metrics['train']\n",
    "            test_metrics = metrics['test']\n",
    "            \n",
    "            row = {\n",
    "                'Model': model_name,\n",
    "                'Reward': reward_combo_name,\n",
    "                'Train_ValOptRatio': train_metrics['ValOptRatio'],\n",
    "                'Train_#opt': train_metrics['#opt'],\n",
    "                'Train_MAE': train_metrics['mean_absolute_error'],\n",
    "                'Train_MPE': train_metrics['mean_percentage_error'],\n",
    "                'Train_vs_Greedy': train_metrics['mean_improvement_over_greedy'],\n",
    "                'Test_ValOptRatio': test_metrics['ValOptRatio'],\n",
    "                'Test_#opt': test_metrics['#opt'],\n",
    "                'Test_MAE': test_metrics['mean_absolute_error'],\n",
    "                'Test_MPE': test_metrics['mean_percentage_error'],\n",
    "                'Test_vs_Greedy': test_metrics['mean_improvement_over_greedy']\n",
    "            }\n",
    "            \n",
    "            rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "def visualize_results(results: Dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    Generate visualizations for the experiment results.\n",
    "    \n",
    "    Args:\n",
    "        results: Results dictionary from test_reward_functions\n",
    "    \"\"\"\n",
    "    # Compare Val/Opt Ratio across models and reward functions\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    summary_df = results['summary']\n",
    "    \n",
    "    # Create data for grouped bar chart\n",
    "    models = summary_df['Model'].unique()\n",
    "    rewards = summary_df['Reward'].unique()\n",
    "    \n",
    "    width = 0.8 / len(rewards)\n",
    "    x = np.arange(len(models))\n",
    "    \n",
    "    # Training ValOptRatio chart\n",
    "    for i, reward in enumerate(rewards):\n",
    "        values = [summary_df[(summary_df['Model'] == model) & (summary_df['Reward'] == reward)]['Train_ValOptRatio'].values[0] \n",
    "                 for model in models]\n",
    "        ax1.bar(x + i*width - 0.4 + width/2, values, width, label=reward)\n",
    "    \n",
    "    ax1.set_ylabel('Val/Opt Ratio (%)')\n",
    "    ax1.set_title('Training Val/Opt Ratio by Model and Reward')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(models)\n",
    "    ax1.legend(title='Reward')\n",
    "    ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Test ValOptRatio chart\n",
    "    for i, reward in enumerate(rewards):\n",
    "        values = [summary_df[(summary_df['Model'] == model) & (summary_df['Reward'] == reward)]['Test_ValOptRatio'].values[0] \n",
    "                 for model in models]\n",
    "        ax2.bar(x + i*width - 0.4 + width/2, values, width, label=reward)\n",
    "    \n",
    "    ax2.set_ylabel('Val/Opt Ratio (%)')\n",
    "    ax2.set_title('Test Val/Opt Ratio by Model and Reward')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(models)\n",
    "    ax2.legend(title='Reward')\n",
    "    ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('val_opt_ratio_comparison.png')\n",
    "    \n",
    "    # Create heatmap for reward function performance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Reshape data for heatmap\n",
    "    pos_rewards = list(set([r.split('_')[0] for r in rewards]))\n",
    "    neg_rewards = list(set([r.split('_')[1] for r in rewards]))\n",
    "    \n",
    "    heatmap_data = np.zeros((len(models), len(pos_rewards), len(neg_rewards)))\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        for j, pos in enumerate(pos_rewards):\n",
    "            for k, neg in enumerate(neg_rewards):\n",
    "                reward = f\"{pos}_{neg}\"\n",
    "                try:\n",
    "                    val = summary_df[(summary_df['Model'] == model) & (summary_df['Reward'] == reward)]['Test_ValOptRatio'].values[0]\n",
    "                    heatmap_data[i, j, k] = val\n",
    "                except:\n",
    "                    heatmap_data[i, j, k] = 0\n",
    "    \n",
    "    # Create subplots for each model\n",
    "    fig, axes = plt.subplots(1, len(models), figsize=(16, 6))\n",
    "    if len(models) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        im = axes[i].imshow(heatmap_data[i], cmap='viridis')\n",
    "        axes[i].set_title(f'{model}')\n",
    "        axes[i].set_xticks(np.arange(len(neg_rewards)))\n",
    "        axes[i].set_yticks(np.arange(len(pos_rewards)))\n",
    "        axes[i].set_xticklabels(neg_rewards)\n",
    "        axes[i].set_yticklabels(pos_rewards)\n",
    "        axes[i].set_xlabel('Negative Reward')\n",
    "        if i == 0:\n",
    "            axes[i].set_ylabel('Positive Reward')\n",
    "            \n",
    "        # Loop over data dimensions and create text annotations\n",
    "        for j in range(len(pos_rewards)):\n",
    "            for k in range(len(neg_rewards)):\n",
    "                text = axes[i].text(k, j, f\"{heatmap_data[i, j, k]:.1f}\",\n",
    "                            ha=\"center\", va=\"center\", color=\"w\" if heatmap_data[i, j, k] < 70 else \"black\")\n",
    "    \n",
    "    fig.colorbar(im, ax=axes, shrink=0.8, label='Val/Opt Ratio (%)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('reward_function_heatmap.png')\n",
    "    \n",
    "    # Plot convergence over time\n",
    "    for model_name in results['training']:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        for reward_combo_name in results['training'][model_name]:\n",
    "            solution_values = results['training'][model_name][reward_combo_name]['solution_values']\n",
    "            best_sum_over_time = solution_values['best_sum_over_time']\n",
    "            t_values = np.arange(len(best_sum_over_time))\n",
    "            \n",
    "            plt.plot(t_values, best_sum_over_time, label=reward_combo_name)\n",
    "        \n",
    "        plt.xlabel('Training Iterations')\n",
    "        plt.ylabel('Sum of Best Values')\n",
    "        plt.title(f'Convergence for {model_name}')\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'convergence_{model_name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_reward_functions(\n",
    "    KPSolver_A2C: KnapsackA2C,\n",
    "    KPSolver_DQN: KnapsackDQN,\n",
    "    KPSolver_PPO: KnapsackPPOSolver,\n",
    "    M: int = 10,\n",
    "    instance_type: str = \"RI\",\n",
    "    N: int = 50,\n",
    "    r_range: int = 500,\n",
    "    seed: int = 42,\n",
    "    t_max: int = None,\n",
    "    use_state_aggregation: bool = False,\n",
    "    n_test_instances: int = 5,\n",
    "    verbose: bool = True,\n",
    "    n_runs: int = 10  # Number of runs to average results over\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Test different reward function combinations across multiple RL models for the Knapsack problem.\n",
    "    Runs each experiment n_runs times and averages the results.\n",
    "    \n",
    "    Args:\n",
    "        M (int): Number of problem instances to generate for training\n",
    "        instance_type (str): Type of knapsack instances to generate ('RI', 'FI', 'HI', 'SS')\n",
    "        N (int): Maximum number of items per problem instance\n",
    "        r_range (int): Range parameter for instance generation\n",
    "        seed (int): Base random seed for reproducibility\n",
    "        t_max (int): Maximum training steps (if None, will use default 3*N*10000)\n",
    "        use_state_aggregation (bool): Whether to use state aggregation\n",
    "        n_test_instances (int): Number of test instances to evaluate on\n",
    "        verbose (bool): Whether to print detailed progress information\n",
    "        n_runs (int): Number of runs to average results over\n",
    "        \n",
    "    Returns:\n",
    "        Dict: Results and metrics for all experiments, including averaged metrics\n",
    "    \"\"\"\n",
    "    # Define the reward function combinations to test\n",
    "    positive_reward_functions = {\n",
    "        'v_i': v_i_positive_reward,\n",
    "        'vr_i': vr_i_positive_reward,\n",
    "        '_1': _1_positive_reward\n",
    "    }\n",
    "    \n",
    "    negative_reward_functions = {\n",
    "        'w_i': w_i_negative_reward,\n",
    "        'wr_i': wr_i_negative_reward,\n",
    "        '_1': _1_negative_reward\n",
    "    }\n",
    "    \n",
    "    # Create all combinations of reward functions and models\n",
    "    # reward_combinations = list(itertools.product(\n",
    "    #     positive_reward_functions.items(),\n",
    "    #     negative_reward_functions.items()\n",
    "    # ))\n",
    "    reward_combinations = [\n",
    "        (('vr_i', positive_reward_functions['vr_i']), ('wr_i', negative_reward_functions['wr_i'])),\n",
    "        (('vr_i', positive_reward_functions['vr_i']), ('w_i', negative_reward_functions['w_i'])),\n",
    "        (('v_i', positive_reward_functions['v_i']), ('wr_i', negative_reward_functions['wr_i'])),\n",
    "        (('v_i', positive_reward_functions['v_i']), ('w_i', negative_reward_functions['w_i'])),\n",
    "        (('_1', positive_reward_functions['_1']), ('_1', negative_reward_functions['_1']))\n",
    "    ]\n",
    "\n",
    "    \n",
    "    # Define models to test\n",
    "    model_constructors = {}\n",
    "    if KPSolver_A2C is not None: model_constructors[\"A2C\"] = KPSolver_A2C\n",
    "    if KPSolver_DQN is not None: model_constructors[\"DQN\"] = KPSolver_DQN\n",
    "    if KPSolver_PPO is not None: model_constructors[\"PPO\"] = KPSolver_PPO\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    results = {\n",
    "        'training': {},\n",
    "        'test': {},\n",
    "        'metrics': {},\n",
    "        'config': {\n",
    "            'num_instances': M,\n",
    "            'instance_type': instance_type,\n",
    "            'n_items': N,\n",
    "            'r_range': r_range,\n",
    "            'base_seed': seed,\n",
    "            't_max': t_max,\n",
    "            'use_state_aggregation': use_state_aggregation,\n",
    "            'n_runs': n_runs\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Total count of experiments\n",
    "    total_experiments = len(reward_combinations) * len(model_constructors)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Running {total_experiments} experiments, each with {n_runs} runs...\")\n",
    "    \n",
    "    experiment_counter = 0\n",
    "    \n",
    "    # Run experiments for each model and reward function combination\n",
    "    for model_name, model in model_constructors.items():\n",
    "        results['training'][model_name] = {}\n",
    "        results['test'][model_name] = {}\n",
    "        results['metrics'][model_name] = {}\n",
    "        \n",
    "        for (pos_name, pos_func), (neg_name, neg_func) in reward_combinations:\n",
    "            experiment_counter += 1\n",
    "            reward_combo_name = f\"(+{pos_name} -{neg_name})\"\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"\\nExperiment {experiment_counter}/{total_experiments}: Testing {model_name} with {reward_combo_name}\")\n",
    "                print(f\"Positive reward: {pos_name}, Negative reward: {neg_name}\")\n",
    "                print(f\"Running {n_runs} times and averaging results...\")\n",
    "            \n",
    "            # Initialize storage for multiple runs\n",
    "            all_training_values = []\n",
    "            all_test_values = []\n",
    "            all_training_times = []\n",
    "            all_train_metrics = []\n",
    "            all_test_metrics = []\n",
    "            \n",
    "            # Run the experiment n_runs times\n",
    "            for run in range(n_runs):\n",
    "                # Set different seed for each run\n",
    "                run_seed = seed + run * 1000\n",
    "                np.random.seed(run_seed)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"\\nRun {run+1}/{n_runs} (seed={run_seed}):\")\n",
    "                \n",
    "                # Generate problem instances for this run\n",
    "                gen = KnapsackInstanceGenerator(seed=run_seed)\n",
    "                \n",
    "                if instance_type == \"RI\":\n",
    "                    training_instances = gen.generate_random_instances(M, N, r_range, seed=run_seed)\n",
    "                    test_instances = gen.generate_random_instances(n_test_instances, N, r_range, seed=run_seed+100)\n",
    "                elif instance_type == \"FI\":\n",
    "                    training_instances = gen.generate_fixed_instances(M, N, seed=run_seed)\n",
    "                    test_instances = gen.generate_fixed_instances(n_test_instances, N, seed=run_seed+100)\n",
    "                elif instance_type == \"HI\":\n",
    "                    training_instances = gen.generate_hard_instances(M, N, r_range, seed=run_seed)\n",
    "                    test_instances = gen.generate_hard_instances(n_test_instances, N, r_range, seed=run_seed+100)\n",
    "                elif instance_type == \"SS\":\n",
    "                    training_instances = gen.generate_subset_sum_instances(M, N, r_range, seed=run_seed)\n",
    "                    test_instances = gen.generate_subset_sum_instances(n_test_instances, N, r_range, seed=run_seed+100)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown instance type: {instance_type}\")\n",
    "                \n",
    "                # Solve instances with DP and Greedy for baselines\n",
    "                if verbose: print(\"Computing DP optimal solutions for training instances...\")\n",
    "                dp_sols_items_train, dp_values_train, dp_weight_train = solve_KP_instances_with_DP(training_instances)\n",
    "\n",
    "                if verbose: print(\"Computing Greedy solutions for training instances...\")\n",
    "                greedy_values_train, greedy_sols_items_train, greedy_weights_train = solve_problem_instances_greedy(training_instances)\n",
    "                \n",
    "                if verbose: print(\"Computing DP optimal solutions for test instances...\")\n",
    "                dp_sols_items_test, dp_values_test, dp_weight_test = solve_KP_instances_with_DP(test_instances)\n",
    "                \n",
    "                if verbose: print(\"Computing Greedy solutions for test instances...\")\n",
    "                greedy_values_test, greedy_sols_items_test, greedy_weights_test = solve_problem_instances_greedy(test_instances)\n",
    "                \n",
    "                # Create environment with specific reward functions\n",
    "                env = KnapsackEnv(\n",
    "                    problem_instance=None,\n",
    "                    N=N,\n",
    "                    positive_reward_function=pos_func,\n",
    "                    negative_reward_function=neg_func\n",
    "                )\n",
    "                \n",
    "                # Initialize the model\n",
    "                kp_solver = model\n",
    "                \n",
    "                # Train the model\n",
    "                start_time = time.time()\n",
    "                \n",
    "                solver, solution_values = run_KPSolver(\n",
    "                    env=env,\n",
    "                    KPSolver=kp_solver,\n",
    "                    training_problem_instances=training_instances,\n",
    "                    t_max=t_max,\n",
    "                    use_state_aggregation=use_state_aggregation,\n",
    "                    verbose=verbose\n",
    "                )\n",
    "                \n",
    "                training_time = time.time() - start_time\n",
    "                all_training_times.append(training_time)\n",
    "                \n",
    "                # Store training results for this run\n",
    "                all_training_values.append(solution_values)\n",
    "                \n",
    "                # Evaluate on test instances\n",
    "                test_values = []\n",
    "                for instance in test_instances:\n",
    "                    env.change_problem_instance(instance)\n",
    "                    value, weight, _ = solver.solve(instance)\n",
    "                    test_values.append(value)\n",
    "                \n",
    "                all_test_values.append(test_values)\n",
    "                \n",
    "                # Calculate performance metrics for this run\n",
    "                # For training instances\n",
    "                train_best_values = solution_values['instance_best_values']\n",
    "                train_metrics = evaluate_knapsack_performance(\n",
    "                    train_best_values, \n",
    "                    dp_values_train, \n",
    "                    greedy_values_train\n",
    "                )\n",
    "                all_train_metrics.append(train_metrics)\n",
    "                \n",
    "                # For test instances\n",
    "                test_metrics = evaluate_knapsack_performance(\n",
    "                    test_values,\n",
    "                    dp_values_test,\n",
    "                    greedy_values_test\n",
    "                )\n",
    "                all_test_metrics.append(test_metrics)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"Run {run+1} training metrics for {model_name} with {reward_combo_name}:\")\n",
    "                    print(f\"  Val/Opt Ratio: {train_metrics['ValOptRatio']:.2f}%\")\n",
    "                    print(f\"  #opt: {train_metrics['#opt']}/{M}\")\n",
    "                    print(f\"  Mean percentage error: {train_metrics['mean_percentage_error']:.4f}\")\n",
    "                    print(f\"  Mean improvement over greedy: {train_metrics['mean_improvement_over_greedy']:.4f}\")\n",
    "                    \n",
    "                    print(f\"Run {run+1} test metrics for {model_name} with {reward_combo_name}:\")\n",
    "                    print(f\"  Val/Opt Ratio: {test_metrics['ValOptRatio']:.2f}%\")\n",
    "                    print(f\"  #opt: {test_metrics['#opt']}/{n_test_instances}\")\n",
    "                    print(f\"  Mean percentage error: {test_metrics['mean_percentage_error']:.4f}\")\n",
    "                    print(f\"  Mean improvement over greedy: {test_metrics['mean_improvement_over_greedy']:.4f}\")\n",
    "            \n",
    "            # Calculate averages across all runs\n",
    "            avg_training_time = np.mean(all_training_times)\n",
    "            \n",
    "            # Average training metrics\n",
    "            avg_train_metrics = {\n",
    "                'ValOptRatio': np.mean([m['ValOptRatio'] for m in all_train_metrics]),\n",
    "                '#opt': np.mean([m['#opt'] for m in all_train_metrics]),\n",
    "                'mean_percentage_error': np.mean([m['mean_percentage_error'] for m in all_train_metrics]),\n",
    "                'mean_improvement_over_greedy': np.mean([m['mean_improvement_over_greedy'] for m in all_train_metrics])\n",
    "            }\n",
    "            \n",
    "            # Calculate std dev of metrics for error bars\n",
    "            std_train_metrics = {\n",
    "                'ValOptRatio': np.std([m['ValOptRatio'] for m in all_train_metrics]),\n",
    "                '#opt': np.std([m['#opt'] for m in all_train_metrics]),\n",
    "                'mean_percentage_error': np.std([m['mean_percentage_error'] for m in all_train_metrics]),\n",
    "                'mean_improvement_over_greedy': np.std([m['mean_improvement_over_greedy'] for m in all_train_metrics])\n",
    "            }\n",
    "            \n",
    "            # Average test metrics\n",
    "            avg_test_metrics = {\n",
    "                'ValOptRatio': np.mean([m['ValOptRatio'] for m in all_test_metrics]),\n",
    "                '#opt': np.mean([m['#opt'] for m in all_test_metrics]),\n",
    "                'mean_percentage_error': np.mean([m['mean_percentage_error'] for m in all_test_metrics]),\n",
    "                'mean_improvement_over_greedy': np.mean([m['mean_improvement_over_greedy'] for m in all_test_metrics])\n",
    "            }\n",
    "            \n",
    "            # Calculate std dev of test metrics for error bars\n",
    "            std_test_metrics = {\n",
    "                'ValOptRatio': np.std([m['ValOptRatio'] for m in all_test_metrics]),\n",
    "                '#opt': np.std([m['#opt'] for m in all_test_metrics]),\n",
    "                'mean_percentage_error': np.std([m['mean_percentage_error'] for m in all_test_metrics]),\n",
    "                'mean_improvement_over_greedy': np.std([m['mean_improvement_over_greedy'] for m in all_test_metrics])\n",
    "            }\n",
    "            \n",
    "            # Store averaged results\n",
    "            results['training'][model_name][reward_combo_name] = {\n",
    "                'solution_values': all_training_values,  # Store all runs\n",
    "                'avg_training_time': avg_training_time,\n",
    "                'avg_metrics': avg_train_metrics,\n",
    "                'std_metrics': std_train_metrics\n",
    "            }\n",
    "            \n",
    "            results['test'][model_name][reward_combo_name] = {\n",
    "                'values': all_test_values,  # Store all runs\n",
    "                'avg_metrics': avg_test_metrics,\n",
    "                'std_metrics': std_test_metrics\n",
    "            }\n",
    "            \n",
    "            results['metrics'][model_name][reward_combo_name] = {\n",
    "                'train': {\n",
    "                    'avg': avg_train_metrics,\n",
    "                    'std': std_train_metrics,\n",
    "                    'all_runs': all_train_metrics\n",
    "                },\n",
    "                'test': {\n",
    "                    'avg': avg_test_metrics,\n",
    "                    'std': std_test_metrics,\n",
    "                    'all_runs': all_test_metrics\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"\\nAVERAGED RESULTS ({n_runs} runs) for {model_name} with {reward_combo_name}:\")\n",
    "                print(f\"Training metrics:\")\n",
    "                print(f\"  Val/Opt Ratio: {avg_train_metrics['ValOptRatio']:.2f}% ± {std_train_metrics['ValOptRatio']:.2f}%\")\n",
    "                print(f\"  #opt: {avg_train_metrics['#opt']:.2f} ± {std_train_metrics['#opt']:.2f}\")\n",
    "                print(f\"  Mean percentage error: {avg_train_metrics['mean_percentage_error']:.4f} ± {std_train_metrics['mean_percentage_error']:.4f}\")\n",
    "                print(f\"  Mean improvement over greedy: {avg_train_metrics['mean_improvement_over_greedy']:.4f} ± {std_train_metrics['mean_improvement_over_greedy']:.4f}\")\n",
    "                \n",
    "                print(f\"Test metrics:\")\n",
    "                print(f\"  Val/Opt Ratio: {avg_test_metrics['ValOptRatio']:.2f}% ± {std_test_metrics['ValOptRatio']:.2f}%\")\n",
    "                print(f\"  #opt: {avg_test_metrics['#opt']:.2f} ± {std_test_metrics['#opt']:.2f}\")\n",
    "                print(f\"  Mean percentage error: {avg_test_metrics['mean_percentage_error']:.4f} ± {std_test_metrics['mean_percentage_error']:.4f}\")\n",
    "                print(f\"  Mean improvement over greedy: {avg_test_metrics['mean_improvement_over_greedy']:.4f} ± {std_test_metrics['mean_improvement_over_greedy']:.4f}\")\n",
    "    \n",
    "    # Generate summary table with averaged results\n",
    "    summary = create_summary_table_with_std(results, n_runs)\n",
    "    results['summary'] = summary\n",
    "    \n",
    "    # Generate visualizations with error bars\n",
    "    visualize_results_with_error_bars(results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def create_summary_table_with_std(results, n_runs):\n",
    "    \"\"\"\n",
    "    Create a summary table of the experiment results across all models and reward functions,\n",
    "    including standard deviations.\n",
    "    \n",
    "    Args:\n",
    "        results: Dictionary containing experiment results\n",
    "        n_runs: Number of runs performed for each experiment\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Summary table with metrics and standard deviations\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for model_name in results['metrics']:\n",
    "        for reward_combo in results['metrics'][model_name]:\n",
    "            # Training metrics\n",
    "            train_metrics = results['metrics'][model_name][reward_combo]['train']['avg']\n",
    "            train_std = results['metrics'][model_name][reward_combo]['train']['std']\n",
    "            \n",
    "            # Test metrics\n",
    "            test_metrics = results['metrics'][model_name][reward_combo]['test']['avg']\n",
    "            test_std = results['metrics'][model_name][reward_combo]['test']['std']\n",
    "            \n",
    "            # Average training time\n",
    "            avg_training_time = results['training'][model_name][reward_combo]['avg_training_time']\n",
    "            \n",
    "            row = {\n",
    "                'Model': model_name,\n",
    "                'Reward Function': reward_combo,\n",
    "                'Train Val/Opt (%)': f\"{train_metrics['ValOptRatio']:.2f} ± {train_std['ValOptRatio']:.2f}\",\n",
    "                'Train #opt': f\"{train_metrics['#opt']:.2f} ± {train_std['#opt']:.2f}\",\n",
    "                'Train MPE': f\"{train_metrics['mean_percentage_error']:.4f} ± {train_std['mean_percentage_error']:.4f}\",\n",
    "                'Train Imp/Greedy': f\"{train_metrics['mean_improvement_over_greedy']:.4f} ± {train_std['mean_improvement_over_greedy']:.4f}\",\n",
    "                'Test Val/Opt (%)': f\"{test_metrics['ValOptRatio']:.2f} ± {test_std['ValOptRatio']:.2f}\",\n",
    "                'Test #opt': f\"{test_metrics['#opt']:.2f} ± {test_std['#opt']:.2f}\",\n",
    "                'Test MPE': f\"{test_metrics['mean_percentage_error']:.4f} ± {test_std['mean_percentage_error']:.4f}\",\n",
    "                'Test Imp/Greedy': f\"{test_metrics['mean_improvement_over_greedy']:.4f} ± {test_std['mean_improvement_over_greedy']:.4f}\",\n",
    "                'Training Time (s)': f\"{avg_training_time:.2f}\"\n",
    "            }\n",
    "            rows.append(row)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    summary_df = pd.DataFrame(rows)\n",
    "    \n",
    "    # Add note about number of runs\n",
    "    summary_df.attrs['note'] = f\"Results averaged over {n_runs} runs. ± values indicate standard deviation.\"\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "\n",
    "def visualize_results_with_error_bars(results, save_fig:bool=False):\n",
    "    \"\"\"\n",
    "    Generate visualizations of the experiment results with error bars.\n",
    "    \n",
    "    Args:\n",
    "        results: Dictionary containing experiment results\n",
    "    \"\"\"\n",
    "    # Create matplotlib figure\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    models = list(results['metrics'].keys())\n",
    "    reward_combos = []\n",
    "    for model in models:\n",
    "        reward_combos.extend(list(results['metrics'][model].keys()))\n",
    "    reward_combos = list(set(reward_combos))  # Remove duplicates\n",
    "    \n",
    "    # Prepare data for Val/Opt Ratio (test set)\n",
    "    x = np.arange(len(reward_combos))\n",
    "    width = 0.8 / len(models)  # Width of bars\n",
    "    \n",
    "    # Plot Val/Opt Ratio for test set with error bars\n",
    "    plt.subplot(2, 2, 1)\n",
    "    for i, model in enumerate(models):\n",
    "        values = []\n",
    "        errors = []\n",
    "        for reward in reward_combos:\n",
    "            if reward in results['metrics'][model]:\n",
    "                values.append(results['metrics'][model][reward]['test']['avg']['ValOptRatio'])\n",
    "                errors.append(results['metrics'][model][reward]['test']['std']['ValOptRatio'])\n",
    "            else:\n",
    "                values.append(0)\n",
    "                errors.append(0)\n",
    "        \n",
    "        plt.bar(x + i*width - width*(len(models)-1)/2, values, width, label=model, yerr=errors, capsize=3)\n",
    "    \n",
    "    plt.ylabel('Val/Opt Ratio (%)')\n",
    "    plt.title('Test Set Val/Opt Ratio by Model and Reward Function')\n",
    "    plt.xticks(x, reward_combos, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Plot #opt for test set with error bars\n",
    "    plt.subplot(2, 2, 2)\n",
    "    for i, model in enumerate(models):\n",
    "        values = []\n",
    "        errors = []\n",
    "        for reward in reward_combos:\n",
    "            if reward in results['metrics'][model]:\n",
    "                values.append(results['metrics'][model][reward]['test']['avg']['#opt'])\n",
    "                errors.append(results['metrics'][model][reward]['test']['std']['#opt'])\n",
    "            else:\n",
    "                values.append(0)\n",
    "                errors.append(0)\n",
    "        \n",
    "        plt.bar(x + i*width - width*(len(models)-1)/2, values, width, label=model, yerr=errors, capsize=3)\n",
    "    \n",
    "    plt.ylabel('Number of Optimal Solutions')\n",
    "    plt.title('Test Set #opt by Model and Reward Function')\n",
    "    plt.xticks(x, reward_combos, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Plot Mean Percentage Error for test set with error bars\n",
    "    plt.subplot(2, 2, 3)\n",
    "    for i, model in enumerate(models):\n",
    "        values = []\n",
    "        errors = []\n",
    "        for reward in reward_combos:\n",
    "            if reward in results['metrics'][model]:\n",
    "                values.append(results['metrics'][model][reward]['test']['avg']['mean_percentage_error'])\n",
    "                errors.append(results['metrics'][model][reward]['test']['std']['mean_percentage_error'])\n",
    "            else:\n",
    "                values.append(0)\n",
    "                errors.append(0)\n",
    "        \n",
    "        plt.bar(x + i*width - width*(len(models)-1)/2, values, width, label=model, yerr=errors, capsize=3)\n",
    "    \n",
    "    plt.ylabel('Mean Percentage Error')\n",
    "    plt.title('Test Set Mean Percentage Error by Model and Reward Function')\n",
    "    plt.xticks(x, reward_combos, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Plot Mean Improvement over Greedy for test set with error bars\n",
    "    plt.subplot(2, 2, 4)\n",
    "    for i, model in enumerate(models):\n",
    "        values = []\n",
    "        errors = []\n",
    "        for reward in reward_combos:\n",
    "            if reward in results['metrics'][model]:\n",
    "                values.append(results['metrics'][model][reward]['test']['avg']['mean_improvement_over_greedy'])\n",
    "                errors.append(results['metrics'][model][reward]['test']['std']['mean_improvement_over_greedy'])\n",
    "            else:\n",
    "                values.append(0)\n",
    "                errors.append(0)\n",
    "        \n",
    "        plt.bar(x + i*width - width*(len(models)-1)/2, values, width, label=model, yerr=errors, capsize=3)\n",
    "    \n",
    "    plt.ylabel('Mean Improvement over Greedy')\n",
    "    plt.title('Test Set Mean Improvement over Greedy by Model and Reward Function')\n",
    "    plt.xticks(x, reward_combos, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_fig: plt.savefig('experiment_results_with_error_bars.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Create additional visualizations for training performance\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Plot Val/Opt Ratio for training set with error bars\n",
    "    plt.subplot(2, 2, 1)\n",
    "    for i, model in enumerate(models):\n",
    "        values = []\n",
    "        errors = []\n",
    "        for reward in reward_combos:\n",
    "            if reward in results['metrics'][model]:\n",
    "                values.append(results['metrics'][model][reward]['train']['avg']['ValOptRatio'])\n",
    "                errors.append(results['metrics'][model][reward]['train']['std']['ValOptRatio'])\n",
    "            else:\n",
    "                values.append(0)\n",
    "                errors.append(0)\n",
    "        \n",
    "        plt.bar(x + i*width - width*(len(models)-1)/2, values, width, label=model, yerr=errors, capsize=3)\n",
    "    \n",
    "    plt.ylabel('Val/Opt Ratio (%)')\n",
    "    plt.title('Training Set Val/Opt Ratio by Model and Reward Function')\n",
    "    plt.xticks(x, reward_combos, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Plot Training Times\n",
    "    plt.subplot(2, 2, 2)\n",
    "    for i, model in enumerate(models):\n",
    "        values = []\n",
    "        for reward in reward_combos:\n",
    "            if reward in results['training'][model]:\n",
    "                values.append(results['training'][model][reward]['avg_training_time'])\n",
    "            else:\n",
    "                values.append(0)\n",
    "        \n",
    "        plt.bar(x + i*width - width*(len(models)-1)/2, values, width, label=model)\n",
    "    \n",
    "    plt.ylabel('Training Time (seconds)')\n",
    "    plt.title('Average Training Time by Model and Reward Function')\n",
    "    plt.xticks(x, reward_combos, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_fig: plt.savefig('training_performance_with_error_bars.png', dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting\n",
    "This jupyter notebook will be used to generate relevant plots relating to our experiments related to reward functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 15 experiments, each with 10 runs...\n",
      "\n",
      "Experiment 1/15: Testing A2C with (+vr_i -wr_i)\n",
      "Positive reward: vr_i, Negative reward: wr_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.012955943704415804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tsemerdz/School/COMP579_Assignments/models/KnapsackA2C.py:233: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:257.)\n",
      "  states_tensor = torch.FloatTensor(states)\n",
      "/Users/tsemerdz/School/COMP579_Assignments/models/KnapsackA2C.py:260: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  value_loss = F.mse_loss(state_values, returns_tensor)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.04680122243024061\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.005276762817043792\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.005276762817043792\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.04680122243024061\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.005276762817043792\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.0348938319928081\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.04680122243024061\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.0348938319928081\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.005276762817043793\n",
      "Run 1 training metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 73.15%\n",
      "  #opt: 232/1000\n",
      "  Mean percentage error: 0.2072\n",
      "  Mean improvement over greedy: -0.1905\n",
      "Run 1 test metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 55.58%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2920\n",
      "  Mean improvement over greedy: -0.2555\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.5433502022234417\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.6774687831513552\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.6774687831513552\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.677468783151355\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.6774687831513551\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.5940683084863962\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.6774687831513552\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.6774687831513553\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.6774687831513553\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.6324614352783368\n",
      "Run 2 training metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 69.87%\n",
      "  #opt: 203/1000\n",
      "  Mean percentage error: 0.2434\n",
      "  Mean improvement over greedy: -0.2268\n",
      "Run 2 test metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 59.58%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2539\n",
      "  Mean improvement over greedy: -0.2539\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.18501283497138832\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.18423872678188535\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.19841203126120963\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.19841203126120963\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.19841203126120963\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.19841203126120963\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.12462127956159647\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.2231593113676447\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.19841203126120963\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.18379630392085097\n",
      "Run 3 training metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 69.98%\n",
      "  #opt: 235/1000\n",
      "  Mean percentage error: 0.2301\n",
      "  Mean improvement over greedy: -0.2132\n",
      "Run 3 test metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 69.22%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3564\n",
      "  Mean improvement over greedy: -0.3366\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -1.3485562228742587\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -1.3485562228742591\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -1.1892230576441105\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -1.3421994009413778\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -1.3350449293966622\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -1.3350449293966626\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -1.2303974221267453\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -1.31890440386681\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -1.3004880622609152\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -1.2127572391185577\n",
      "Run 4 training metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 72.16%\n",
      "  #opt: 234/1000\n",
      "  Mean percentage error: 0.2197\n",
      "  Mean improvement over greedy: -0.2051\n",
      "Run 4 test metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 49.33%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4208\n",
      "  Mean improvement over greedy: -0.4015\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -1.717073170731707\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -1.6500599452999136\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -1.6500599452999136\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -1.7180260512282544\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -1.633232800069936\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -1.6446586240055947\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -1.6446586240055951\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -1.6552288224495153\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -1.580763178599528\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -1.6250688434303697\n",
      "Run 5 training metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 73.69%\n",
      "  #opt: 238/1000\n",
      "  Mean percentage error: 0.2022\n",
      "  Mean improvement over greedy: -0.1885\n",
      "Run 5 test metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 54.93%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4502\n",
      "  Mean improvement over greedy: -0.4125\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.4750101738080235\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.4917135036907012\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.5653898333799453\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.5612370186636333\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.5562726449275361\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.5430359299516908\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.49853907867494823\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.49853907867494823\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.49853907867494823\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.5507168825689893\n",
      "Run 6 training metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 73.65%\n",
      "  #opt: 241/1000\n",
      "  Mean percentage error: 0.2018\n",
      "  Mean improvement over greedy: -0.1858\n",
      "Run 6 test metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 53.67%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4410\n",
      "  Mean improvement over greedy: -0.4318\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.1493463299818354\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.20132940260318166\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.2882627216209993\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.1493463299818354\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.18484598459845986\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.1493463299818354\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.2882627216209993\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.1493463299818354\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.1493463299818354\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.1493463299818354\n",
      "Run 7 training metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 74.73%\n",
      "  #opt: 280/1000\n",
      "  Mean percentage error: 0.1882\n",
      "  Mean improvement over greedy: -0.1762\n",
      "Run 7 test metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 59.99%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3219\n",
      "  Mean improvement over greedy: -0.3089\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.2919037178753565\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.2919037178753565\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.29644794447712564\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.33035830241187375\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.3101421732021006\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.32184924709841656\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.30423817254174396\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.3218492470984165\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.27596852831417\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.29440805067671666\n",
      "Run 8 training metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 73.69%\n",
      "  #opt: 227/1000\n",
      "  Mean percentage error: 0.2054\n",
      "  Mean improvement over greedy: -0.1897\n",
      "Run 8 test metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 71.89%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.2851\n",
      "  Mean improvement over greedy: -0.2656\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.18603263086394578\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.153133474374103\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.153133474374103\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.15068806439192828\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.1630686326764758\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.15339304559153313\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.153133474374103\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.153133474374103\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.15678237203972498\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.2043416916182199\n",
      "Run 9 training metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 74.61%\n",
      "  #opt: 258/1000\n",
      "  Mean percentage error: 0.1900\n",
      "  Mean improvement over greedy: -0.1744\n",
      "Run 9 test metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 49.56%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4172\n",
      "  Mean improvement over greedy: -0.4064\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.4444814213564214\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.37843096457533076\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.40686049181028033\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.37815225361692356\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.40636330840876284\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.39980339105339113\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.459105164548713\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.42111074477853977\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.3360055845011379\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.380700366290098\n",
      "Run 10 training metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 74.86%\n",
      "  #opt: 232/1000\n",
      "  Mean percentage error: 0.1948\n",
      "  Mean improvement over greedy: -0.1820\n",
      "Run 10 test metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 44.61%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4869\n",
      "  Mean improvement over greedy: -0.4606\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for A2C with (+vr_i -wr_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 73.04% ± 1.73%\n",
      "  #opt: 238.00 ± 19.02\n",
      "  Mean percentage error: 0.2083 ± 0.0169\n",
      "  Mean improvement over greedy: -0.1932 ± 0.0159\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 56.84% ± 8.19%\n",
      "  #opt: 0.70 ± 0.78\n",
      "  Mean percentage error: 0.3726 ± 0.0769\n",
      "  Mean improvement over greedy: -0.3533 ± 0.0746\n",
      "\n",
      "Experiment 2/15: Testing A2C with (+vr_i -w_i)\n",
      "Positive reward: vr_i, Negative reward: w_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -17.19871635759008\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -8.79845082425049\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -8.798621472714654\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -17.19871635759008\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -17.19871635759008\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -17.19871635759008\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -13.199019652464369\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -17.19871635759008\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -8.798621472714654\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -8.79845082425049\n",
      "Run 1 training metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 75.68%\n",
      "  #opt: 268/1000\n",
      "  Mean percentage error: 0.1818\n",
      "  Mean improvement over greedy: -0.1652\n",
      "Run 1 test metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 59.17%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3362\n",
      "  Mean improvement over greedy: -0.2997\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -45.120196118160955\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -44.46876058675675\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -44.49766106096504\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -43.05156885719162\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -44.42023583999122\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -44.52717329848852\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -26.612763406298743\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -20.3166918175721\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -35.289028465084805\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -40.314195351950005\n",
      "Run 2 training metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 76.34%\n",
      "  #opt: 300/1000\n",
      "  Mean percentage error: 0.1733\n",
      "  Mean improvement over greedy: -0.1567\n",
      "Run 2 test metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 49.68%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.3177\n",
      "  Mean improvement over greedy: -0.3177\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -41.832572871710454\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -41.85723639841418\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -41.91483012319976\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -41.85992204049606\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -41.88765226792004\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -41.91473163509367\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -41.911676794963185\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -41.85567717240788\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -43.845079994225195\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -41.914343453678825\n",
      "Run 3 training metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 76.24%\n",
      "  #opt: 290/1000\n",
      "  Mean percentage error: 0.1733\n",
      "  Mean improvement over greedy: -0.1563\n",
      "Run 3 test metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 66.01%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2970\n",
      "  Mean improvement over greedy: -0.2771\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -51.136477557530185\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -48.535915219082185\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -45.33749106930222\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -50.609492481203006\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -51.57705483220246\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -51.57705483220246\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -51.57705483220246\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -54.152156432748534\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -51.52561281251911\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -33.286384063607294\n",
      "Run 4 training metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 75.87%\n",
      "  #opt: 286/1000\n",
      "  Mean percentage error: 0.1783\n",
      "  Mean improvement over greedy: -0.1637\n",
      "Run 4 test metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 55.35%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4384\n",
      "  Mean improvement over greedy: -0.4190\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -50.391358510359304\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -50.24654690095288\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -50.23189089955416\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -50.24654690095288\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -50.31561762391818\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -51.94288786482335\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -50.2426435877262\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -50.215871142582394\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -50.241236122038636\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -50.2426435877262\n",
      "Run 5 training metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 75.43%\n",
      "  #opt: 280/1000\n",
      "  Mean percentage error: 0.1790\n",
      "  Mean improvement over greedy: -0.1653\n",
      "Run 5 test metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 54.58%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4565\n",
      "  Mean improvement over greedy: -0.4188\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -44.93522775213421\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -44.3087243878061\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -44.495763751646905\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -44.997782684178745\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -44.308724387806095\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -44.370434645366714\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -44.370434645366714\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -45.06018607113697\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -15.652068623807752\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -44.6230664715719\n",
      "Run 6 training metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 76.03%\n",
      "  #opt: 277/1000\n",
      "  Mean percentage error: 0.1758\n",
      "  Mean improvement over greedy: -0.1597\n",
      "Run 6 test metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 57.11%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4365\n",
      "  Mean improvement over greedy: -0.4273\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -32.991776677667765\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -26.74865876122496\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -32.99177667766777\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -27.748359105573478\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -32.99177667766777\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -32.991776677667765\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -26.74865876122496\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -32.991776677667765\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -26.74865876122496\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -34.74093048839768\n",
      "Run 7 training metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 75.35%\n",
      "  #opt: 287/1000\n",
      "  Mean percentage error: 0.1822\n",
      "  Mean improvement over greedy: -0.1702\n",
      "Run 7 test metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 60.04%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3024\n",
      "  Mean improvement over greedy: -0.2894\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -49.52966416749627\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -50.8827731092437\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -49.61768930753496\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -49.61881027268862\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -45.36939030517797\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -49.981670067016715\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -49.39051653658239\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -49.48232005160019\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -45.38245127466018\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -49.800357619789004\n",
      "Run 8 training metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 75.28%\n",
      "  #opt: 266/1000\n",
      "  Mean percentage error: 0.1849\n",
      "  Mean improvement over greedy: -0.1693\n",
      "Run 8 test metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 56.53%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4022\n",
      "  Mean improvement over greedy: -0.3826\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -36.63279930396064\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -38.3586066132541\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -36.45177205628672\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -28.136933161734614\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -36.722023013750956\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -36.176681683115504\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -36.904147288990856\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -37.540277743197294\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -37.63165696976034\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -36.90416400022081\n",
      "Run 9 training metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 76.09%\n",
      "  #opt: 289/1000\n",
      "  Mean percentage error: 0.1730\n",
      "  Mean improvement over greedy: -0.1574\n",
      "Run 9 test metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 61.78%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3693\n",
      "  Mean improvement over greedy: -0.3585\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -44.45155160475725\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -44.32804076966212\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -44.607092648513095\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -43.391869592208906\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -44.27992463122818\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -44.68798244952984\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -44.402369383490075\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -44.607092648513095\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -44.45272873827562\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -44.363299885749676\n",
      "Run 10 training metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 75.23%\n",
      "  #opt: 266/1000\n",
      "  Mean percentage error: 0.1848\n",
      "  Mean improvement over greedy: -0.1721\n",
      "Run 10 test metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 52.31%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3721\n",
      "  Mean improvement over greedy: -0.3457\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for A2C with (+vr_i -w_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 75.75% ± 0.39%\n",
      "  #opt: 280.90 ± 10.97\n",
      "  Mean percentage error: 0.1786 ± 0.0045\n",
      "  Mean improvement over greedy: -0.1636 ± 0.0055\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 57.26% ± 4.49%\n",
      "  #opt: 0.70 ± 0.64\n",
      "  Mean percentage error: 0.3728 ± 0.0560\n",
      "  Mean improvement over greedy: -0.3536 ± 0.0539\n",
      "\n",
      "Experiment 3/15: Testing A2C with (+v_i -wr_i)\n",
      "Positive reward: v_i, Negative reward: wr_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 30.593174061433444\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 21.96382252559727\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 21.96382252559727\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 21.96382252559727\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 21.96382252559727\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 21.96382252559727\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 21.96382252559727\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 21.96382252559727\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 21.96382252559727\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 21.96382252559727\n",
      "Run 1 training metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 54.90%\n",
      "  #opt: 142/1000\n",
      "  Mean percentage error: 0.3805\n",
      "  Mean improvement over greedy: -0.3638\n",
      "Run 1 test metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 52.93%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.3124\n",
      "  Mean improvement over greedy: -0.2758\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 3.081171237954041\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 3.081171237954041\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 3.081171237954041\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 3.081171237954041\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 3.081171237954041\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 3.081171237954041\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 3.081171237954041\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 3.081171237954041\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 3.081171237954041\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 3.081171237954041\n",
      "Run 2 training metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 53.26%\n",
      "  #opt: 139/1000\n",
      "  Mean percentage error: 0.3996\n",
      "  Mean improvement over greedy: -0.3830\n",
      "Run 2 test metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 48.40%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.3112\n",
      "  Mean improvement over greedy: -0.3112\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 8.90909090909091\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 8.90909090909091\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 8.90909090909091\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 8.90909090909091\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 8.90909090909091\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 8.90909090909091\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 8.90909090909091\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 8.90909090909091\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 8.90909090909091\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 8.90909090909091\n",
      "Run 3 training metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 53.90%\n",
      "  #opt: 150/1000\n",
      "  Mean percentage error: 0.3937\n",
      "  Mean improvement over greedy: -0.3768\n",
      "Run 3 test metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 65.78%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3950\n",
      "  Mean improvement over greedy: -0.3751\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 13.421052631578947\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 13.421052631578947\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 13.421052631578947\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 13.421052631578947\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 13.421052631578947\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 13.421052631578947\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 13.421052631578947\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 13.421052631578947\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 13.421052631578947\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 13.421052631578947\n",
      "Run 4 training metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 53.22%\n",
      "  #opt: 152/1000\n",
      "  Mean percentage error: 0.3965\n",
      "  Mean improvement over greedy: -0.3819\n",
      "Run 4 test metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 49.59%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3799\n",
      "  Mean improvement over greedy: -0.3605\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 2.800944138473643\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 2.800944138473643\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 2.800944138473643\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 2.800944138473643\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 2.800944138473643\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 2.800944138473643\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 2.800944138473643\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 2.800944138473643\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 2.800944138473643\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 2.800944138473643\n",
      "Run 5 training metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 54.60%\n",
      "  #opt: 155/1000\n",
      "  Mean percentage error: 0.3817\n",
      "  Mean improvement over greedy: -0.3679\n",
      "Run 5 test metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 46.77%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5054\n",
      "  Mean improvement over greedy: -0.4677\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 10.246603260869565\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 10.246603260869565\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 10.246603260869565\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 10.246603260869565\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 10.246603260869565\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 10.246603260869565\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 10.246603260869565\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 10.246603260869565\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 10.246603260869565\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 10.246603260869565\n",
      "Run 6 training metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 53.66%\n",
      "  #opt: 154/1000\n",
      "  Mean percentage error: 0.3901\n",
      "  Mean improvement over greedy: -0.3741\n",
      "Run 6 test metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 45.98%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5218\n",
      "  Mean improvement over greedy: -0.5126\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 19.09158415841584\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 19.09158415841584\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 19.09158415841584\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 19.09158415841584\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 19.09158415841584\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 19.09158415841584\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 19.09158415841584\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 19.09158415841584\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 19.09158415841584\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 19.09158415841584\n",
      "Run 7 training metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 53.75%\n",
      "  #opt: 171/1000\n",
      "  Mean percentage error: 0.3856\n",
      "  Mean improvement over greedy: -0.3736\n",
      "Run 7 test metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 59.99%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3219\n",
      "  Mean improvement over greedy: -0.3089\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 10.646103896103895\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 10.646103896103895\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 10.646103896103895\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 10.646103896103895\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 10.646103896103895\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 10.646103896103895\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 10.646103896103895\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 10.646103896103895\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 10.646103896103895\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 10.646103896103895\n",
      "Run 8 training metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 54.77%\n",
      "  #opt: 158/1000\n",
      "  Mean percentage error: 0.3748\n",
      "  Mean improvement over greedy: -0.3592\n",
      "Run 8 test metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 72.13%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2537\n",
      "  Mean improvement over greedy: -0.2342\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 16.38770053475936\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 16.38770053475936\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 16.38770053475936\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 16.38770053475936\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 16.38770053475936\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 16.38770053475936\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 16.38770053475936\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 16.38770053475936\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 16.38770053475936\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 16.38770053475936\n",
      "Run 9 training metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 55.82%\n",
      "  #opt: 180/1000\n",
      "  Mean percentage error: 0.3560\n",
      "  Mean improvement over greedy: -0.3404\n",
      "Run 9 test metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 58.26%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4248\n",
      "  Mean improvement over greedy: -0.4140\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 10.37310606060606\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 10.37310606060606\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 10.37310606060606\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 10.37310606060606\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 10.37310606060606\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 10.37310606060606\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 10.37310606060606\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 10.37310606060606\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 10.37310606060606\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 10.37310606060606\n",
      "Run 10 training metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 53.19%\n",
      "  #opt: 141/1000\n",
      "  Mean percentage error: 0.3922\n",
      "  Mean improvement over greedy: -0.3794\n",
      "Run 10 test metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 57.47%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2925\n",
      "  Mean improvement over greedy: -0.2661\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for A2C with (+v_i -wr_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 54.11% ± 0.84%\n",
      "  #opt: 154.20 ± 12.41\n",
      "  Mean percentage error: 0.3851 ± 0.0121\n",
      "  Mean improvement over greedy: -0.3700 ± 0.0123\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 55.73% ± 8.20%\n",
      "  #opt: 0.90 ± 0.83\n",
      "  Mean percentage error: 0.3719 ± 0.0858\n",
      "  Mean improvement over greedy: -0.3526 ± 0.0861\n",
      "\n",
      "Experiment 4/15: Testing A2C with (+v_i -w_i)\n",
      "Positive reward: v_i, Negative reward: w_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 4.8\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 4.8\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 4.8\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 19.6\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 19.6\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 21.8\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 4.8\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 4.8\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 15.2\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 21.8\n",
      "Run 1 training metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 75.04%\n",
      "  #opt: 249/1000\n",
      "  Mean percentage error: 0.1885\n",
      "  Mean improvement over greedy: -0.1718\n",
      "Run 1 test metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 62.38%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2495\n",
      "  Mean improvement over greedy: -0.2130\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -36.44736842105263\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -36.95652173913044\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -36.1578947368421\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -41.10526315789474\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -37.78947368421053\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -12.538461538461538\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -30.90625\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 6.0\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -23.076923076923077\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -36.1578947368421\n",
      "Run 2 training metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 74.78%\n",
      "  #opt: 273/1000\n",
      "  Mean percentage error: 0.1886\n",
      "  Mean improvement over greedy: -0.1720\n",
      "Run 2 test metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 57.03%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2583\n",
      "  Mean improvement over greedy: -0.2583\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 13.5\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -32.75\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -32.75\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -32.75\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -17.0\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -32.75\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -32.75\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -32.75\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -32.75\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -13.941176470588236\n",
      "Run 3 training metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 68.74%\n",
      "  #opt: 210/1000\n",
      "  Mean percentage error: 0.2449\n",
      "  Mean improvement over greedy: -0.2280\n",
      "Run 3 test metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 80.93%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.1614\n",
      "  Mean improvement over greedy: -0.1416\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -45.25\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -30.636363636363637\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -45.8235294117647\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -45.8235294117647\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -45.8235294117647\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -45.8235294117647\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -45.8235294117647\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -45.8235294117647\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -45.8235294117647\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -45.8235294117647\n",
      "Run 4 training metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 60.14%\n",
      "  #opt: 167/1000\n",
      "  Mean percentage error: 0.3334\n",
      "  Mean improvement over greedy: -0.3188\n",
      "Run 4 test metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 44.47%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4025\n",
      "  Mean improvement over greedy: -0.3831\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -45.829268292682926\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -45.829268292682926\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -45.829268292682926\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -45.829268292682926\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -45.829268292682926\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -45.829268292682926\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -45.829268292682926\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -45.829268292682926\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -45.829268292682926\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -45.829268292682926\n",
      "Run 5 training metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 54.18%\n",
      "  #opt: 144/1000\n",
      "  Mean percentage error: 0.3904\n",
      "  Mean improvement over greedy: -0.3767\n",
      "Run 5 test metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 46.77%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5054\n",
      "  Mean improvement over greedy: -0.4677\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -34.5625\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -39.25\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -37.25\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -39.25\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -34.5625\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -34.5625\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -34.5625\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -34.5625\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -34.5625\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -34.5625\n",
      "Run 6 training metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 67.20%\n",
      "  #opt: 205/1000\n",
      "  Mean percentage error: 0.2576\n",
      "  Mean improvement over greedy: -0.2416\n",
      "Run 6 test metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 45.98%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5218\n",
      "  Mean improvement over greedy: -0.5126\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -15.5\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -15.5\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -15.5\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -15.5\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -17.25\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -20.75\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -13.0\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -15.5\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -13.0\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -15.5\n",
      "Run 7 training metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 72.86%\n",
      "  #opt: 253/1000\n",
      "  Mean percentage error: 0.2059\n",
      "  Mean improvement over greedy: -0.1939\n",
      "Run 7 test metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 59.99%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3219\n",
      "  Mean improvement over greedy: -0.3089\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -38.54545454545455\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -38.54545454545455\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -38.54545454545455\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -38.54545454545455\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -42.68181818181818\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -38.54545454545455\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -38.54545454545455\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -38.54545454545455\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -38.54545454545455\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -5.166666666666667\n",
      "Run 8 training metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 57.74%\n",
      "  #opt: 160/1000\n",
      "  Mean percentage error: 0.3522\n",
      "  Mean improvement over greedy: -0.3365\n",
      "Run 8 test metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 72.13%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2537\n",
      "  Mean improvement over greedy: -0.2342\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -19.636363636363637\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -19.636363636363637\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -19.636363636363637\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -19.636363636363637\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -19.636363636363637\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -19.636363636363637\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -20.90909090909091\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -19.454545454545453\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -26.272727272727273\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -22.818181818181817\n",
      "Run 9 training metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 74.96%\n",
      "  #opt: 272/1000\n",
      "  Mean percentage error: 0.1848\n",
      "  Mean improvement over greedy: -0.1692\n",
      "Run 9 test metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 56.47%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4001\n",
      "  Mean improvement over greedy: -0.3893\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -33.208333333333336\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -33.583333333333336\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -33.583333333333336\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -33.6\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -33.583333333333336\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -33.583333333333336\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -33.583333333333336\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -31.458333333333332\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -35.791666666666664\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -35.458333333333336\n",
      "Run 10 training metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 73.36%\n",
      "  #opt: 231/1000\n",
      "  Mean percentage error: 0.2032\n",
      "  Mean improvement over greedy: -0.1905\n",
      "Run 10 test metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 45.61%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4400\n",
      "  Mean improvement over greedy: -0.4136\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for A2C with (+v_i -w_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 67.90% ± 7.45%\n",
      "  #opt: 216.40 ± 44.66\n",
      "  Mean percentage error: 0.2550 ± 0.0727\n",
      "  Mean improvement over greedy: -0.2399 ± 0.0729\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 57.18% ± 11.63%\n",
      "  #opt: 1.00 ± 0.63\n",
      "  Mean percentage error: 0.3515 ± 0.1145\n",
      "  Mean improvement over greedy: -0.3322 ± 0.1138\n",
      "\n",
      "Experiment 5/15: Testing A2C with (+_1 -_1)\n",
      "Positive reward: _1, Negative reward: _1\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Run 1 training metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 53.36%\n",
      "  #opt: 132/1000\n",
      "  Mean percentage error: 0.4041\n",
      "  Mean improvement over greedy: -0.3874\n",
      "Run 1 test metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 52.93%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.3124\n",
      "  Mean improvement over greedy: -0.2758\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.7894736842105263\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.7894736842105263\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.7894736842105263\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.7894736842105263\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.7894736842105263\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.7894736842105263\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.7894736842105263\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.7894736842105263\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.7894736842105263\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.7894736842105263\n",
      "Run 2 training metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 53.26%\n",
      "  #opt: 139/1000\n",
      "  Mean percentage error: 0.3996\n",
      "  Mean improvement over greedy: -0.3830\n",
      "Run 2 test metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 48.40%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.3112\n",
      "  Mean improvement over greedy: -0.3112\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.6666666666666666\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.6666666666666666\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.6666666666666666\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.6666666666666666\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.6666666666666666\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.6666666666666666\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.6666666666666666\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.6666666666666666\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.6666666666666666\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.6666666666666666\n",
      "Run 3 training metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 53.80%\n",
      "  #opt: 143/1000\n",
      "  Mean percentage error: 0.3969\n",
      "  Mean improvement over greedy: -0.3800\n",
      "Run 3 test metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 65.78%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3950\n",
      "  Mean improvement over greedy: -0.3751\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.6470588235294118\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.6470588235294118\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.6470588235294118\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.6470588235294118\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.6470588235294118\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.6470588235294118\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.6470588235294118\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.6470588235294118\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.6470588235294118\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.6470588235294118\n",
      "Run 4 training metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 53.20%\n",
      "  #opt: 146/1000\n",
      "  Mean percentage error: 0.3999\n",
      "  Mean improvement over greedy: -0.3853\n",
      "Run 4 test metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 49.59%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3799\n",
      "  Mean improvement over greedy: -0.3605\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.7560975609756098\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.7560975609756098\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.7560975609756098\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.7560975609756098\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.7560975609756098\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.7560975609756098\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.7560975609756098\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.7560975609756098\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.7560975609756098\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.7560975609756098\n",
      "Run 5 training metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 54.27%\n",
      "  #opt: 144/1000\n",
      "  Mean percentage error: 0.3899\n",
      "  Mean improvement over greedy: -0.3762\n",
      "Run 5 test metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 46.77%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5054\n",
      "  Mean improvement over greedy: -0.4677\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.625\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.625\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.625\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.625\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.625\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.625\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.625\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.625\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.625\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.625\n",
      "Run 6 training metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 53.80%\n",
      "  #opt: 153/1000\n",
      "  Mean percentage error: 0.3902\n",
      "  Mean improvement over greedy: -0.3741\n",
      "Run 6 test metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 45.98%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5218\n",
      "  Mean improvement over greedy: -0.5126\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Run 7 training metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 53.12%\n",
      "  #opt: 156/1000\n",
      "  Mean percentage error: 0.3993\n",
      "  Mean improvement over greedy: -0.3874\n",
      "Run 7 test metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 59.99%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3219\n",
      "  Mean improvement over greedy: -0.3089\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.6363636363636364\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.6363636363636364\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.6363636363636364\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.6363636363636364\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.6363636363636364\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.6363636363636364\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.6363636363636364\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.6363636363636364\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.6363636363636364\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.6363636363636364\n",
      "Run 8 training metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 53.62%\n",
      "  #opt: 139/1000\n",
      "  Mean percentage error: 0.3961\n",
      "  Mean improvement over greedy: -0.3804\n",
      "Run 8 test metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 72.13%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2537\n",
      "  Mean improvement over greedy: -0.2342\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.09090909090909091\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.09090909090909091\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.09090909090909091\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.2727272727272727\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.09090909090909091\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.09090909090909091\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.09090909090909091\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.2727272727272727\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.45454545454545453\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.09090909090909091\n",
      "Run 9 training metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 74.96%\n",
      "  #opt: 274/1000\n",
      "  Mean percentage error: 0.1852\n",
      "  Mean improvement over greedy: -0.1696\n",
      "Run 9 test metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 46.45%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5052\n",
      "  Mean improvement over greedy: -0.4944\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.4166666666666667\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.5833333333333334\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.8333333333333334\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.4166666666666667\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.6363636363636364\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.5833333333333334\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.5833333333333334\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.4166666666666667\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.75\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.5833333333333334\n",
      "Run 10 training metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 73.55%\n",
      "  #opt: 227/1000\n",
      "  Mean percentage error: 0.2038\n",
      "  Mean improvement over greedy: -0.1911\n",
      "Run 10 test metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 50.77%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3978\n",
      "  Mean improvement over greedy: -0.3714\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for A2C with (+_1 -_1):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 57.69% ± 8.29%\n",
      "  #opt: 165.30 ± 44.36\n",
      "  Mean percentage error: 0.3565 ± 0.0812\n",
      "  Mean improvement over greedy: -0.3414 ± 0.0808\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 53.88% ± 8.60%\n",
      "  #opt: 0.80 ± 0.75\n",
      "  Mean percentage error: 0.3904 ± 0.0892\n",
      "  Mean improvement over greedy: -0.3712 ± 0.0894\n",
      "\n",
      "Experiment 6/15: Testing DQN with (+vr_i -wr_i)\n",
      "Positive reward: vr_i, Negative reward: wr_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.005276762817043792\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.004517794822580917\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.0348938319928081\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.004517794822580917\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.005276762817043793\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.004517794822580917\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.004517794822580917\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.004517794822580917\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.012955943704415804\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.004517794822580917\n",
      "Run 1 training metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 74.80%\n",
      "  #opt: 278/1000\n",
      "  Mean percentage error: 0.1887\n",
      "  Mean improvement over greedy: -0.1721\n",
      "Run 1 test metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 50.88%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3406\n",
      "  Mean improvement over greedy: -0.3040\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.5883612962029406\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.6561123915624898\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.648529635945937\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.6308031602694317\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.5308348406939956\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.6406130385003624\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.6056266914907603\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.6189968759927991\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.6774687831513554\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.6536516827033059\n",
      "Run 2 training metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 72.55%\n",
      "  #opt: 227/1000\n",
      "  Mean percentage error: 0.2151\n",
      "  Mean improvement over greedy: -0.1985\n",
      "Run 2 test metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 59.64%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2342\n",
      "  Mean improvement over greedy: -0.2342\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.19408512875661837\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.21265048189106225\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.1895321822424838\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.20224592254864954\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.20224592254864954\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.1748879983451684\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.16528990633674637\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.1961380435183652\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.1652899063367464\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.06905786006582265\n",
      "Run 3 training metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 72.61%\n",
      "  #opt: 222/1000\n",
      "  Mean percentage error: 0.2143\n",
      "  Mean improvement over greedy: -0.1974\n",
      "Run 3 test metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 66.25%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4051\n",
      "  Mean improvement over greedy: -0.3852\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -1.354203598426962\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -1.4399170761217592\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -1.3542035984269616\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -1.354203598426962\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -1.3414639540026538\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -1.354203598426962\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -1.354203598426962\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -1.2872722346406558\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -1.2127572391185577\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -1.2872722346406555\n",
      "Run 4 training metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 72.05%\n",
      "  #opt: 222/1000\n",
      "  Mean percentage error: 0.2188\n",
      "  Mean improvement over greedy: -0.2042\n",
      "Run 4 test metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 65.63%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2225\n",
      "  Mean improvement over greedy: -0.2031\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.6654526534859522\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -1.717073170731707\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -1.3754668930390495\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -1.3866369552914548\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.9382587582379466\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -1.5856587114258236\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -1.6608049581839903\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -1.5040770609318994\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -1.158455522971652\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -1.4624787775891341\n",
      "Run 5 training metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 71.05%\n",
      "  #opt: 225/1000\n",
      "  Mean percentage error: 0.2207\n",
      "  Mean improvement over greedy: -0.2070\n",
      "Run 5 test metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 47.58%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5183\n",
      "  Mean improvement over greedy: -0.4806\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.5555272493961353\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.527893101288082\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.5125069058998869\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.5734740802675585\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.512506905899887\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.5278931012880819\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.5555272493961352\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.5271452815259037\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.49853907867494823\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.512506905899887\n",
      "Run 6 training metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 72.07%\n",
      "  #opt: 227/1000\n",
      "  Mean percentage error: 0.2150\n",
      "  Mean improvement over greedy: -0.1990\n",
      "Run 6 test metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 43.85%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5509\n",
      "  Mean improvement over greedy: -0.5417\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.20132940260318166\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.20132940260318166\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.2882627216209993\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.20132940260318166\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.2882627216209993\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.2882627216209993\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.20132940260318166\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.2882627216209993\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.20132940260318166\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.2882627216209993\n",
      "Run 7 training metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 71.08%\n",
      "  #opt: 228/1000\n",
      "  Mean percentage error: 0.2221\n",
      "  Mean improvement over greedy: -0.2102\n",
      "Run 7 test metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 44.13%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3953\n",
      "  Mean improvement over greedy: -0.3823\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.30423817254174396\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.30423817254174396\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.34260856331168826\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 0.03828349632535942\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.2919037178753565\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.3264924161876502\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.3426085633116883\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.34260856331168826\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 0.024264705882352952\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.3135991907156432\n",
      "Run 8 training metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 71.78%\n",
      "  #opt: 228/1000\n",
      "  Mean percentage error: 0.2195\n",
      "  Mean improvement over greedy: -0.2038\n",
      "Run 8 test metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 57.38%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3967\n",
      "  Mean improvement over greedy: -0.3771\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.1500504635214843\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.1704673267908562\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.17046732679085622\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.17046732679085622\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.18571518567751408\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.15678237203972498\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.15678237203972498\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.1500504635214843\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.1500504635214843\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.17046732679085622\n",
      "Run 9 training metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 73.06%\n",
      "  #opt: 231/1000\n",
      "  Mean percentage error: 0.2079\n",
      "  Mean improvement over greedy: -0.1924\n",
      "Run 9 test metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 53.66%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4410\n",
      "  Mean improvement over greedy: -0.4302\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.41374120604875736\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.4832138785978913\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.40122169273378944\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.42023200757575746\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.3848748602627061\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.35429198903932946\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.46694766253237036\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.35758753221363193\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.4414472228701976\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.379277248289345\n",
      "Run 10 training metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 72.54%\n",
      "  #opt: 219/1000\n",
      "  Mean percentage error: 0.2162\n",
      "  Mean improvement over greedy: -0.2034\n",
      "Run 10 test metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 57.65%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3497\n",
      "  Mean improvement over greedy: -0.3233\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for DQN with (+vr_i -wr_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 72.36% ± 1.02%\n",
      "  #opt: 230.70 ± 16.12\n",
      "  Mean percentage error: 0.2138 ± 0.0092\n",
      "  Mean improvement over greedy: -0.1988 ± 0.0102\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 54.67% ± 7.67%\n",
      "  #opt: 0.70 ± 0.78\n",
      "  Mean percentage error: 0.3854 ± 0.1007\n",
      "  Mean improvement over greedy: -0.3662 ± 0.0992\n",
      "\n",
      "Experiment 7/15: Testing DQN with (+vr_i -w_i)\n",
      "Positive reward: vr_i, Negative reward: w_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -15.598374450112683\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -15.598374450112683\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -15.598374450112683\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -15.598374450112683\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -15.598374450112683\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -15.598374450112683\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -15.598374450112683\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -15.598374450112683\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -15.598374450112683\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -15.598374450112683\n",
      "Run 1 training metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 64.88%\n",
      "  #opt: 213/1000\n",
      "  Mean percentage error: 0.2806\n",
      "  Mean improvement over greedy: -0.2639\n",
      "Run 1 test metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 50.22%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3843\n",
      "  Mean improvement over greedy: -0.3477\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -44.474027512790286\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -44.55134574215157\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -44.44540387082793\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -44.55134574215157\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -44.04385184915425\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -44.08210528603721\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -46.36369955077007\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -44.42558280303833\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -44.42326733015915\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -44.436263878283555\n",
      "Run 2 training metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 62.93%\n",
      "  #opt: 200/1000\n",
      "  Mean percentage error: 0.2984\n",
      "  Mean improvement over greedy: -0.2818\n",
      "Run 2 test metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 61.40%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2471\n",
      "  Mean improvement over greedy: -0.2471\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -41.85707774818411\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -41.85707774818411\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -41.9142040592959\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -41.85707774818411\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -41.9142040592959\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -41.9142040592959\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -41.82934332718609\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -41.9142040592959\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -41.9142040592959\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -41.9142040592959\n",
      "Run 3 training metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 62.97%\n",
      "  #opt: 188/1000\n",
      "  Mean percentage error: 0.2985\n",
      "  Mean improvement over greedy: -0.2815\n",
      "Run 3 test metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 56.63%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5021\n",
      "  Mean improvement over greedy: -0.4822\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -51.52915062045357\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -52.09237938596491\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -50.070925669436754\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -42.058900928792575\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -47.79908410732715\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -52.56127102334533\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -42.49029282765738\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -52.4299237913789\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -47.79708820662768\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -51.598747885975094\n",
      "Run 4 training metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 62.83%\n",
      "  #opt: 183/1000\n",
      "  Mean percentage error: 0.3038\n",
      "  Mean improvement over greedy: -0.2892\n",
      "Run 4 test metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 65.89%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2624\n",
      "  Mean improvement over greedy: -0.2430\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -50.2426435877262\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -45.98595213319459\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -42.06691045230943\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -50.28053463714361\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -50.28053463714361\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -50.2426435877262\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -48.94625149342892\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -50.2426435877262\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -50.28053463714361\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -50.276010640290735\n",
      "Run 5 training metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 63.63%\n",
      "  #opt: 206/1000\n",
      "  Mean percentage error: 0.2887\n",
      "  Mean improvement over greedy: -0.2750\n",
      "Run 5 test metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 51.91%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3936\n",
      "  Mean improvement over greedy: -0.3559\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -44.68366092995169\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -44.68366092995169\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -44.68366092995169\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -44.68366092995169\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -44.68366092995169\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -44.68366092995169\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -44.68366092995169\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -44.68366092995169\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -44.68366092995169\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -44.68366092995169\n",
      "Run 6 training metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 63.81%\n",
      "  #opt: 186/1000\n",
      "  Mean percentage error: 0.2948\n",
      "  Mean improvement over greedy: -0.2788\n",
      "Run 6 test metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 51.50%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4810\n",
      "  Mean improvement over greedy: -0.4718\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -34.74093048839768\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -34.74093048839768\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -34.74093048839768\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -34.74093048839768\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -34.74093048839768\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -34.74093048839768\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -26.74865876122496\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -34.74093048839768\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -34.74093048839768\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -34.74093048839768\n",
      "Run 7 training metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 64.02%\n",
      "  #opt: 186/1000\n",
      "  Mean percentage error: 0.2943\n",
      "  Mean improvement over greedy: -0.2823\n",
      "Run 7 test metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 49.97%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3824\n",
      "  Mean improvement over greedy: -0.3694\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -49.61774737167594\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -49.61774737167594\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -49.61774737167594\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -49.61774737167594\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -49.61774737167594\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -49.61774737167594\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -49.61774737167594\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -32.26674829931973\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -49.61774737167594\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -49.43939698322511\n",
      "Run 8 training metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 63.22%\n",
      "  #opt: 176/1000\n",
      "  Mean percentage error: 0.3014\n",
      "  Mean improvement over greedy: -0.2857\n",
      "Run 8 test metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 49.91%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4603\n",
      "  Mean improvement over greedy: -0.4408\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -38.3586066132541\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -38.3586066132541\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -37.63165696976034\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -37.63165696976034\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -37.63165696976034\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -38.3586066132541\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -38.3586066132541\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -38.3586066132541\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -38.3586066132541\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -38.3586066132541\n",
      "Run 9 training metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 65.41%\n",
      "  #opt: 193/1000\n",
      "  Mean percentage error: 0.2793\n",
      "  Mean improvement over greedy: -0.2637\n",
      "Run 9 test metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 53.01%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4394\n",
      "  Mean improvement over greedy: -0.4286\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -44.31988562955132\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -44.439242264078416\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -44.439242264078416\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -44.439242264078416\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -44.439242264078416\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -44.439242264078416\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -44.28311079545455\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -44.31988562955132\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -44.439242264078416\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -44.32470654121863\n",
      "Run 10 training metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 66.08%\n",
      "  #opt: 167/1000\n",
      "  Mean percentage error: 0.2794\n",
      "  Mean improvement over greedy: -0.2666\n",
      "Run 10 test metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 49.68%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4536\n",
      "  Mean improvement over greedy: -0.4272\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for DQN with (+vr_i -w_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 63.98% ± 1.07%\n",
      "  #opt: 189.80 ± 13.05\n",
      "  Mean percentage error: 0.2919 ± 0.0089\n",
      "  Mean improvement over greedy: -0.2769 ± 0.0087\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 54.01% ± 5.30%\n",
      "  #opt: 0.70 ± 0.64\n",
      "  Mean percentage error: 0.4006 ± 0.0824\n",
      "  Mean improvement over greedy: -0.3814 ± 0.0808\n",
      "\n",
      "Experiment 8/15: Testing DQN with (+v_i -wr_i)\n",
      "Positive reward: v_i, Negative reward: wr_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 21.96382252559727\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 21.96382252559727\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 21.96382252559727\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 21.96382252559727\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 21.96382252559727\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 21.96382252559727\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 21.96382252559727\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 21.96382252559727\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 21.96382252559727\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 21.96382252559727\n",
      "Run 1 training metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 66.37%\n",
      "  #opt: 175/1000\n",
      "  Mean percentage error: 0.2753\n",
      "  Mean improvement over greedy: -0.2586\n",
      "Run 1 test metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 60.72%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2739\n",
      "  Mean improvement over greedy: -0.2374\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 7.591178650852485\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 7.591178650852485\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 7.591178650852487\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 7.591178650852485\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 7.591178650852485\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 7.591178650852485\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 7.591178650852485\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 7.591178650852485\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 7.591178650852485\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 7.591178650852485\n",
      "Run 2 training metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 58.78%\n",
      "  #opt: 175/1000\n",
      "  Mean percentage error: 0.3397\n",
      "  Mean improvement over greedy: -0.3232\n",
      "Run 2 test metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 62.73%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2332\n",
      "  Mean improvement over greedy: -0.2332\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 4.695580808080806\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 2.937626262626263\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 4.695580808080806\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 4.695580808080806\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 8.903219696969694\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 4.695580808080806\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 4.695580808080806\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 4.695580808080806\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 4.695580808080806\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 4.695580808080806\n",
      "Run 3 training metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 55.37%\n",
      "  #opt: 160/1000\n",
      "  Mean percentage error: 0.3767\n",
      "  Mean improvement over greedy: -0.3598\n",
      "Run 3 test metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 64.47%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3367\n",
      "  Mean improvement over greedy: -0.3168\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 5.6813655761024195\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 5.710526315789475\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 5.6813655761024195\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 5.6813655761024195\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 5.6813655761024195\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 5.6813655761024195\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 5.6813655761024195\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 5.326059050064185\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 5.6813655761024195\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 5.681365576102418\n",
      "Run 4 training metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 54.95%\n",
      "  #opt: 147/1000\n",
      "  Mean percentage error: 0.3824\n",
      "  Mean improvement over greedy: -0.3679\n",
      "Run 4 test metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 60.43%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.2989\n",
      "  Mean improvement over greedy: -0.2795\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 17.301075268817204\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 17.301075268817204\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 17.301075268817204\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 17.301075268817204\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 17.301075268817204\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 17.301075268817204\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 16.989247311827956\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 17.301075268817204\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 17.301075268817204\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 17.301075268817204\n",
      "Run 5 training metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 57.65%\n",
      "  #opt: 172/1000\n",
      "  Mean percentage error: 0.3489\n",
      "  Mean improvement over greedy: -0.3352\n",
      "Run 5 test metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 53.30%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3838\n",
      "  Mean improvement over greedy: -0.3461\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 6.203125\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 6.203125\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 6.203125\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 6.203125\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 6.203125\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 6.203125\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 6.203125\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 6.203125\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 6.203125\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 6.203125\n",
      "Run 6 training metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 55.82%\n",
      "  #opt: 169/1000\n",
      "  Mean percentage error: 0.3718\n",
      "  Mean improvement over greedy: -0.3558\n",
      "Run 6 test metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 31.51%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.6837\n",
      "  Mean improvement over greedy: -0.6746\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 19.09158415841584\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 19.09158415841584\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 19.09158415841584\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 15.556930693069306\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 19.09158415841584\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 15.556930693069306\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 15.556930693069306\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 15.556930693069306\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 15.556930693069306\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 15.556930693069306\n",
      "Run 7 training metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 55.85%\n",
      "  #opt: 159/1000\n",
      "  Mean percentage error: 0.3719\n",
      "  Mean improvement over greedy: -0.3600\n",
      "Run 7 test metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 45.33%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4052\n",
      "  Mean improvement over greedy: -0.3922\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 10.783685064935066\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 10.783685064935066\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 10.783685064935066\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 10.783685064935066\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 10.783685064935066\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 10.783685064935066\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 10.783685064935064\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 10.783685064935064\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 10.783685064935064\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 10.783685064935066\n",
      "Run 8 training metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 55.91%\n",
      "  #opt: 155/1000\n",
      "  Mean percentage error: 0.3783\n",
      "  Mean improvement over greedy: -0.3627\n",
      "Run 8 test metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 67.33%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3126\n",
      "  Mean improvement over greedy: -0.2931\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 16.84491978609626\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 16.84491978609626\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 16.84491978609626\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 16.84491978609626\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 16.84491978609626\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 16.84491978609626\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 16.38770053475936\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 16.84491978609626\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 16.84491978609626\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 16.84491978609626\n",
      "Run 9 training metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 57.34%\n",
      "  #opt: 167/1000\n",
      "  Mean percentage error: 0.3532\n",
      "  Mean improvement over greedy: -0.3376\n",
      "Run 9 test metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 50.37%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4763\n",
      "  Mean improvement over greedy: -0.4655\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 9.237878787878788\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 9.237878787878788\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 9.237878787878788\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 9.237878787878788\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 9.237878787878788\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 9.237878787878788\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 9.237878787878788\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 9.237878787878788\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 9.237878787878788\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 9.237878787878788\n",
      "Run 10 training metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 56.15%\n",
      "  #opt: 154/1000\n",
      "  Mean percentage error: 0.3714\n",
      "  Mean improvement over greedy: -0.3586\n",
      "Run 10 test metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 51.86%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4011\n",
      "  Mean improvement over greedy: -0.3747\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for DQN with (+v_i -wr_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 57.42% ± 3.18%\n",
      "  #opt: 163.30 ± 9.20\n",
      "  Mean percentage error: 0.3570 ± 0.0303\n",
      "  Mean improvement over greedy: -0.3419 ± 0.0309\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 54.81% ± 10.21%\n",
      "  #opt: 0.60 ± 0.66\n",
      "  Mean percentage error: 0.3805 ± 0.1218\n",
      "  Mean improvement over greedy: -0.3613 ± 0.1247\n",
      "\n",
      "Experiment 9/15: Testing DQN with (+v_i -w_i)\n",
      "Positive reward: v_i, Negative reward: w_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 21.8\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 21.8\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 21.8\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 21.8\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 19.6\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 4.8\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 21.8\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 21.8\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 21.8\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 21.8\n",
      "Run 1 training metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 63.18%\n",
      "  #opt: 201/1000\n",
      "  Mean percentage error: 0.2895\n",
      "  Mean improvement over greedy: -0.2728\n",
      "Run 1 test metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 54.97%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3196\n",
      "  Mean improvement over greedy: -0.2831\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -36.23684210526316\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -36.23684210526316\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -36.23684210526316\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -36.23684210526316\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -31.0\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -5.875\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -36.23684210526316\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -36.23684210526316\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -36.23684210526316\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -36.23684210526316\n",
      "Run 2 training metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 63.61%\n",
      "  #opt: 185/1000\n",
      "  Mean percentage error: 0.2869\n",
      "  Mean improvement over greedy: -0.2703\n",
      "Run 2 test metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 60.06%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2500\n",
      "  Mean improvement over greedy: -0.2500\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -37.0\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -37.0\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -37.0\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -37.916666666666664\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -37.0\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -37.0\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -37.916666666666664\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -37.0\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -32.30769230769231\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -37.916666666666664\n",
      "Run 3 training metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 62.27%\n",
      "  #opt: 190/1000\n",
      "  Mean percentage error: 0.3031\n",
      "  Mean improvement over greedy: -0.2861\n",
      "Run 3 test metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 63.70%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4201\n",
      "  Mean improvement over greedy: -0.4002\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -45.24390243902439\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -44.84848484848485\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -44.114285714285714\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 15.0\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -44.44736842105263\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -46.825\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -45.8125\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -21.846153846153847\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 13.666666666666666\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -46.81818181818182\n",
      "Run 4 training metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 61.57%\n",
      "  #opt: 185/1000\n",
      "  Mean percentage error: 0.3106\n",
      "  Mean improvement over greedy: -0.2960\n",
      "Run 4 test metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 63.10%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.2742\n",
      "  Mean improvement over greedy: -0.2548\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -47.8780487804878\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -47.8780487804878\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -25.0\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -47.09756097560975\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -47.09756097560975\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -47.09756097560975\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -47.111111111111114\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -47.09756097560975\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -25.0\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -25.0\n",
      "Run 5 training metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 61.29%\n",
      "  #opt: 200/1000\n",
      "  Mean percentage error: 0.3085\n",
      "  Mean improvement over greedy: -0.2948\n",
      "Run 5 test metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 57.75%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3858\n",
      "  Mean improvement over greedy: -0.3481\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -37.9375\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -37.9375\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -37.9375\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -37.9375\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -37.9375\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -37.9375\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -37.9375\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -37.9375\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -37.9375\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -37.9375\n",
      "Run 6 training metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 61.45%\n",
      "  #opt: 179/1000\n",
      "  Mean percentage error: 0.3116\n",
      "  Mean improvement over greedy: -0.2955\n",
      "Run 6 test metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 37.85%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.5458\n",
      "  Mean improvement over greedy: -0.5366\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -15.5\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -17.25\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -17.25\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -17.25\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -15.5\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -15.5\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -17.25\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -15.5\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -17.25\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -17.25\n",
      "Run 7 training metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 62.50%\n",
      "  #opt: 196/1000\n",
      "  Mean percentage error: 0.3020\n",
      "  Mean improvement over greedy: -0.2901\n",
      "Run 7 test metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 47.94%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3924\n",
      "  Mean improvement over greedy: -0.3794\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -38.54545454545455\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -38.54545454545455\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -42.54545454545455\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -38.54545454545455\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -38.54545454545455\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -38.54545454545455\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -38.54545454545455\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -38.54545454545455\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -42.68181818181818\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -38.54545454545455\n",
      "Run 8 training metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 59.56%\n",
      "  #opt: 173/1000\n",
      "  Mean percentage error: 0.3335\n",
      "  Mean improvement over greedy: -0.3179\n",
      "Run 8 test metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 75.59%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.2228\n",
      "  Mean improvement over greedy: -0.2033\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -21.09090909090909\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -21.363636363636363\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -21.363636363636363\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -21.363636363636363\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -21.363636363636363\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -21.363636363636363\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -21.363636363636363\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -21.09090909090909\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -21.09090909090909\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -21.363636363636363\n",
      "Run 9 training metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 62.47%\n",
      "  #opt: 203/1000\n",
      "  Mean percentage error: 0.2936\n",
      "  Mean improvement over greedy: -0.2780\n",
      "Run 9 test metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 53.55%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4632\n",
      "  Mean improvement over greedy: -0.4524\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -34.625\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -34.625\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -34.625\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -34.625\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -34.625\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -34.625\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -34.625\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -34.625\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -34.625\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -34.625\n",
      "Run 10 training metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 60.04%\n",
      "  #opt: 174/1000\n",
      "  Mean percentage error: 0.3262\n",
      "  Mean improvement over greedy: -0.3134\n",
      "Run 10 test metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 53.12%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3914\n",
      "  Mean improvement over greedy: -0.3650\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for DQN with (+v_i -w_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 61.79% ± 1.22%\n",
      "  #opt: 188.60 ± 10.59\n",
      "  Mean percentage error: 0.3065 ± 0.0143\n",
      "  Mean improvement over greedy: -0.2915 ± 0.0149\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 56.76% ± 9.57%\n",
      "  #opt: 0.60 ± 0.66\n",
      "  Mean percentage error: 0.3665 ± 0.0954\n",
      "  Mean improvement over greedy: -0.3473 ± 0.0969\n",
      "\n",
      "Experiment 10/15: Testing DQN with (+_1 -_1)\n",
      "Positive reward: _1, Negative reward: _1\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Run 1 training metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 66.85%\n",
      "  #opt: 193/1000\n",
      "  Mean percentage error: 0.2665\n",
      "  Mean improvement over greedy: -0.2498\n",
      "Run 1 test metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 47.51%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4211\n",
      "  Mean improvement over greedy: -0.3846\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.52\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.25\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.7894736842105263\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.7894736842105263\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.7894736842105263\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.7894736842105263\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.14285714285714285\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.7777777777777778\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.7837837837837838\n",
      "Run 2 training metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 67.76%\n",
      "  #opt: 205/1000\n",
      "  Mean percentage error: 0.2614\n",
      "  Mean improvement over greedy: -0.2448\n",
      "Run 2 test metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 56.76%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2728\n",
      "  Mean improvement over greedy: -0.2728\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.6111111111111112\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.7222222222222222\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.7222222222222222\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.375\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.6666666666666666\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.7222222222222222\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.7222222222222222\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.7222222222222222\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.7222222222222222\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.7222222222222222\n",
      "Run 3 training metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 67.71%\n",
      "  #opt: 211/1000\n",
      "  Mean percentage error: 0.2535\n",
      "  Mean improvement over greedy: -0.2366\n",
      "Run 3 test metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 72.73%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3758\n",
      "  Mean improvement over greedy: -0.3559\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.8536585365853658\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.8536585365853658\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.8536585365853658\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.14285714285714285\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.8536585365853658\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.14285714285714285\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.8536585365853658\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.14285714285714285\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.8536585365853658\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.7560975609756098\n",
      "Run 4 training metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 69.52%\n",
      "  #opt: 213/1000\n",
      "  Mean percentage error: 0.2390\n",
      "  Mean improvement over greedy: -0.2244\n",
      "Run 4 test metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 69.81%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2123\n",
      "  Mean improvement over greedy: -0.1929\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.8048780487804879\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.3333333333333333\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.3333333333333333\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.3333333333333333\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.8048780487804879\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.8048780487804879\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.8048780487804879\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.8048780487804879\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.8048780487804879\n",
      "Run 5 training metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 69.46%\n",
      "  #opt: 219/1000\n",
      "  Mean percentage error: 0.2397\n",
      "  Mean improvement over greedy: -0.2260\n",
      "Run 5 test metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 62.62%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3545\n",
      "  Mean improvement over greedy: -0.3168\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.625\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.625\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.625\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.625\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.625\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.625\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.625\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.625\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.75\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.75\n",
      "Run 6 training metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 70.10%\n",
      "  #opt: 209/1000\n",
      "  Mean percentage error: 0.2347\n",
      "  Mean improvement over greedy: -0.2187\n",
      "Run 6 test metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 50.72%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4861\n",
      "  Mean improvement over greedy: -0.4769\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Run 7 training metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 68.94%\n",
      "  #opt: 197/1000\n",
      "  Mean percentage error: 0.2476\n",
      "  Mean improvement over greedy: -0.2357\n",
      "Run 7 test metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 38.29%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4556\n",
      "  Mean improvement over greedy: -0.4426\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.6363636363636364\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.5454545454545454\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.7272727272727273\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.5454545454545454\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.6363636363636364\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.6363636363636364\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.6363636363636364\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.7272727272727273\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.6363636363636364\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.6363636363636364\n",
      "Run 8 training metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 69.67%\n",
      "  #opt: 213/1000\n",
      "  Mean percentage error: 0.2398\n",
      "  Mean improvement over greedy: -0.2242\n",
      "Run 8 test metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 60.29%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3849\n",
      "  Mean improvement over greedy: -0.3654\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.09090909090909091\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.09090909090909091\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.09090909090909091\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 0.09090909090909091\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 0.09090909090909091\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.09090909090909091\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.09090909090909091\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.09090909090909091\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.09090909090909091\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.09090909090909091\n",
      "Run 9 training metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 69.31%\n",
      "  #opt: 224/1000\n",
      "  Mean percentage error: 0.2396\n",
      "  Mean improvement over greedy: -0.2240\n",
      "Run 9 test metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 51.59%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4682\n",
      "  Mean improvement over greedy: -0.4573\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.75\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.75\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.75\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.75\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.7272727272727273\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.5833333333333334\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.75\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.75\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.75\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.75\n",
      "Run 10 training metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 68.11%\n",
      "  #opt: 199/1000\n",
      "  Mean percentage error: 0.2573\n",
      "  Mean improvement over greedy: -0.2445\n",
      "Run 10 test metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 46.88%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4747\n",
      "  Mean improvement over greedy: -0.4483\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for DQN with (+_1 -_1):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 68.75% ± 1.01%\n",
      "  #opt: 208.30 ± 9.34\n",
      "  Mean percentage error: 0.2479 ± 0.0105\n",
      "  Mean improvement over greedy: -0.2329 ± 0.0103\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 55.72% ± 10.24%\n",
      "  #opt: 0.60 ± 0.66\n",
      "  Mean percentage error: 0.3906 ± 0.0864\n",
      "  Mean improvement over greedy: -0.3713 ± 0.0863\n",
      "\n",
      "Experiment 11/15: Testing PPO with (+vr_i -wr_i)\n",
      "Positive reward: vr_i, Negative reward: wr_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.0348938319928081\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.0348938319928081\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.0348938319928081\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.0348938319928081\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.0348938319928081\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.0348938319928081\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.0348938319928081\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.0348938319928081\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.0348938319928081\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.0348938319928081\n",
      "Run 1 training metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 59.77%\n",
      "  #opt: 141/1000\n",
      "  Mean percentage error: 0.3494\n",
      "  Mean improvement over greedy: -0.3327\n",
      "Run 1 test metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 52.93%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.3124\n",
      "  Mean improvement over greedy: -0.2758\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.6774687831513554\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.6774687831513552\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.4192173846072064\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.39845253859338364\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.5976159990244498\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.5546539212705184\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.6070972306402806\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.5868661147211136\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.5673197682829001\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.5936327695037851\n",
      "Run 2 training metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 75.60%\n",
      "  #opt: 281/1000\n",
      "  Mean percentage error: 0.1814\n",
      "  Mean improvement over greedy: -0.1648\n",
      "Run 2 test metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 61.61%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2392\n",
      "  Mean improvement over greedy: -0.2392\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.19479570181399453\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.14607851094109742\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.10957604248655385\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.23293478105833687\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.16550875419147915\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.10324585529205095\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.17548365468095786\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.18986033898271198\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.18502701863605397\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.2063255589746991\n",
      "Run 3 training metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 76.74%\n",
      "  #opt: 293/1000\n",
      "  Mean percentage error: 0.1699\n",
      "  Mean improvement over greedy: -0.1529\n",
      "Run 3 test metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 67.68%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3595\n",
      "  Mean improvement over greedy: -0.3396\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -1.29468833373757\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -1.093583959899749\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -1.3485567577480289\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.24420534093855326\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -1.5074912891986065\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -1.383072905139215\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -1.3216331269349844\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -1.348556222874259\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -1.3485567577480289\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -1.485443792407849\n",
      "Run 4 training metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 75.49%\n",
      "  #opt: 286/1000\n",
      "  Mean percentage error: 0.1800\n",
      "  Mean improvement over greedy: -0.1654\n",
      "Run 4 test metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 47.18%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4018\n",
      "  Mean improvement over greedy: -0.3824\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -1.6552288224495146\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.8340879079418977\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -1.7180260512282544\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -1.5645430107526885\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -1.6058726220016544\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -1.7207172139633111\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -1.582967261124224\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -1.6654733805402568\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -1.6446586240055947\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -1.5806835637480798\n",
      "Run 5 training metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 75.54%\n",
      "  #opt: 281/1000\n",
      "  Mean percentage error: 0.1797\n",
      "  Mean improvement over greedy: -0.1660\n",
      "Run 5 test metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 53.88%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4931\n",
      "  Mean improvement over greedy: -0.4553\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.5555272493961353\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.5625654052960222\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.48824688878386896\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.5837287486064661\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.5154648386034255\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.5493165059195755\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.5734740802675585\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.5625654052960223\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.49853907867494823\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.5278818491501758\n",
      "Run 6 training metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 75.93%\n",
      "  #opt: 283/1000\n",
      "  Mean percentage error: 0.1750\n",
      "  Mean improvement over greedy: -0.1590\n",
      "Run 6 test metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 36.90%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.6255\n",
      "  Mean improvement over greedy: -0.6163\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.20132940260318166\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.1493463299818354\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.18484598459845986\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.2882627216209993\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.1493463299818354\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.20132940260318166\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.18484598459845986\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.1493463299818354\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.18484598459845983\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.1493463299818354\n",
      "Run 7 training metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 75.18%\n",
      "  #opt: 290/1000\n",
      "  Mean percentage error: 0.1841\n",
      "  Mean improvement over greedy: -0.1722\n",
      "Run 7 test metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 37.61%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.5104\n",
      "  Mean improvement over greedy: -0.4974\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.32326397189794903\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.3226609354101049\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.28686122176143186\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.05823380408936812\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.2959564152365491\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.2990795858714578\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.2895660909053766\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.2786691762070682\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.26395698523311767\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.38728548237476806\n",
      "Run 8 training metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 75.59%\n",
      "  #opt: 264/1000\n",
      "  Mean percentage error: 0.1832\n",
      "  Mean improvement over greedy: -0.1675\n",
      "Run 8 test metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 59.87%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3882\n",
      "  Mean improvement over greedy: -0.3687\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.1590112019449836\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.19179881393116685\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.20589802354508235\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.15068806439192828\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.18301020447790925\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.17259538950715422\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.16364555115978266\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.07057614521900236\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.19124734334293159\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.20589802354508235\n",
      "Run 9 training metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 76.37%\n",
      "  #opt: 299/1000\n",
      "  Mean percentage error: 0.1728\n",
      "  Mean improvement over greedy: -0.1572\n",
      "Run 9 test metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 51.79%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4550\n",
      "  Mean improvement over greedy: -0.4442\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.28167254440961337\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.4715127857157713\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.4202320075757577\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.3327699470668221\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.4069832651107852\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.3887496720451265\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.45246039944903593\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.43974312086381057\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.43710126129250254\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.3879470844811754\n",
      "Run 10 training metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 75.41%\n",
      "  #opt: 279/1000\n",
      "  Mean percentage error: 0.1831\n",
      "  Mean improvement over greedy: -0.1703\n",
      "Run 10 test metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 61.96%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2736\n",
      "  Mean improvement over greedy: -0.2472\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for PPO with (+vr_i -wr_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 74.16% ± 4.82%\n",
      "  #opt: 269.70 ± 43.81\n",
      "  Mean percentage error: 0.1958 ± 0.0514\n",
      "  Mean improvement over greedy: -0.1808 ± 0.0509\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 53.14% ± 9.74%\n",
      "  #opt: 0.80 ± 0.87\n",
      "  Mean percentage error: 0.4059 ± 0.1121\n",
      "  Mean improvement over greedy: -0.3866 ± 0.1136\n",
      "\n",
      "Experiment 12/15: Testing PPO with (+vr_i -w_i)\n",
      "Positive reward: vr_i, Negative reward: w_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -8.798621472714654\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -8.798621472714654\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -13.199019652464369\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -13.199019652464369\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -8.798621472714654\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -8.798621472714654\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -8.79845082425049\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -8.79845082425049\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -8.79845082425049\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -8.79845082425049\n",
      "Run 1 training metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 74.96%\n",
      "  #opt: 271/1000\n",
      "  Mean percentage error: 0.1871\n",
      "  Mean improvement over greedy: -0.1704\n",
      "Run 1 test metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 73.65%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2156\n",
      "  Mean improvement over greedy: -0.1790\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -44.47329441373887\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -44.4237309565818\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -36.623827326096496\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -41.87951703781465\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -44.42390056046005\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -50.08198748043818\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -44.497631990775055\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -44.424864979349785\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -44.55047760860183\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -44.41827831021215\n",
      "Run 2 training metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 76.31%\n",
      "  #opt: 287/1000\n",
      "  Mean percentage error: 0.1741\n",
      "  Mean improvement over greedy: -0.1575\n",
      "Run 2 test metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 59.00%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2423\n",
      "  Mean improvement over greedy: -0.2423\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -41.83133424318513\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -41.91128013996676\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -41.94018822400593\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -41.85718312474447\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -41.85993844123136\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -41.886230315676\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -22.874512676978444\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -41.88738300381042\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -38.39458300410014\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -38.41285411321453\n",
      "Run 3 training metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 76.52%\n",
      "  #opt: 286/1000\n",
      "  Mean percentage error: 0.1710\n",
      "  Mean improvement over greedy: -0.1541\n",
      "Run 3 test metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 54.01%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5329\n",
      "  Mean improvement over greedy: -0.5130\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -51.600222507488226\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -51.38621553884712\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -51.59874788597511\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -50.59550770866561\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -49.48897297122116\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -51.60621255883611\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -51.62843388960205\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -52.64238395467836\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -51.65322473551415\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -53.0822621068801\n",
      "Run 4 training metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 75.97%\n",
      "  #opt: 276/1000\n",
      "  Mean percentage error: 0.1784\n",
      "  Mean improvement over greedy: -0.1638\n",
      "Run 4 test metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 53.76%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3952\n",
      "  Mean improvement over greedy: -0.3758\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -50.251161440185825\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -50.24654690095288\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -50.23189089955416\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -50.2216482394026\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -50.233054681353266\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 0.05619146722164412\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -50.25790388145817\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -46.54201911589008\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -50.25116144018583\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -40.17984639016897\n",
      "Run 5 training metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 75.48%\n",
      "  #opt: 289/1000\n",
      "  Mean percentage error: 0.1794\n",
      "  Mean improvement over greedy: -0.1656\n",
      "Run 5 test metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 55.55%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4003\n",
      "  Mean improvement over greedy: -0.3626\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -44.43620670964385\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -44.43620670964385\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -44.183395281525904\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -45.06018607113697\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -44.93522775213421\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -44.683660929951685\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -44.997782684178745\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -45.24599585018537\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -45.43563092251951\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -44.68366092995169\n",
      "Run 6 training metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 76.27%\n",
      "  #opt: 282/1000\n",
      "  Mean percentage error: 0.1734\n",
      "  Mean improvement over greedy: -0.1574\n",
      "Run 6 test metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 41.50%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.5091\n",
      "  Mean improvement over greedy: -0.4999\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -27.748359105573478\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -27.748359105573478\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -26.74865876122496\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -32.991776677667765\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -32.99177667766777\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -32.991776677667765\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -26.74865876122496\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -32.991776677667765\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -26.74865876122496\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -32.99177667766777\n",
      "Run 7 training metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 75.61%\n",
      "  #opt: 292/1000\n",
      "  Mean percentage error: 0.1782\n",
      "  Mean improvement over greedy: -0.1663\n",
      "Run 7 test metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 49.87%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3439\n",
      "  Mean improvement over greedy: -0.3309\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -37.51691922087187\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -49.363118280648266\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -49.66352763781951\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -49.57250115955473\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -49.43847928664952\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -49.6642862537353\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -49.98157540004638\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -49.34692980727645\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -49.57250115955473\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -49.98268376307135\n",
      "Run 8 training metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 75.62%\n",
      "  #opt: 267/1000\n",
      "  Mean percentage error: 0.1798\n",
      "  Mean improvement over greedy: -0.1641\n",
      "Run 8 test metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 75.71%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2455\n",
      "  Mean improvement over greedy: -0.2259\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -36.17922340232389\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -37.54026103196735\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -36.45135256899963\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -36.81441518040783\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -36.176681683115504\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -36.635357734398966\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -36.45177205628672\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -36.26925092617692\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -36.814940290430485\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -37.995909597666916\n",
      "Run 9 training metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 76.14%\n",
      "  #opt: 288/1000\n",
      "  Mean percentage error: 0.1730\n",
      "  Mean improvement over greedy: -0.1574\n",
      "Run 9 test metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 60.49%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3504\n",
      "  Mean improvement over greedy: -0.3396\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -44.40389125631314\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -53.60989214547208\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -44.32007140369209\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -44.362581585081585\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -44.332379476584016\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -44.36005902544205\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 0.03899793388429752\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -30.181775654269973\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -33.81624428456159\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -44.40844859889214\n",
      "Run 10 training metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 75.78%\n",
      "  #opt: 291/1000\n",
      "  Mean percentage error: 0.1797\n",
      "  Mean improvement over greedy: -0.1669\n",
      "Run 10 test metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 35.19%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.5591\n",
      "  Mean improvement over greedy: -0.5327\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for PPO with (+vr_i -w_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 75.87% ± 0.44%\n",
      "  #opt: 282.90 ± 8.25\n",
      "  Mean percentage error: 0.1774 ± 0.0044\n",
      "  Mean improvement over greedy: -0.1624 ± 0.0051\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 55.87% ± 11.91%\n",
      "  #opt: 0.90 ± 0.70\n",
      "  Mean percentage error: 0.3794 ± 0.1179\n",
      "  Mean improvement over greedy: -0.3602 ± 0.1179\n",
      "\n",
      "Experiment 13/15: Testing PPO with (+v_i -wr_i)\n",
      "Positive reward: v_i, Negative reward: wr_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 28.385665529010236\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 30.793856655290103\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 30.593174061433444\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 28.385665529010236\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 21.96382252559727\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 30.793856655290103\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 21.96382252559727\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 18.55221843003413\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 21.96382252559727\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 28.385665529010236\n",
      "Run 1 training metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 75.50%\n",
      "  #opt: 266/1000\n",
      "  Mean percentage error: 0.1831\n",
      "  Mean improvement over greedy: -0.1664\n",
      "Run 1 test metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 53.81%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2913\n",
      "  Mean improvement over greedy: -0.2548\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 15.905633802816899\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 5.643068939955523\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 6.043365455893254\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 9.67272053372869\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 6.36360266864344\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 6.15011119347665\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 4.869162342475908\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 7.325955734406438\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 4.070803197563762\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 13.537131882202305\n",
      "Run 2 training metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 76.04%\n",
      "  #opt: 284/1000\n",
      "  Mean percentage error: 0.1771\n",
      "  Mean improvement over greedy: -0.1605\n",
      "Run 2 test metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 56.87%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2625\n",
      "  Mean improvement over greedy: -0.2625\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 12.369191919191922\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 9.969444444444447\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 20.322402597402597\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 15.105485893416928\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 24.40050505050505\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 5.114141414141412\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 11.169318181818182\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 5.979166666666665\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 10.108964646464646\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 7.290656565656562\n",
      "Run 3 training metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 76.41%\n",
      "  #opt: 306/1000\n",
      "  Mean percentage error: 0.1711\n",
      "  Mean improvement over greedy: -0.1542\n",
      "Run 3 test metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 47.18%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5591\n",
      "  Mean improvement over greedy: -0.5393\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 4.778032036613273\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 10.656698564593302\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 10.358299595141704\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 3.0231065468549434\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 3.0231065468549434\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 7.320175438596492\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 5.195290858725763\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 1.3459563543003852\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 4.848026315789475\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 5.139196675900277\n",
      "Run 4 training metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 76.01%\n",
      "  #opt: 283/1000\n",
      "  Mean percentage error: 0.1770\n",
      "  Mean improvement over greedy: -0.1624\n",
      "Run 4 test metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 57.12%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2988\n",
      "  Mean improvement over greedy: -0.2794\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 0.2640382317801671\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 3.61136712749616\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.5476003147128246\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 2.700236034618413\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 1.7938630999213232\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 0.686073957513769\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 2.775767112509835\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 1.7938630999213232\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 3.153422501966954\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 7.31989247311828\n",
      "Run 5 training metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 76.21%\n",
      "  #opt: 300/1000\n",
      "  Mean percentage error: 0.1722\n",
      "  Mean improvement over greedy: -0.1584\n",
      "Run 5 test metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 44.92%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5063\n",
      "  Mean improvement over greedy: -0.4686\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 7.782608695652174\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 1.84375\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 12.394701086956522\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 8.161684782608695\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 5.634510869565218\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 11.19429347826087\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 12.394701086956522\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 11.447010869565217\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 7.65625\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 7.656249999999999\n",
      "Run 6 training metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 75.79%\n",
      "  #opt: 273/1000\n",
      "  Mean percentage error: 0.1769\n",
      "  Mean improvement over greedy: -0.1609\n",
      "Run 6 test metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 58.67%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4133\n",
      "  Mean improvement over greedy: -0.4041\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 14.547029702970297\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 5.71039603960396\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 19.09158415841584\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 5.71039603960396\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 5.71039603960396\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 15.556930693069306\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 19.09158415841584\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 19.09158415841584\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 5.71039603960396\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 15.556930693069306\n",
      "Run 7 training metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 75.55%\n",
      "  #opt: 292/1000\n",
      "  Mean percentage error: 0.1812\n",
      "  Mean improvement over greedy: -0.1692\n",
      "Run 7 test metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 60.46%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3329\n",
      "  Mean improvement over greedy: -0.3199\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 8.444805194805193\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 9.820616883116882\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 13.210119047619049\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 6.79383116883117\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 8.582386363636362\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 36.0\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 8.582386363636363\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 9.08685064935065\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 10.23336038961039\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 9.545454545454543\n",
      "Run 8 training metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 75.32%\n",
      "  #opt: 268/1000\n",
      "  Mean percentage error: 0.1839\n",
      "  Mean improvement over greedy: -0.1683\n",
      "Run 8 test metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 65.70%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3439\n",
      "  Mean improvement over greedy: -0.3243\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 10.901069518716577\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 19.13101604278075\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 15.656149732620321\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 11.083957219251339\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 10.26096256684492\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 17.027807486631016\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 11.358288770053477\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 10.901069518716577\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 14.833155080213906\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 15.473262032085563\n",
      "Run 9 training metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 76.27%\n",
      "  #opt: 309/1000\n",
      "  Mean percentage error: 0.1723\n",
      "  Mean improvement over greedy: -0.1567\n",
      "Run 9 test metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 51.46%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4263\n",
      "  Mean improvement over greedy: -0.4155\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 5.621969696969696\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 8.144696969696968\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 7.219696969696969\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 9.700378787878787\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 11.045833333333333\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 7.68219696969697\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 12.895833333333341\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 9.237878787878788\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 5.790151515151514\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 12.223106060606066\n",
      "Run 10 training metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 75.92%\n",
      "  #opt: 268/1000\n",
      "  Mean percentage error: 0.1806\n",
      "  Mean improvement over greedy: -0.1679\n",
      "Run 10 test metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 47.01%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4536\n",
      "  Mean improvement over greedy: -0.4272\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for PPO with (+v_i -wr_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 75.90% ± 0.34%\n",
      "  #opt: 284.90 ± 15.42\n",
      "  Mean percentage error: 0.1775 ± 0.0044\n",
      "  Mean improvement over greedy: -0.1625 ± 0.0050\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 54.32% ± 6.34%\n",
      "  #opt: 0.80 ± 0.60\n",
      "  Mean percentage error: 0.3888 ± 0.0937\n",
      "  Mean improvement over greedy: -0.3695 ± 0.0908\n",
      "\n",
      "Experiment 14/15: Testing PPO with (+v_i -w_i)\n",
      "Positive reward: v_i, Negative reward: w_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 4.8\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 5.4\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 21.8\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 21.8\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 15.2\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 19.6\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 4.8\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 21.8\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 4.8\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 4.8\n",
      "Run 1 training metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 75.40%\n",
      "  #opt: 265/1000\n",
      "  Mean percentage error: 0.1840\n",
      "  Mean improvement over greedy: -0.1673\n",
      "Run 1 test metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 46.63%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3861\n",
      "  Mean improvement over greedy: -0.3496\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -26.09090909090909\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -29.96153846153846\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -12.333333333333334\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -41.18421052631579\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -33.8\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -28.954545454545453\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -37.8421052631579\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -33.44736842105263\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -40.0\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -36.52\n",
      "Run 2 training metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 76.07%\n",
      "  #opt: 277/1000\n",
      "  Mean percentage error: 0.1766\n",
      "  Mean improvement over greedy: -0.1601\n",
      "Run 2 test metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 52.77%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2909\n",
      "  Mean improvement over greedy: -0.2909\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -31.805555555555557\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -20.142857142857142\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -30.11111111111111\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -28.416666666666668\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -32.44444444444444\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -29.694444444444443\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -25.97222222222222\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -28.02777777777778\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -31.88888888888889\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -5.473684210526316\n",
      "Run 3 training metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 76.48%\n",
      "  #opt: 290/1000\n",
      "  Mean percentage error: 0.1716\n",
      "  Mean improvement over greedy: -0.1547\n",
      "Run 3 test metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 74.09%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3180\n",
      "  Mean improvement over greedy: -0.2982\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -47.31707317073171\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -45.24390243902439\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -45.21951219512195\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -44.90243902439025\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -41.89473684210526\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -45.24390243902439\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -26.705882352941178\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -45.09756097560975\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -44.90243902439025\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -46.85\n",
      "Run 4 training metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 75.77%\n",
      "  #opt: 281/1000\n",
      "  Mean percentage error: 0.1802\n",
      "  Mean improvement over greedy: -0.1657\n",
      "Run 4 test metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 65.98%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3184\n",
      "  Mean improvement over greedy: -0.2991\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -44.54545454545455\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -45.78048780487805\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -46.80487804878049\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -47.8780487804878\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -47.09756097560975\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -49.073170731707314\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -46.4390243902439\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -47.90243902439025\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -49.073170731707314\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -48.31707317073171\n",
      "Run 5 training metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 75.70%\n",
      "  #opt: 287/1000\n",
      "  Mean percentage error: 0.1772\n",
      "  Mean improvement over greedy: -0.1635\n",
      "Run 5 test metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 48.78%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4896\n",
      "  Mean improvement over greedy: -0.4519\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -35.375\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -37.9375\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 50.0\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -38.75\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -36.0\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -38.75\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -35.9375\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -38.75\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -38.75\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -37.3125\n",
      "Run 6 training metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 75.73%\n",
      "  #opt: 279/1000\n",
      "  Mean percentage error: 0.1769\n",
      "  Mean improvement over greedy: -0.1609\n",
      "Run 6 test metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 42.89%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5756\n",
      "  Mean improvement over greedy: -0.5664\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -15.5\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -20.75\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -20.75\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -15.5\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -17.25\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -15.5\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -17.25\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -15.5\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -15.5\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -20.75\n",
      "Run 7 training metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 75.19%\n",
      "  #opt: 281/1000\n",
      "  Mean percentage error: 0.1834\n",
      "  Mean improvement over greedy: -0.1715\n",
      "Run 7 test metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 47.52%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4168\n",
      "  Mean improvement over greedy: -0.4038\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -37.45454545454545\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -38.86363636363637\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -39.95454545454545\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -42.45454545454545\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -41.0\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -39.86363636363637\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -39.285714285714285\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -43.72727272727273\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -37.54545454545455\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -39.63636363636363\n",
      "Run 8 training metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 75.67%\n",
      "  #opt: 278/1000\n",
      "  Mean percentage error: 0.1821\n",
      "  Mean improvement over greedy: -0.1664\n",
      "Run 8 test metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 73.28%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.2746\n",
      "  Mean improvement over greedy: -0.2551\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -21.727272727272727\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -22.818181818181817\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -28.181818181818183\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -24.272727272727273\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -2.875\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -19.454545454545453\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -23.0\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -23.90909090909091\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -19.90909090909091\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -21.545454545454547\n",
      "Run 9 training metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 76.77%\n",
      "  #opt: 294/1000\n",
      "  Mean percentage error: 0.1707\n",
      "  Mean improvement over greedy: -0.1551\n",
      "Run 9 test metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 49.15%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4685\n",
      "  Mean improvement over greedy: -0.4577\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -34.75\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -38.791666666666664\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -35.208333333333336\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -11.416666666666666\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -38.375\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -30.541666666666668\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -28.416666666666668\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -19.58823529411765\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -31.541666666666668\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -34.625\n",
      "Run 10 training metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 74.98%\n",
      "  #opt: 267/1000\n",
      "  Mean percentage error: 0.1851\n",
      "  Mean improvement over greedy: -0.1723\n",
      "Run 10 test metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 60.14%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3195\n",
      "  Mean improvement over greedy: -0.2931\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for PPO with (+v_i -w_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 75.78% ± 0.52%\n",
      "  #opt: 279.90 ± 8.69\n",
      "  Mean percentage error: 0.1788 ± 0.0048\n",
      "  Mean improvement over greedy: -0.1637 ± 0.0058\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 56.13% ± 10.88%\n",
      "  #opt: 0.50 ± 0.67\n",
      "  Mean percentage error: 0.3858 ± 0.0946\n",
      "  Mean improvement over greedy: -0.3666 ± 0.0949\n",
      "\n",
      "Experiment 15/15: Testing PPO with (+_1 -_1)\n",
      "Positive reward: _1, Negative reward: _1\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 0.6\n",
      "Run 1 training metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 75.77%\n",
      "  #opt: 289/1000\n",
      "  Mean percentage error: 0.1786\n",
      "  Mean improvement over greedy: -0.1619\n",
      "Run 1 test metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 51.99%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3075\n",
      "  Mean improvement over greedy: -0.2709\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.7368421052631579\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.7368421052631579\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.7368421052631579\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.6842105263157895\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.6842105263157895\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.7222222222222222\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.6842105263157895\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.7142857142857143\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.2\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.5172413793103449\n",
      "Run 2 training metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 76.54%\n",
      "  #opt: 288/1000\n",
      "  Mean percentage error: 0.1741\n",
      "  Mean improvement over greedy: -0.1576\n",
      "Run 2 test metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 53.78%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2844\n",
      "  Mean improvement over greedy: -0.2844\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.6666666666666666\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.6111111111111112\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.7222222222222222\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.7777777777777778\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.7222222222222222\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.5555555555555556\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.6666666666666666\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.14285714285714285\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 0.7142857142857143\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.7333333333333333\n",
      "Run 3 training metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 76.86%\n",
      "  #opt: 292/1000\n",
      "  Mean percentage error: 0.1691\n",
      "  Mean improvement over greedy: -0.1521\n",
      "Run 3 test metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 61.97%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4371\n",
      "  Mean improvement over greedy: -0.4173\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.9024390243902439\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.9024390243902439\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.8536585365853658\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.8333333333333334\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.6842105263157895\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.8536585365853658\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.8048780487804879\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.76\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.7560975609756098\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.8048780487804879\n",
      "Run 4 training metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 76.30%\n",
      "  #opt: 288/1000\n",
      "  Mean percentage error: 0.1767\n",
      "  Mean improvement over greedy: -0.1621\n",
      "Run 4 test metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 59.87%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3799\n",
      "  Mean improvement over greedy: -0.3605\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.6\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.8048780487804879\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.8536585365853658\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.8048780487804879\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.6\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.8048780487804879\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.7837837837837838\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.8536585365853658\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.8536585365853658\n",
      "Run 5 training metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 75.62%\n",
      "  #opt: 283/1000\n",
      "  Mean percentage error: 0.1776\n",
      "  Mean improvement over greedy: -0.1639\n",
      "Run 5 test metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 46.73%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5316\n",
      "  Mean improvement over greedy: -0.4939\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.75\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.625\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.625\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.625\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.75\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.75\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.75\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.625\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.625\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.75\n",
      "Run 6 training metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 75.56%\n",
      "  #opt: 282/1000\n",
      "  Mean percentage error: 0.1788\n",
      "  Mean improvement over greedy: -0.1628\n",
      "Run 6 test metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 36.11%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.6423\n",
      "  Mean improvement over greedy: -0.6332\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.5\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.5\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.5\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: 0.0\n",
      "Run 7 training metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 75.00%\n",
      "  #opt: 271/1000\n",
      "  Mean percentage error: 0.1865\n",
      "  Mean improvement over greedy: -0.1746\n",
      "Run 7 test metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 44.81%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4349\n",
      "  Mean improvement over greedy: -0.4219\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.7272727272727273\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.6363636363636364\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.7272727272727273\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.6363636363636364\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.6363636363636364\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.6363636363636364\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.5454545454545454\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.7272727272727273\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.7272727272727273\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.6363636363636364\n",
      "Run 8 training metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 75.61%\n",
      "  #opt: 274/1000\n",
      "  Mean percentage error: 0.1810\n",
      "  Mean improvement over greedy: -0.1654\n",
      "Run 8 test metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 61.69%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3952\n",
      "  Mean improvement over greedy: -0.3757\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.2727272727272727\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.2727272727272727\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.2727272727272727\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.45454545454545453\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: 0.09090909090909091\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.2727272727272727\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.45454545454545453\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.09090909090909091\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: -0.2727272727272727\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.2727272727272727\n",
      "Run 9 training metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 76.31%\n",
      "  #opt: 298/1000\n",
      "  Mean percentage error: 0.1741\n",
      "  Mean improvement over greedy: -0.1585\n",
      "Run 9 test metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 45.77%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5211\n",
      "  Mean improvement over greedy: -0.5103\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 1000 KP Instances, with N=50, t_max=10000\n",
      "Iteration [0/10000], Training KP Instance 0, Reward: -0.8333333333333334\n",
      "Iteration [1000/10000], Training KP Instance 0, Reward: -0.6666666666666666\n",
      "Iteration [2000/10000], Training KP Instance 0, Reward: -0.75\n",
      "Iteration [3000/10000], Training KP Instance 0, Reward: -0.75\n",
      "Iteration [4000/10000], Training KP Instance 0, Reward: -0.8333333333333334\n",
      "Iteration [5000/10000], Training KP Instance 0, Reward: -0.1111111111111111\n",
      "Iteration [6000/10000], Training KP Instance 0, Reward: -0.5833333333333334\n",
      "Iteration [7000/10000], Training KP Instance 0, Reward: -0.75\n",
      "Iteration [8000/10000], Training KP Instance 0, Reward: 0.3333333333333333\n",
      "Iteration [9000/10000], Training KP Instance 0, Reward: -0.5833333333333334\n",
      "Run 10 training metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 75.40%\n",
      "  #opt: 275/1000\n",
      "  Mean percentage error: 0.1823\n",
      "  Mean improvement over greedy: -0.1696\n",
      "Run 10 test metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 46.56%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4429\n",
      "  Mean improvement over greedy: -0.4165\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for PPO with (+_1 -_1):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 75.90% ± 0.55%\n",
      "  #opt: 284.00 ± 8.20\n",
      "  Mean percentage error: 0.1779 ± 0.0046\n",
      "  Mean improvement over greedy: -0.1628 ± 0.0059\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 50.93% ± 8.04%\n",
      "  #opt: 0.50 ± 0.67\n",
      "  Mean percentage error: 0.4377 ± 0.1016\n",
      "  Mean improvement over greedy: -0.4185 ± 0.1025\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Results:\n",
      "   Model Reward Function Train Val/Opt (%)      Train #opt        Train MPE  \\\n",
      "0    A2C   (+vr_i -wr_i)      73.04 ± 1.73  238.00 ± 19.02  0.2083 ± 0.0169   \n",
      "1    A2C    (+vr_i -w_i)      75.75 ± 0.39  280.90 ± 10.97  0.1786 ± 0.0045   \n",
      "2    A2C    (+v_i -wr_i)      54.11 ± 0.84  154.20 ± 12.41  0.3851 ± 0.0121   \n",
      "3    A2C     (+v_i -w_i)      67.90 ± 7.45  216.40 ± 44.66  0.2550 ± 0.0727   \n",
      "4    A2C       (+_1 -_1)      57.69 ± 8.29  165.30 ± 44.36  0.3565 ± 0.0812   \n",
      "5    DQN   (+vr_i -wr_i)      72.36 ± 1.02  230.70 ± 16.12  0.2138 ± 0.0092   \n",
      "6    DQN    (+vr_i -w_i)      63.98 ± 1.07  189.80 ± 13.05  0.2919 ± 0.0089   \n",
      "7    DQN    (+v_i -wr_i)      57.42 ± 3.18   163.30 ± 9.20  0.3570 ± 0.0303   \n",
      "8    DQN     (+v_i -w_i)      61.79 ± 1.22  188.60 ± 10.59  0.3065 ± 0.0143   \n",
      "9    DQN       (+_1 -_1)      68.75 ± 1.01   208.30 ± 9.34  0.2479 ± 0.0105   \n",
      "10   PPO   (+vr_i -wr_i)      74.16 ± 4.82  269.70 ± 43.81  0.1958 ± 0.0514   \n",
      "11   PPO    (+vr_i -w_i)      75.87 ± 0.44   282.90 ± 8.25  0.1774 ± 0.0044   \n",
      "12   PPO    (+v_i -wr_i)      75.90 ± 0.34  284.90 ± 15.42  0.1775 ± 0.0044   \n",
      "13   PPO     (+v_i -w_i)      75.78 ± 0.52   279.90 ± 8.69  0.1788 ± 0.0048   \n",
      "14   PPO       (+_1 -_1)      75.90 ± 0.55   284.00 ± 8.20  0.1779 ± 0.0046   \n",
      "\n",
      "    Train Imp/Greedy Test Val/Opt (%)    Test #opt         Test MPE  \\\n",
      "0   -0.1932 ± 0.0159     56.84 ± 8.19  0.70 ± 0.78  0.3726 ± 0.0769   \n",
      "1   -0.1636 ± 0.0055     57.26 ± 4.49  0.70 ± 0.64  0.3728 ± 0.0560   \n",
      "2   -0.3700 ± 0.0123     55.73 ± 8.20  0.90 ± 0.83  0.3719 ± 0.0858   \n",
      "3   -0.2399 ± 0.0729    57.18 ± 11.63  1.00 ± 0.63  0.3515 ± 0.1145   \n",
      "4   -0.3414 ± 0.0808     53.88 ± 8.60  0.80 ± 0.75  0.3904 ± 0.0892   \n",
      "5   -0.1988 ± 0.0102     54.67 ± 7.67  0.70 ± 0.78  0.3854 ± 0.1007   \n",
      "6   -0.2769 ± 0.0087     54.01 ± 5.30  0.70 ± 0.64  0.4006 ± 0.0824   \n",
      "7   -0.3419 ± 0.0309    54.81 ± 10.21  0.60 ± 0.66  0.3805 ± 0.1218   \n",
      "8   -0.2915 ± 0.0149     56.76 ± 9.57  0.60 ± 0.66  0.3665 ± 0.0954   \n",
      "9   -0.2329 ± 0.0103    55.72 ± 10.24  0.60 ± 0.66  0.3906 ± 0.0864   \n",
      "10  -0.1808 ± 0.0509     53.14 ± 9.74  0.80 ± 0.87  0.4059 ± 0.1121   \n",
      "11  -0.1624 ± 0.0051    55.87 ± 11.91  0.90 ± 0.70  0.3794 ± 0.1179   \n",
      "12  -0.1625 ± 0.0050     54.32 ± 6.34  0.80 ± 0.60  0.3888 ± 0.0937   \n",
      "13  -0.1637 ± 0.0058    56.13 ± 10.88  0.50 ± 0.67  0.3858 ± 0.0946   \n",
      "14  -0.1628 ± 0.0059     50.93 ± 8.04  0.50 ± 0.67  0.4377 ± 0.1016   \n",
      "\n",
      "     Test Imp/Greedy Training Time (s)  \n",
      "0   -0.3533 ± 0.0746             32.46  \n",
      "1   -0.3536 ± 0.0539             31.61  \n",
      "2   -0.3526 ± 0.0861             34.55  \n",
      "3   -0.3322 ± 0.1138             32.53  \n",
      "4   -0.3712 ± 0.0894             33.46  \n",
      "5   -0.3662 ± 0.0992             37.63  \n",
      "6   -0.3814 ± 0.0808             38.35  \n",
      "7   -0.3613 ± 0.1247             38.16  \n",
      "8   -0.3473 ± 0.0969             37.32  \n",
      "9   -0.3713 ± 0.0863             37.48  \n",
      "10  -0.3866 ± 0.1136             59.67  \n",
      "11  -0.3602 ± 0.1179             58.98  \n",
      "12  -0.3695 ± 0.0908             58.03  \n",
      "13  -0.3666 ± 0.0949             58.58  \n",
      "14  -0.4185 ± 0.1025             56.95  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO integrate the instance generator in this code\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "\n",
    "    N = 50\n",
    "    M = 1000\n",
    "    gamma = 0.99\n",
    "    t_max = 10**4\n",
    "    # t_max = None\n",
    "\n",
    "    env:KnapsackEnv = KnapsackEnv(problem_instance=None, N=N, pad_meta_data_at_back=False)\n",
    "    gen = KnapsackInstanceGenerator(seed=42)\n",
    "\n",
    "    problem_instances = gen.generate('RI', M=M, N=N, R=100)\n",
    "    # print(problem_instances)\n",
    "\n",
    "    KPSolver_A2C = KnapsackA2C(N=N, gamma=gamma, lr_policy=0.001, lr_value=0.001, verbose=False)\n",
    "    KPSolver_PPO = KnapsackPPOSolver(N=N, gamma=gamma, policy_lr=0.001, value_lr=0.001, verbose=False)\n",
    "    KPSolver_DQN = KnapsackDQN(N=N, gamma=gamma, lr=0.001, verbose=False)\n",
    "\n",
    "\n",
    "    results = test_reward_functions(\n",
    "        KPSolver_A2C=KPSolver_A2C,\n",
    "        # KPSolver_A2C=None,\n",
    "        KPSolver_PPO=KPSolver_PPO,\n",
    "        KPSolver_DQN=KPSolver_DQN,\n",
    "        # KPSolver_DQN=None,\n",
    "        M=M,\n",
    "        instance_type=\"RI\",\n",
    "        N=N,\n",
    "        r_range=100,\n",
    "        seed=42,\n",
    "        t_max=t_max,\n",
    "        use_state_aggregation=False,\n",
    "        n_test_instances=5,\n",
    "        verbose=True,\n",
    "        n_runs=10\n",
    "    )\n",
    "    \n",
    "    # Print summary table\n",
    "    print(\"\\nSummary of Results:\")\n",
    "    print(results['summary'])\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABW0AAAIkCAYAAABlZwmZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAADnjElEQVR4nOzdB5wU5f3H8d9e445eQpPeFBQBC4iKEgULGoiCiooKxBbFhi1iA+yYWBLFGgP6NyrR2IiRBNGgKERQEIjSBFQUEFCQfm3/r++Dsze7twd7e3u3e3eft6+RvWd3Z5+ZZ+aZZ37zzDOBYDAYNAAAAAAAAABASkhLdgYAAAAAAAAAAEUI2gIAAAAAAABACiFoCwAAAAAAAAAphKAtAAAAAAAAAKQQgrYAAAAAAAAAkEII2gIAAAAAAABACiFoCwAAAAAAAAAphKAtAAAAAAAAAKQQgrYAAAAAAAAAkEII2iIljBgxwtq2bRvXd8eNG2eBQCDheaquVA4qD1TcNqf1Xbt2bauqyrK+ylI3lIf//Oc/bln0L8ytC5VvVURdCACpY/Xq1e6YM3ny5Cp5vNJyKY9azlRa33/4wx+sqop3myjrtlgefvnLX7oJVTs2kGr1BCoGQVvslSqFWKbqHMCYOnWq9e3b15o0aWI1a9a09u3b21lnnWXTpk2La3733HOPvf766/v83IMPPujW/TvvvFPiZ55++mn3mTfffNMS4bDDDrPLL788LO0f//iHnXzyydaoUSPLzs62/fff366//nrbtGlT3L/z3XffuQPuggULSnUA86aMjAxr0aKFC7h8++23ceVhx44dLg9VadtWEErrp3///nvdXjTNmzevwvNXlZTHNllZeSc30abevXsnNW8fffSR2883b96c1HwAqBwee+wxV3cdccQRyc5KygVI9jVVx4CSljmWdZPKweTy5m8vzZo1q9j7wWDQWrVq5d7/1a9+lZQ8ViXeuYA31apVy3r16mXPPfecVTdqk5e0T8Z7Hp8oscYDUD1kJDsDSG3/93//F/a3KvTp06cXS+/SpUuZfkfBosLCwri+e+utt9pNN91kyaCrzzfccIML2o4ZM8YFbVesWOECqS+99JILZsZTSZ9xxhl22mmn7fVzZ599tvvtF154ocQgnN5TMHXAgAFWVmvXrrX58+fbHXfcEUpTcPaBBx6w7t272+9+9ztr2LChffrpp/boo4+65Z8xY4YdcMABcQVtx48f7xoWPXr0iPl7ylu7du1s165dNmfOHNcQVANw8eLFLqBc2qCt8iCRJxrJ3ObKSuvhvffes3Xr1lmzZs3C3vvrX//q3tf6Q2Ikcpus7M455xw75ZRTwtIaN25syQ7aaj9Xw71+/fph7y1dutTS0ri2DSD8OKm2yccff+zaex07drTqbvDgwWHrYdu2bXbZZZfZ6aef7t7zNG3atEy/06ZNG9u5c6dlZmbG9X19VxdQK9Itt9xiF110UejvuXPn2p/+9Ce7+eabw86dunXrZgcddJBr29eoUcOqI7WJdN7Sp0+fsPSZM2famjVrqu16KQ86t7ruuutC53d//vOfbfjw4bZ79267+OKLrTrRdqXlj6Rz22QqKR5w/vnnV+t6oroiaIu9Ou+888L+VtBBQdvI9GgBLwUwYxVvA0zUAKvoRpjk5+fbnXfeaSeccIL9+9//Lvb+999/X66/v99++9lxxx1nr776qj3++OPFKm/15nv//fftkksuKdP69bz99tuuQXX88ce7v1988UUXsB06dKg7iUlPTw99VgEQ5e3MM890QdyKKh8Fpw8//HD3Wo3kX/ziFzZhwgTX01i9nxMlWdtcIhx99NHupGHKlCl29dVXh9LVIP7ggw/cSdbf//73pOaxKqmobbK8bN++3fXCSIRDDz10n8eOVEKDGIDfqlWr3IUetbsuvfRS1/YZO3ZsheZBHRxyc3NT6qKfAo6aPBs3bnRBW6Xtrc7XxcysrKyYL46p91tZljsZ60znCJF5UNBW6dF6Hvvb0tWNLuq+/PLLbv3429gK5OpOP21XSAzd+eXfN3XepjtFH3rooUoRtNU5uOpC1R9lpW2tMrVNVUdU53qiuqILCcpMjY6uXbvaJ598Yscee6wL1uoKsrzxxht26qmnugCjToA7dOjgAp0FBQV7HbfSP47SU0895b6n7/fs2dMFnPY1bo3+vuKKK9xtBcqbvqsr2NFuddDt7wqqqCGl33nyySdjGgtHjYeffvrJBcGi0XAJfrp6qca9eiMoP7rV58Ybb3Tp/nwrSPLss8+Gbs/Y25iKOshs2bLF3nrrrWLvqaerDmjDhg1zf2tdHnXUUa7nbU5OjmsAvfLKKxYr/YYCsfquqHdagwYNXPlEHjx0m4163i5atCjsN/zbivKieakX4hNPPBFWHipnGTlyZGg9xDNu1DHHHOP+/fLLL0NpOtm5/fbb3fLXq1fPBaT0OfU+9W9/Xg9ALWfk7WvRtg8viO9tq9qetR/4y3dfVq5caSeddJLLk/YZ9dLUbWGifzXPX//611FPfLQsOoncF23n6vmiRrCfgvAqT/1+NO+++65bT8qbeiQqH1988UWxz6kXqcrPvz+V5Pnnn3floO1AvbR15fibb76xeMRa13jb4Oeff+62Z9VXarzef//9xeapQLaucGuZtT+PHj26VOUZ6zYpS5YscVfUtR607lQn+Yc10e372s90MuOvg3Syq33a205EJ8v+XtQKxusCSuvWrUN1j5ZFvY6ija2svOnkqU6dOqH6Q8ut72i/UPqgQYPc+invsdjKcmzw1quC48q3tjP1/FfPJ28/1t0KonrI28+9ccKijWmrfVTrUuWkbUfDO0TWv964x3/729/s7rvvtpYtW7oy7devn+uZB6ByUpBWx0kda1Rf629PXl6eqxfUbomktqLqAN2dVJo2ob89q99SO1af9dqysbbrVNdfddVV7qKhV3/rwn602/KV/pvf/Mb1ivXazn/5y1/KvO68elFtU92tpOOu6lCtmx9++MGtm4MPPtgdg+rWresueH722Wf7HEfUO24p3zpe67Xqe80v8vgfubxeW071sne3hdpSKkN1Pol3HSZyrEodhzQkgHeuonLWevKG7tIFBP2t7UvlrzviIu2rfRELBfPU01m/r7sLdbeQZ9KkSS7f0X5bvQXVdollWCjdjaOh1dQ5yN9m1zZ97rnnRv2OzpnUY1T7j7ZXHeO1X/jbRKVtwyRyH4h12y5tu8Fr/6g8dM6ldl5ZaL107ty5WNtU55EPP/ywWwfKj9aJzjV+/PHH0GeuvfbaYu3QK6+80i2Pv826fv16l6aORrGej0W2+5QXr92ndnxpzzsS9RyLstZFWq9//OMfQ/uuPqe7c72h6fYWDyhpTFsN3eMdI3QuNGrUqGJDf5XmHAippXJ2FUPK0UFWByEFXRRI9G6BUsWiSksVuv5V4EcVtBppv//97/c5XwWWtm7d6g4QqqBUqSjgpBPnffUeVSWuxozGYNUBWgeOIUOG2Ndff+0OLqIGhirJ5s2bu+CcKlUFymK5ZVdBHB0sNaatDk5qDJVElbMaCMqTer7qligFNNUIWrZsWWjMGg07od54OgDrc6IDUEm0LhSg0Xry34LmrTs1sLygsg4OyoOCMDpQquGs4IPGpNUJyN7oZERDPqjxJcuXL3e3DusAogZINBdccIE7IdH8tV14dKBXQEiBFDXQ1EDRMuhqqRpJWjcqA20nWgdekEsnJqXlHdB0kuXRtqfbYPTbupqs7euZZ55xwUrd7qhbhlT+alRE3t7n70kSSeWmg6saxmpA/ve//7V7773XBTZfe+21feZV2562RQWBtJ3rpEzrT8FgrQ9t/9q39J4agf7tTduglivWK8Vq/J544omuceZtX9pelPdo+5XKXvu3rsLr5EQnL4888ojbttST2guqaZvWfLX+9DnlXcsQ7ZZINUpvu+02tx1o3W3YsMHNUxd+tF9G3qq+L6Wpa7QNal2rXPX7OiHQRQY1nryhRLSMaiyrvtCJmhpA2j8137KItk3+73//c+tSDScNu6GGq/YLNfrU61nboNaHGlrqPa/8iOoTbRfaHtQAU2NN1Hj39htRzxWdgGp7Vt2n7VzrWicses9PZaZ9QbcnqoHs3TGhMlKQXduO9kWth33VG5GUh8ieMmqox3MnQCzHhoULF7r1oL9Vl2g71Tav/UXbnz6v+lcXLFQX62RcSqr/dcKhZddyqAy0LrXPq17VNqRy8rvvvvtcUF0Ndl1cUx5V/6puAFD5KHCqekPtFbUh1E7QxSIFDFTPqA5Qu1NBA38PMLXxFDTy2kKxtgk9qm91TFDwVvWUd8yNtV2ntpq+r9tq1cbQ7ebR6m/VcXrfCxSrLtRdVhdeeKE7ll5zzTVlXoe6mKp1o3pR60SvdfzSMivvuoCmfGgdKjio93T83Vf7ScctjTOs45baLLoTTO0bHff2Re0A/a7abGrTqI2oNr7uiintOiwPCtrp2Kvjndp5WsaBAwe6Dg/qHOA9a0L517L4h/aJpX2xLxoaT8dbBYHUSUDbne660zar9p3ajnpP+8chhxwS9l2lKVCk398XbddHHnmkOyZ7bTFtfzp+at/xBwBFQUJt/wryaRtV+/1f//qXuxirwJn2J0+sbZhE7wNqk5Rm246l3aBzFm0LWg7lR7+h9aDzAgWv46G2n9qE/rap6HfUvtaFDLV7dLeBhsBTO/3DDz909Z7aWVrX2tbUTvXaoVoO/eu1Wb3Astr5sZ6P+enigLY/1ZkKTGp5S3PesTeRbVMtl9qnpRVrXaTtSetV27m2TeVb60d3NOuiSmnjAVp2xTE0XKJ+R3WAd3zyyqk050BIQUGgFEaNGqXLaGFpffv2dWlPPPFEsc/v2LGjWNqll14arFmzZnDXrl2htOHDhwfbtGkT+nvVqlVuno0aNQr+8MMPofQ33njDpU+dOjWUNnbs2GJ50t9ZWVnBFStWhNI+++wzl/7II4+E0gYOHOjy8u2334bSli9fHszIyCg2z2huv/1297latWoFBwwYELz77ruDn3zySbHP/d///V8wLS0t+MEHH4Sla53p+x9++GEoTfPS+ojVmWeeGczOzg5u2bIllLZkyRI33zFjxpRYFrm5ucGuXbsGjz/++LB0lUPk78+YMcPNT+Uir7/+uvv7oYce2mve6tatGzz00EOLbSsPPPBAKG337t3BHj16BJs0aeLyJHPnznWfmzRpUkzrQJ/T5995553ghg0bgt98803wlVdeCTZu3DhYo0YN97cnPz/f/abfjz/+GGzatGnwN7/5TShN89E8tX1FitzmFixY4P6+6KKLwj53/fXXu/R33313r/nX+tbnrrzyylBaYWFh8NRTT3XbsfIiS5cudZ97/PHHw74/aNCgYNu2bd139kZlq3lqHTRr1ix45513uvTPP//czXfmzJmhdaky8Hjls2nTprD9Sdv0BRdcEEo77bTT3Lb41VdfhdI07/T09LD1tXr1apem/cVv0aJFbt/zp0fWDSWJta7xtsHnnnsulKbtQetjyJAhobSHH37Yfe5vf/tbKG379u3Bjh07uvT33nsvYdtkv379ggcffHBYPlWWRx11VLBTp05h9a+2U8+1114bPPbYY13ZeNuEyigQCAT/+Mc/7nXd3Hvvve5z/rLytsObbrop7LPe9n355ZeHpZ977rkl7iN+Xn0ebfLWo8pFU6SyHBu0burUqRO2jOLfT37/+9+H1W17qwuvueYa91l/Pb5169Zgu3bt3P5XUFDg0rRM+lyXLl3C6hqVidK1nQOoXObNm+f23+nTp4fqkZYtWwavvvrq0Gf+9a9/FauH5JRTTgm2b98+rjah/tZn//e//xXLUyztOrVJNQ/VX34jRowoVn9feOGFwebNmwc3btwY9tmzzz47WK9evajHkmiitZ+8elHrIXI+OvZ59adHdbKOlXfccUdYWmTb0Dtu+T8nhxxySPCwww4LS4vMk9eW87f95PTTT3fHmHjW4b68/PLLJbYhvHaD/3ik45DSPvroo2LbWU5OTtjx7cknnyw271jbF9F461u/s2bNmlD6f//7X5c+evToUNo555wT3G+//cLK8dNPP42pLe9vdz766KPuuO1tIzrHOe6448LasB7vXOSuu+4Km98ZZ5zh2jfeOWBp2jCx7gPRtsVoYt22Y203aB9Xm0/tcv/nnnrqKfe5aO2oSFqPJ554ottPNWne559/vvu+2pke1U9K++tf/xr2/WnTpoWlf//99+7vxx57zP29efNmV2ep7Pxt1quuuirYsGHDUBss1vMxb13rnFK/5RfreUdJvPojcvLWo1cukftrWeoinRPqc1ofkfzt05LiAZH1hNaJzhVVpv5tTfuSPveXv/yl1OdASD0Mj4CE0BWvaLeEebfSi66g6UqWrsipp5Ju19kXjZfqv+rn9R7TVcV90dUm/1Up9ZJUr1Dvu7oapitgutrsv9KpW9VivdKkq1rq8aUry7q6q9tudZuHxm703zqu3mzqSaFbT7QOvMkbHzbyVpDS0FV3XXlU7w6Pd+u7d2tzZFnoKpuu4Gp9qlfBvvzzn/+0Aw88MNS7Q2Up6sG8N3pfV1Ijxw7y38avXhb6W2MAa9iEslCZ62qrrjTryr96FOgWMN1m5NFtWl4PGPV2US9FXeHUlc1Y1kVJ60fUy9PPG+Q/2vAV0eiqvse7yq/eM9pOZf/993dXb/23ZCr/6gWgst7XkB7+daCrq+rNIJqf1pm/d6ZHDyhYsGCB62Xi792r/UljsnnLrv1J+4D2J92G79F2HznkgrZVrXvlwb8/6Jb+Tp06xbU/lKauUU9cf69kbQ+6mu2vV7Rc6oGv7cijXqfeFe9EbZMqP/X40Lrw8q1Jdy9ovalXu3dboZZHvTR0BV10VV49FpTu9WBQzy2dm/rL0r9udLuV5q8eGvpctNsZI3smeWXs9ZbwlLbHidadbnv0T/E+6GFfxwb13FavZPXe92+PEut+EknrQduJ/yEp2pa0XOpB7d2q59Ex0d/brjTHLwCpRcdJ9d7SLaVePaJ6SL1bvVtf1aZTT1iNGe9vb6mu02fjbROqV57aYJFiadd5Qyl4vTE9ukPMT8cD9bxUD0699udLxyLNO942kp8eduTPt3cO4fUM1brU8U91q251j/U3f/vb34b9rfUQa10b7bvKg9d+jXUdlheVvXqgetQOFG0v/uObl+4td2naF3ujdp2/p6yOg/otr23g3V2nhwj7t13tMypr3eUYK+VVdzqpt7jyrH9LGhpBv6/2bGTbRG1vbcNqG3ufi6UNUx77QGm37X21G3T7vM6XtM36P6c2eml6hupZLGqbalIPS/Xs1G/770xTPaV5qq3vXxc6z9UyeGXtDa2gNpeoZ6fKRT2e1WbVdiZqp6r95LXBSns+pu3IfydUac479kbDE0S2TdU7Nl77qou0jWkdRBsPPZ72qc4Rda6o7dk/Prh6LyvuEXkOGss5EFIPwyMgIXQwjzYYuG6V0NhVajREBu908NuXyJNt7yTdP5ZOrN/1vu99Vwc9NQyiPfm3NE8D1m0dmrR8un1FtzsoaKqDvveEeB2wFMQt6bbbsjy0TAFmBdP0m954NwrGKRji3S4tavjcddddLgAXOY7uvqjC1/J4vGCtF7wtid6PHNtXAfLIBxspGCkKfOi2pHhNnDjRzUvblsafUgMi2sOEdEuzDsgK5mnoB49uXYrHV1995Q6UkduNgpC6rV3v74u+r+EHSlov/oaxgrmap4a/UKNKy6Bb9kpDjWDdaqZxtbTt6NazaNuCl3c1MCOpYaQGkwKBKmvtTwq6RtJ3/Y177Q9qEEf7rMRzu3xp6hoFTCOXVXWDbqf3L7fKM/Jz0dZDWbZJ3faodaGhIjSVVD+ojvUa72r4ahkUcNU+rXpFt2F576mR5g+GaogHDRWhYHFk3Rm5bnRRxX+Rw1sX2j4jb80q7bpQeSuInQj7OjZ4jU/vVr1E0HrwTor9vCeA633/75Xl+AUgdSg4oOCsAra6Pdij+kBtiRkzZrhbdFV/KrCgY6raWarrdZFSx2h/0La0bcKS2iaxtOu8+jtyHpHtFV3o0viHGitTUyz5ike0ZfHGd9SYjFq//vEfveHM9sYbE7Kk9v6+7K2u1vE01nVYXiLz5wXnIm+F99K95S5N+2JvorXV1K7RMAseBfZ0oVuBWg0tpTLVuYief7CvDh5+Kke1E7QP6aK7tgX/xXM/lYvOKSLn7z8ml6YNUx77QGm37X21G7xliiwTtZsjzyH2RnWX6g7lR+eqeq3f8J/Lq55SGzHyPC7aulD71Gvnqx2qwKsmnZ/qb13w0vlGZAC+NOdjkWkqr1jPO/ZGweNEtU1jqYs0TJe2270Nq1gaJZ2nqSy1TUSeg8ZyDoTUQ9AWCRF51Vx04FPvADV4NCanDpaqzHT1TGOn6EC2LyU9HTFygPlEfzceWk41WjTp4KkDkYK4WgdaVl3JfPDBB6N+N94xiES/pSvTTz/9tLuiqQCNDrT+QcV1wNR4R+qVp4aDGlb6nsYHinwgVSQ1MnQw9QaO9zeI9lbB6yCh4Fm03iHlRVcK1UgQXXnVFV01ENQzUVcWRWNaKbit93UVWI0RbSsaCyxyAP7SircHX2kouKqHKahhrLHMtDxa5tIG0NRg0z6pK7Mq45J6MpQH7Q9aV+oFEW0/9coqVqWtayqybtjXNunlTeOXldQzwDsxVCNPjVYFftXrXflV7xs1EK+++mq3z2lfVy9af88O1UnqwaB1od4Qumii3jXaDyLXjb9XSEXS9hBt/Uc+vCFZ9Xs8KkMeAeybLgbqrhMFbjVF0vFYQVvvGK0xK3V8U52vwJbqXf+FtNK2CaO1scvSrovGOxaoB5Z6w0azt3H9YxVtWfS8BAUVdWeExrxVMEPHIbVPynKuUFXq6pLyt698l6Z9kYg8qm2jcxFtj+ptqZ63sT5rwU/zUS/BdevWuY4ppX3GQbzKYx8o7bZdUdui7gjwApXaNlRH6YF3CjB7dw0qfzpH8t/d5+cPTqptq7LXBXPvuQpq1yldf6v9qvn57wIr7flYtLqjvJV0XlfatmkqSfX6DtERtEW50ZMWdRuIehl4g46Lv5dCMungoMBOtKdylvUJ3wrSKGirRr4oiKQrjLr6vK/AXjyBP90arwcS6JY8rV/NQ71//bdiaFnVK9Lfy0+N+1h62erqvf+WYF1h16TB9XWAj3YVXQ8uEDUC/NSIU89Mf29bPXhDvOEXEhH89A786hmjQfP1AAbRgOu68qjt0v87kbeplCYP6vGqxoiC5V5AWxREV0BR7++Lvq/Gjte7Ntp6ETX49PAENaJU7moY62mq8dA2oqvrynPkgP/+ZRPvlnw/BfPV8FNZavtSg8q7Dcov8rvaH9Q4UADSv7ypVNdoudX7QPn0bwvR1kNZtkmvZ4ROtmO50q8Gr4K2WncqM+17CgZoH9UtnApUa9gWjx7SoO1I9ZF6aXv8T2eOdftWI9p/caAs6yKSrvJHuzUrll7q0Xjr1f+E62hKu5+XtB947wOoenS8VZtRd05E0nFHDxtVG0zHQB2DFEBVe0ztJgV8NXSWX2nahCWJtV3n1d86Hvp7pEW2cxWA0fFEwYhE9TqLldplOi7qIUR+aj95D4hMpljXYaopbfuiJNHadWpX+NumojaGek3qYZ+6aKFtqjS3qXv0cDQNm6aHMvmHGolWLro1XHd6+c9DIo/JsbZhymMfSPS27S2TysQbTkXUS1XbZ7xDTum8Qp0fFGTWule7XvWU1q8eZLevgKkXjFXbUg+/8s65VB+q0493l6WGVvDEej5WEpVXrOcd8fJ6Oqu8EtE2Fa1X1duRD5WOFOuxwX+e5u9trSETtE1UdH2O8sGYtij3Kzn+KzeqQHQFNhV4t0Mo8KhAor8R5o2DtDe6bWf27NlR3/O+7zUO1BNWPdt0FTKSbu1QENOjg1rkwWFfdEBV40lXLdXA0YE3chxXVf7+K4O65T7yCcXR6PYS77Y/P91urds9NHZP5BVHjU2rp+7qVuHIsaw0XpF6ofi3Cf2tg693MPcCuqVdD5H0xFr1dFRQU+P+lrRdqkd0ZFlq/NJY83DKKae4fyODp14vmlifMKxAnkf5099qbOvEzk9DIWj8TF2Z1vJ4T6QuLT2ZVI2jvY3dpJNPBQcV9POvCwXDNCaWt+zKhxrn2qbU29ujW0DVOPHTE0v1eQUXI6/s6m8FYJNd12i5VC+oUenf50u6ZS7ebVKBAKVpH/Au8kTe/hXZMNa+q/3caySr14Z612p7U8Pd35Mh2rrRa11siZU3xnfkk5vjvVhQUiNWJ1r+5VVQQxcl4qH6RCcLGpLCvz1GrovS1DXaJvREY39dobpb24Tq34q8qwBAxVAbTUEFXYDWbdqRk4YrUtBIw8949bHSFbjSOJFq8/iHRihtm7AksbbrvKBZ5PHwkUceKTY/tdcUDI52sSvyWJRI+u3ItoCGfoplvNWKEOs6TDWlbV+URNuUvyx0HFS7OfL5H+qFqunPf/6z247UNo08d4iF7kJSoG/cuHFhQ7NFOyZr+/e3neWhhx5y+4aXv1jbMOWxDyR621anILVvdJFI7VyPhuYr6zmT7sZS+9url1RPaf2qh3Ak1Wv+31NHAg2zoXWvdqjOS0XtUQXL1ZbW8Hf+7SHW87GSlOa8I14KiOp3vPF6PWU5v9A2pmX2d7AoqX0aS5kqlqGhELR9+7+vCwUa3iLWc1CkNnraotwoiKArVLrFRIO/6wCqBmwqdb9Xg0CBJx1c9PAd7+CvYKPGCNsbBXC0jDoInXzyye52NlWuOnjoVhDd7qEHlHlBNt0ipwCnBm7X7+m3FKRQug4u3i3UClzqyqYCMN7t0NHGUfTTutXtRLpCKrpF3E8VtuanfOpzGodIPUZ0W9TehjjQyYPyq8ZBJPXy1NVUBX8UQNTfKm/19FOgRGM16SAdOT6plkkBXZ1cqJelgk9a1wp8eJ9VAEe3Q+l3ddVbBy6tg3jGnFVg88wzz3QNGq1/nXjpBExX8rVedBVSv6OAy7Zt20Lf09VbpSl/yqeuhmq7iDZGpq5sazvXMni36qtRq0CntgPvwSV7ox4z6imp+WhZFfhXL2cNgRA5PpLyrfWrhp8aoyWNNxVLY0T7wL7owQT6Hd2Kf+GFF7rtQicr6t3p/74aIFoGNdL0wA416vQ5ja3s385UvurhO2bMGLcdaB2pnFUW6rGkBzvpdr5k1jW6NU91gXqO6CKEgteapxfML4vIbVL7onpk6XZZ/a6ulKuXthqua9asccFLjxeQ1RV1b38XBSi1zajHVc+ePUPpuuVN61vrUycJGkJCJySlGVdVQXv1ylYjVQ1ArW+N4ZjIXka6dVB1lBrg2sZUR2m/1LYTOUZxrNSA1XrVgyG1Tan+0Pam/cqr370LReoJpxNM1UE6SYwcd1vUc0Rj9Glf0HamOkH7uLZbrdNkDCsBoHwpGKugrIYiiEZtQB2j1RvXC87qXx37dFFU9br/DpzStglLEmu7TnWcggQKUCkgo/zOnDkzdCePvzfXfffd5/KjNoiORWoDqTeY2nVql+p1eVC7TO1WPQhJxxfdIaL1WZoxOstTadZhqilN+6Ik2qY0D50naexkrQe1QW+88cZin1WbyWu/xTM0gqek4Qn8dKxW+1rHbx3b1RbXOd0bb7zhhh/wxrAtTRsm0ftAordttVHUflZvWPW0VV2jNoh62Jd1f1HbRuc4qldGjRrlzmX0O7pDTG0mdeDR76tnq84/dP7nH29Y7VMNH6NtzeuhqvaX2lPaVyKHYYv1fGxvYj3viJfOc9Re1zy1n2ub0ljiZRnfW9usjgFqo2pdqg5XT3DFDvSe91DqWOMBOv7ofErrQvPSsUrnCNredT5Qlv0QKSQIlMKoUaMUBQlL69u3b/Cggw6K+vkPP/ww2Lt372BOTk5wv/32C954443Bf/3rX24e7733Xuhzw4cPD7Zp0yb096pVq9xnfv/73xebp9LHjh0b+luvI/Okv5XXSPoN/ZbfjBkzgoccckgwKysr2KFDh+Cf//zn4HXXXRfMzs7e67rIy8sLPv3008HTTjvNzbdGjRrBmjVrunkp37t37w77fG5ubnDChAluXemzDRo0CB522GHB8ePHB7ds2RL63JIlS4LHHnusW2dajsj8luR///uf+7zm/eOPPxZ7/5lnngl26tTJvd+5c+fgpEmToq47/zr6xz/+EQwEAsH169eX+Luvv/568IQTTnDLo3l37NjRrb8NGzYU+6y3rcybNy945JFHunWs33v00UeLffaNN94IHnjggcGMjAyXR+W3JHpPn5k7d26x9woKCly5asrPzw8WFhYG77nnnlCZqby0nJHboHz00UeujLRt+Le7aOtN24PKsl27dsHMzMxgq1atgmPGjAnu2rUruC/67Vq1agW//PLL4Iknnui2o6ZNm7rfUf6jufzyy10eXnjhhWCstHynnnrqXj9T0rp85513gkcffbTbLuvWrRscOHBg8PPPPy/2/ZkzZ4bWWfv27YNPPPFE1PUlf//734N9+vRxy65J26X226VLl4atm8hyKUtdU1J9Fe13vvrqq+CgQYNcefziF78IXn311cFp06YVm2dZt0lR2V9wwQXBZs2aue2nRYsWwV/96lfBV155pdj3mzRp4ubt3y9nzZrl0o455phin1c59e/fP1i7dm23HBdffHHws88+K7ZfedthNDt37gxeddVVwUaNGrnPqPy/+eabYvVxNHurz/2ef/55t81o2+nRo4crv7IcG2Tx4sXB008/PVi/fn1X3xxwwAHB2267Lewzd955p1vfaWlpbh76jZKOFyqnM844IzS/Xr16ufrDT9uG5vPyyy9HXQ97q8sApBbVddrXt2/fXuJnRowY4ertjRs3ur/VzlAbQPv7XXfdFfU7sbYJS2rPlqZdp7xrHg0bNnTHAbVbdZzV5+67776wz+q4os8q/1omHZP69esXfOqpp2JeZ2r/RdbHJdWLonaS2o3Nmzd3x3C1NWbPnu2O15r2VoeWdNwq6dwg2vlDZHvVO357x4LSrsO90fKX1IaI9rsltduibRclHR9L074oaX4PPPCA2ya0ramdoTZENGvXrg2mp6cH999//32ui1jaS37R1sXWrVuDo0ePdu0+LZv2B+VX+2C8bZhY9oFYj+exbtulbTc89thj7nxD5XH44YcH33///WLzLM169EyePLnY72m5VTcp/3Xq1AkefPDBro393XffhX134sSJ7ruXXXZZWLran0rX+bZfrOdj+2pDlua8I9Le2r0e1Q9Dhgxx5wKqpy+99FLXtixLXaS2v5ZH9bby3bhx4+CAAQOCn3zyyT7jAdHqCdG5tOanbVbnkCqHyHhAac6BkFoC+l+yA8dAqlHPPz2NPto4OdWJrlrOmzfP9RpNBN2mtXHjxn2OM4l908PIdOuLHtSQiN6fAACgelDPOd0NpmG1dKcUSo91WJza+LozSUOo6QFcAICy414+VHu61dtPgVqN46oAY3WnW4qijbmD5NJYqDpJ0O16BGwBAECs7VzRLe4a0sX/8E6UjHUYGw37pKE+dPs3ACAxGNMW1Z7GABoxYoT7V0+D1OD3GtA72lhN1Y3GgUTq0BhKGt9IYwVrXLWrr7462VkCAAAp7P7773djs2u8RD0ISOOfa1IbT89jwL6xDvfu3Xffdc+3uPvuu93dino4JwAgMQjaotrToN16uIxuM9dDfPSwJT3gp1OnTsnOGhDGe+CbHjymAezVExoAAKAkegDS9OnT3VPg9YCf1q1bu4eI6gFOiA3rcO/0sK2PPvrIPVRPD20CACQOY9oCAAAAAAAAQAphTFsAAAAAAAAASCEEbQEAAAAAAAAghVT5MW0LCwvtu+++szp16lggEEh2dgAAAFAGGtlr69attt9++7mnt1cHtGcBAACqX3u2ygdt1cDlqZ4AAABVyzfffGMtW7a06oD2LAAAQPVrz1b5oK16JHgrom7dusnODgAAAMrgp59+cgFMr41XHdCeBQAAqH7t2SoftPVuIVMDl0YuAABA1VCdhgmgPQsAAFD92rPVYyAwAAAAAAAAAKgkCNoCAAAAAAAAQAohaAsAAAAAAAAAKaTKj2kLAAAAVAcFBQWWl5eX7GxUSllZWZaWRn8WAACQOgjaAgAAAJVYMBi0devW2ebNm5OdlUpLAdt27dq54C0AAEAqIGgLAAAAVGJewLZJkyZWs2bNfT6JGOEKCwvtu+++s7Vr11rr1q1ZfwAAICUQtAUAAAAq8ZAIXsC2UaNGyc5OpdW4cWMXuM3Pz7fMzMxkZwcAAIAHkQEAAACVlTeGrXrYIn7esAgKggMAAFh1D9qqUXTbbbe58aNycnKsQ4cOduedd7pxuTx6ffvtt1vz5s3dZ/r372/Lly9PZrYBAACAlMIt/WXD+gMAAKkmqUHbCRMm2OOPP26PPvqoffHFF+7v+++/3x555JHQZ/T3n/70J3viiSfsv//9r9WqVctOOukk27VrVzKzDgAAAAAAAABVb0zbjz76yH7961/bqaee6v5u27atvfjii/bxxx+Hetk+/PDDduutt7rPyXPPPWdNmza1119/3c4+++xkZh8AAAAAAAAAqlbQ9qijjrKnnnrKli1bZvvvv7999tlnNmvWLHvwwQfd+6tWrXJPw9WQCJ569erZEUccYbNnz44atN29e7ebPD/99JP7Vw8V0CRpaWlu0pNiNXm8dA3b4B+ioaT09PR0dyuVN19/erQxsUpKz8jIcPP1p2u++nxkHktKZ5lYJpaJZWKZWCaWiWWqLsuUar799lv73e9+Z2+//bbt2LHDOnbsaJMmTbLDDz/cva9lGTt2rD399NPuoWFHH320u9usU6dO5Zqvtje9ZRVp9X17OmKUltr1ffr0sZNPPtneeqsozzo3uO+++9z5wcaNG10Hj9/+9rd29dVXh30/NzfXdfT461//6oZR0/i+BxxwgF100UV23nnn8WAxAABQKSU1aHvTTTe5oGrnzp1dI1wN87vvvtuGDRvm3lfAVtSz1k9/e+9Fuvfee238+PHF0ufPn++GVvCeDqvxcxUU3rBhQ+gzLVu2dJOCyFu2bAmlt2/f3j2Rd/HixbZz585QuvJdv359N2//SUW3bt3cwwzmzZsXlgc13NWoXLhwYShNy92zZ0/3e0uWLAmla/ze7t27uwbqypUrw4LWXbp0cU+3XbNmTSidZWKZWCaWiWVimVgmlqk6LNOmTZsslfz4448uCHvccce5oK3WpQKHDRo0KDbc17PPPuue5aBnOmi4r88//9yys7OtunvmmWfsyiuvdP9q29xvv/1c+ieffOK2s+eff95atWrl7tK75JJL3DZyxRVXuM9o+9G6VIBXz8ZQWdStW9fmzJljf/jDH+yQQw6xHj16JHkJAQAASi8Q9HePqGAvvfSS3XDDDfb73//eDjroIFuwYIFdc801rqft8OHDXcNMDS813vQgMs9ZZ53leltMmTIlpp62auSpga8GXGXsTVIVe8iwTCwTy8QysUwsE8vEMsWzTOqpqoCogrpe2y7ZnRA+/PBD++CDD6K+r+VQEPK6666z66+/3qUp7+qEMHny5JiG+1J7VgH3aMus5zwo2K5gcGQAuDL0tN22bZtr5yugr97ICvDffPPNJX5+1KhR7lkY7777biggPmbMGPd9BWj98vLyXFDX67ixN3tbjwAAAIm0t7ZdyvS0VcBWDV2vsXrwwQfbV1995XrLKmjbrFkzl75+/fqwoK3+LumKeY0aNdwUSY1/TX7eCUck7wQi1vTI+caTrhORaOkl5bG06SwTy1RSOsvEMu0t7ywTy8QysUypuEyp5M0333Q9Pc8880ybOXOmtWjRwi6//HK7+OKLK2y4LwWGvclbd8nolxHtN0vKi5euThjqoa2h0nS33ejRo935gd6P9nmd3DRs2DA0Tw2JoHWrcwP/73jbj3cBIJa8a/Kv4+p2QYRlYplYJpaJZWKZWCarsGWKRVKDthrzK7Lh7c+8rnQrcDtjxoxQkFaN1v/+97922WWXJSXPAAAAgEfDT2h82muvvdb1EJ07d65dddVVbjgIdUIo7+G+NMyFepOqXa2TAv2uJvUcrWj6ff/vqp2v8WV10uMPQqu9r+Eu1BNW4/wq4L19+3Y3xISCsu+884579oXHW6b//Oc/Lsj7yiuvuM+ro4aGotCdefrbo56yOlHSOvGfhOk3lSf/Z0XrVOcfWo8a8qO6Dj3CMrFMLBPLxDKxTCyTpdRwX0kdHmHEiBGuUfbkk0+64RG0QjRO1W9+8xubMGGC+4z+1QMI/GOAaUXEOgZYrF2OkTxr1651U0nUy9rf0xoAAFRfqda2U+NdjXUN6+VR0FbBW/WkLe/hvhSYXL16ddht/V6v1HZj/mkVadW9p5Sqp61OYnSnnU64dNIkGttWZfvcc8+Fff5///ufC+pq3d56662hdAWF1av5j3/8Y0y/u6/hEVq3bh1aj9Wx1w/LxDKxTCwTy8QysUzpKTPcV1J72j7yyCMuCKtbyL7//ns33tell15qt99+e+gzN954o7sarmCuFkpPlp02bRpjTVUhCtpH603i0fhm48aNq9A8AQAAxEKB2AMPPDAsTb0//v73v7vXFTHcl04AvMkTObxARSjpN0tK/8tf/uJOiDSkhEcnN1r2Rx991AXnRZ01+vXr584HdO7gp2EVli5dGvU3SrMOvPXnX8cHP3uwJdOi4YuKpTGcCsvEMrFMe0tnmVgmlskqzTLFIqmDgtWpU8cefvhhN46tuiJ/+eWXdtddd7keC/4FvOOOO9ztY7oCrp65apyh6lCgXk8HnjVrVihNr5WmSe8DAACkIvWiVdDQT7fftWnTpthwXx5vuK8jjzzSqisFa9Wb9oEHHnAPI/amzz77zHXkePHFF8N62GqoibvvvrvYfM4991x3fqA79iJp+IXIoRAAAAAqi6T2tAX8wx/4G9XqeRLLk34BAACSSQ/O0vir99xzjxvy4OOPP7annnrKTV4HhGuuucZ1TOjUqVNouC8FJk877TSrrv7xj3/Yjz/+aBdeeGGoR61nyJAh9swzz7g77I4//nj3oDeNGeyNAaweMRq3TrRu33rrLdcT984773TfUccQjTenYdY0n5J6NAMAAKQygrYAAABAnPSQiddee83GjBnj7g5TUFZ3kg0bNizpw32tvu9US1UKpvbv379YwNYL2t5///1uyDQ9SOT55593k0e9mDWOr2gohenTp9tDDz3khty6/vrr3Ti3GqJC49927dq1QpcLAAAgUZL6ILLq+LAKlEwnM7Vr13avt23bRk9bAABQTHVs2+1tmb0HaPkfRIbSi7YeU3FMWwAAUH3as/S0BQAAAAAAVUIyL7hwsQVAIiX1QWQAAAAAAAAAgHAEbQEAAAAAAAAghTA8AgAAAAAAAFIaY42juqGnLQAAAAAAAACkEIK2AAAAAAAAAJBCGB4BAAAAAAAAQFIw9EV0BG0BlKu1a9e6qSTNmzd3EwAAAAAAAPYgaAugXD355JM2fvz4Et8fO3asjRs3rkLzhMQgIF91UbZVG+ULAAAApD6CtgDK1aWXXmqDBg2ynTt3Wp8+fVzarFmzLCcnx72uzIGB6h74ICBfdVG2VRvlCwAAAKQ+grYAypUXuNy+fXsorUePHlarVi2r7Kp74KMqB+SrO8q2aqN8q5Fx9Sr497aU6uMjRoywZ5991r3OyMiwhg0bWrdu3eycc85x76WlFT0z+aOPPrK77rrLZs+e7bbdTp062ciRI+3qq6+29PT00OcCgYDVqFHDli5dam3atAmln3baaVa/fn2bPHlyQhYVAACgvBG0BVAhA4QX7i4Mve71116WVqPoRKyyDhBe1QIfiSjbS/53SVHZLqq8ZVvdVeWLLVUR+y4qs5NPPtkmTZpkBQUFtn79eps2bZoLxL7yyiv25ptvumDua6+9ZmeddZYL0r733nsu+PrOO+/YjTfe6IK4f/vb31yw1qPXt99+eyggDAAAUBkRtAWAn7W96a24vleYuyv0+py/r7O0rOyf/yp56IRoVt93qlUmeZvzLH9zvhXmFQV+dn6909Iy9wR+MupnWGb9zCTmEGUN7FXFiy1g30VqUa/YZs2audctWrSwQw891Hr37m39+vVzvWLV6/biiy92F0mfeuqp0Pcuuugia9q0qUtX0Hbo0KGh96644gp78MEH7YYbbrCuXbsmZbkAAADKiqAtgHJVlYMD+dt+sIJtP1gwLzeUlrt+pQUys9zr9NoNLaN2Q6uqfnjvB9vwxoawtFV3rwq9bvzrxtb09KZWWVXnMYur8n6Lqr/vovI7/vjjrXv37vbqq69ao0aNbNOmTXb99dcX+9zAgQNt//33txdffDEsaHv00UfbsmXL7KabbrJ//OMfFZx7AACAxCBoC6BcVeXgwLYFb9uWD18MS1v/wo2h1/WOPsfq9xlmVVXD4xpa3UPqlvi+AnuVWXUes7gq77eo+vsuqobOnTvbwoULXfBVunTpUuLnvM/43XvvvW583A8++MCOOeaYcs8vqsewMonCHSgAgFjQKgdQrqpycKB2jwGW0/GIEt9XT9uqTD0tq3Jvy6o2ZnFpVOX9FlV/30XVEAwGw8ap1d8lycrac4eL34EHHmgXXHCB62374Ycflls+AQAAygtnXSmgOt+Ci6qvKgcHMqr48AfVXXV+GFdV3m8BVA5ffPGFtWvXzjp16hT6+6ijjor6OdXN0ehuCQ2f8Prrr5d7fgEAABItvieKIOG34B522GElTnofAAAAqA7effddW7RokQ0ZMsROOukka9iwoT3wwAPFPvfmm2/a8uXLbcSIEVHn06pVK/dQsptvvtkKCgoqIOcAAACJQ0/bFFCdb8EFAABA9bV7925bt26dC6quX7/epk2b5saj/dWvfuWGN0hPT3cdGM4++2y75JJLXBC2bt26NmPGDLvhhhvs4osvtlNOOaXE+Y8ZM8aefvppW7VqVdjDygAAAFIdQdsUUJ1vwQUAAEA5GbfFUp2CtGoHZ2RkWIMGDax79+72pz/9yYYPH25paXtuCjzjjDPsvffes7vvvts9VOynn35y6RMmTLAbbyx6AGg06qX7u9/9zvW2BQAAqEwI2iJlnsZauLsw9LrXX3tZWo34Ru/gaawAAACpb/LkyW6KhYK1CvDKrl277Ne//rX77siRI61x48Z7fWCZettqAgAAqEwY0xYAAABApZGdnW1vvPGGGz7h/fffT3Z2AAAAygU9bQEAAABUusDtTTfdlOxsAAAAlBuCtrC1a9e6aV9j7gIAAAAAAAAofwRt4Z7IO378+BLfHzt2rI0bN65C8wQAAAAAAABUVwRtYZdeeqkNGjTIdu7caX369HFps2bNspycHPeaXrYAAAAAAABAxSFoW07a3vRWqb9TmLsr9LrLbdMsLSs7rt9efd+ppfq8N/zB9u3bQ2k9evSwWrVqxfX7AAAAAAAAAOKXVobvAgAAAAAAAAASjKAtAAAAAAAAAKQQhkeoisbVi+97ucGi13c3N8sKxDefdq3j+x4AAAAAAAAAetoCAAAAAAAAQCqhpy0AAABQBR387MEV+nuLhi8q1edHjBhhzz77rHudmZlprVu3tgsuuMBuvvlmmzVrlh133HGhzzZp0sT69Oljv//97619+/ah9I8++sjuuusumz17tu3cudM6depkI0eOtKuvvtrS09MTuHQAAAAVi562AAAAAJLi5JNPtrVr19ry5cvtuuuus3HjxrnArGfp0qX23Xff2csvv2z/+9//bODAgVZQUODee+2116xv377WsmVLe++992zJkiUuWKsg7tlnn23BoG/oLwAAgEqGnrYAAAAAkqJGjRrWrFkz9/qyyy5zgdg333zTjjzyyFAP2/r161vz5s3t9ttvt2HDhtmKFStcoPbiiy+2QYMG2VNPPRWa30UXXWRNmzZ16X/7299s6NChSVs2AACAsiBomwLyt/1gBdt+sGBebigtd/1KC2RmudfptRtaRu2G5fb7a7cW2tptQduZV9QbYcG6AsvJ3PMgsua1A9a8Dp2yAQAAUL5ycnJs06ZNJb4nubm59u9//9t97vrrry/2OfXG3X///e3FF18kaAsAACotgrYpYNuCt23Lhy+Gpa1/4cbQ63pHn2P1+wwrt99/8pNcGz+zKGAsfSbtCL0e2zfLxv0yu9x+HwAAANWbhjKYMWOG/etf/7Irr7yy2PsaQuEPf/iDtWjRwg444AD75z//6dK7dOkSdX6dO3e2ZcuWlXu+AQAAygtB2xRQu8cAy+l4RInvq6dtebr0sCwbdEBmie+rpy0AAACQaP/4xz+sdu3alpeXZ4WFhXbuuee6cW3nzp3r3tcwCAro7tixw7p3725///vfLStrz91owri1AACgqkpq0LZt27b21VdfFUu//PLLbeLEibZr1y73QIKXXnrJdu/ebSeddJI99thjbpyqqiSjnIc/2BcNfdC8TtJ+HgAAANXUcccdZ48//rgLxO63336WkRF+evLBBx9Y3bp13di2deoUNVg1/IF88cUXdtRRRxWbr9IPPPDAClgCAACA8pHUgUp1BV23OnnT9OnTXfqZZ57p/h09erRNnTrVPS125syZ7smxgwcPTmaWAQAAACRIrVq1rGPHjta6detiAVtp166ddejQISxgKyeeeKI1bNjQHnjggWLf0YPMli9fbuecc0655h0AAKDK9rRt3Lhx2N/33Xefa5T17dvXtmzZYs8884y98MILdvzxx7v3J02a5MatmjNnjvXu3TtJuQYAAACQ7GDvk08+aWeffbZdcskldsUVV7geuRoX94YbbrAzzjjDzjrrrGRnEwAAoPKPaaunwD7//PN27bXXWiAQsE8++cSNbdW/f/+wBwroKvzs2bNLDNpqGAVNnp9++sn9m5+f7yZJS0tzk8bN0uTx0gsKCsLGxyopPT093eXVm68/3SxomRH9mPMKzTQ6bEax9IAFLBiWrp/JDwYszYKWHi09ELR031CzhUGzgmDA0gNByw8UjfOVFiywNCuwgkCmBd2ve+n5lmaFxdLTg3kuL/55eOlapoJi6XqAWcDNx5NpmZZnmk/AMnybWFDzNf1umqVbetR0j76n7xdYgfus/z2lFVph6DOR6aUrJ3OfjyVdvT80X3+65qvPR25LJaVXzLZXvssUWX5uncdRTpHp2ga0LWj78YtM95a5PMopMy1YbH9K8+1nBUG9F7CMQNAC/vRCrYfi6fmF2r4DofmGp1uxOsIr42Rte/51X9Zy8kSrC0pKVx5ScX/yp+t1sssp3mVS2SSinGKpyyPrCPdvJa73Ur0ud3lNQDnFW5f7819R5YTYLBq+yKoyBWbfe+89u/vuu+2YY45xQ6t16tTJbrnlFrvmmmvcNgMAAFBZpUzQ9vXXX7fNmzfbiBEj3N/r1q1zY1vVr18/7HMaz1bvleTee++18ePHF0ufP3++uyLv9fBVj95Vq1bZhg0bQp/Rgw406Umz6unrad++vRtHa/HixbZz586wILLyp3n7Tyq6devmgjEjOoWfVExenma1M8zOaFcYFsidvDzdWtQyG9CyKH1zrtnLq9KtU72gHdus6ARvzQ6zt79Jt0MaBe3QRkXpS7cE7P11ATu6adDmNRxVtEw/zrGWP862ZU0H2paabYqWacN0a7J1sS1uca7tzCoaT7fz2let/s6vbH6bi60grShA2+2b5ywrf6vNa1c0bzl81UTLzahjC1tdEEobnJNhU3ZMsWbpzaxfdr9Q+pbCLTZ151Rrn9HeetcoCrqvLVhrM3bNsAMzDrTFttilnVHzDPs6/WubkzvHemb1tI6ZHUOfX5i70BbmLbS+2X2teXrzUPqc3XNsRf6KUpWTtrF58+aFL9Phh7uLCAsXLgyl6SSxZ8+ebrtYsmRJKD0nJ8c9FGPjxo22cuXKUHq9evVcr3AN6bFmzZpQekVse+W9TF0zu1q3rG6h9BV5K+IqpwE5A6xeWr1QurYBbQuDaw62TN9FgKk7ptqO4A4bWmuo+9tbtvIoJ2+f9e9PB9Qr2s8+3RSwTzYG7ISWhdayZtH61Wf1ndPbFlp933WNt9ek2ZrtZsM6KCBclP7KqjTbll+8jlBZJnPb89ZxIsrJM2X7FKsZqGkDaw4MpeUF86LWEdrOU3F/+vTTT0Npeq3AQGWsI1Q2iSinfdXl0eoIqcz1XqrX5ZKIcoq3LvfnsyLKadOmTWHzQOU1efLkEt/75S9/GdNDxlQnT5s2LcE5AwAASL5AMEUeuaqHjKkxrzFsRcMijBw5MqzXrPTq1cs9sGDChAkx97Rt1aqVa+DrlqmK6iHTbsxbSetpuzR7ZFJ72vZq2yqu3lm222zxpXuCtt2e7GaBGvH1tF1w3gJ6Z/nyqPGiv//++xKXqVmzZi6YEOsydX+2e1J72n487ONyK6cut09Lak/bZXefmvBlKs221/P5nkntaTv3vLkpuT/pOOJdQNTFRe9YUtnqiF5/7ZW0nrYLhi9ImV6pqV5O8SzTIX89JKk9becOm1uh5aT9sEGDBi6o6+2PVZ3qIV1EiLbM6l2qCwga+zU7Oztpeazsoq3Hg589OKl5quo9pZOJsq3aklm+lG35Yt+tuqpb2f60l7ZdyvW0/eqrr+ydd96xV199NZSmQJJ6Xqhh7u9tu379evdeSWrUqOGmSGr8Rz7cwDuJiuSdQMSaHu2hCQpkKkgbSadq0dOjf16BoGh3ASpwpMBSJAWaMlwg1aIEXS3m9GjzKDk9GJauk/w9qcHQ67C8//xftHSPf7iEgp//i+QCvWUup9Kl64QxWnpJ21Jp0xOz7YWna2zoaL3PPWPHjrVx48bFnMeSyq+05VRSerRtxp8eucyJLCddQIncnxSoLZb3YGDPzhxjeuR8i9KL5zvRyxRruraxaOs+3nLyK6kuiEz3tvNU3p/0OtnlFO8y+dd1Wcoplro8WnpFltO+0lO5nOJNT1Q5xVOXR8tPeZcTAAAAUNWlRNBWDxhTT79TT93Ty0wOO+wwy8zMdA8TGDJkiEtbunSpff3113bkkUcmMbdItLzNeZa/Od8KfRGsnV/vtLSfuyFm1M+wzPrhvcIQu0svvdQGDRrkbsnt06ePS5s1a5a7zVSaNy+63RUAAAAAAADJl/SgrW4rVNB2+PDhYb0p1E34wgsvdA8ma9iwoesufOWVV7qAbUkPIUPl9MN7P9iGN4rGBJRVd68KvW7868bW9PSmSchZ1aCgrKbt27eH0nr06BEa4xkAAAAAAACpJelBWw2LoN6zv/nNb4q999BDD7lb4NTTVuPUatzbxx57LCn5RPlpeFxDq3vIXsbwqJ/0zRQAACClpchjKiot1h8AAEg1SY+GnXjiiSU2kvQQgIkTJ7oJVZeGPmD4AwAAgNLTcGKyY8eO0NBHKD09S2NvY08DAABUu6AtgFIaVy++7+X6Lo7c3dwsK/rDsfapXev4vgcAABJOQUY9tPf77793f9esWTP0wETEPlzbhg0b3Lor6WF5AAAAFY1WCQAAAFCJNWvWzP3rBW5RehqSrXXr1gS8AQBAyiBoCwAAAFRiCjTqoaNNmjSxvLy8ZGenUsrKynKBWwAAgFRB0BYAAACoIkMlMCYrAABA1UDQFqji1m4ttLXbgrYzr2hM2wXrCiwnc8/tf81rB6x5HXqWoOpre9NbcX2vMHdX6HWX26ZZWlZ2XPNZfd+pcX0PAAAAAFD9ELQFqrgnP8m18TP3PBHZ02fSjtDrsX2zbNwv4wtCAQAAAAAAIPEI2gJV3KWHZdmgAzJLfF89bQEAAAAAAJA6CNoCVZyGPmheJ9m5AAAAAAAAQKwYyBIAAAAAAAAAUghBWwAAACBO48aNs0AgEDZ17tw59P6uXbts1KhR1qhRI6tdu7YNGTLE1q9fn9Q8AwAAIPURtAUAAADK4KCDDrK1a9eGplmzZoXeGz16tE2dOtVefvllmzlzpn333Xc2ePDgpOYXAAAAqY8xbQEAAIAyyMjIsGbNmhVL37Jliz3zzDP2wgsv2PHHH+/SJk2aZF26dLE5c+ZY7969k5BbAAAAVAYEbQEAAIAyWL58ue23336WnZ1tRx55pN17773WunVr++STTywvL8/69+8f+qyGTtB7s2fPLjFou3v3bjd5fvrpJ/dvfn6+myQtLc1NhYWFbvJ46QUFBRYMBveZnp6e7oZ08ObrTxd9PpZ0Ba41X3+65qvPR+axpPRUWyaXVwtYhu+UKWhBy7d8S7M0S7f0faYXWqEVWIFL03sepek9zVu/ES3dn3/KKbHLlMhy8qdrG9C2kGmZYXmMTPeWmXIqn2Xy1nNZy8mTZ3nF6oKS0pUHyqn8lkllk4hyircup5w45iZyf4oFQVugnHm3SpakefPmbgIAAJXPEUccYZMnT7YDDjjAHe/Hjx9vxxxzjC1evNjWrVtnWVlZVr9+/bDvNG3a1L1XEgV9NZ9I8+fPt1q1arnXjRs3tg4dOtiqVatsw4YNoc+0bNnSTcuWLXM9fT3t27e3Jk2auHzt3LkzLIis/Gne/pOKbt26ubzPmzcvLA+HH3645ebm2sKFC0NpOvno2bOn+70lS5aE0nNycqx79+62ceNGW7lyZSi9Xr16rrexhopYs2ZNKD3VlkmapTezftn9QulbCrfY1J1TrX1Ge+tdoyjovrZgrc3YNcO6Zna1blndQukr8lbYnNw51jOrp3XM7BhKX5i70BbmLbS+2X2teXpRO3DO7jm2In+FDcgZEJZPyimxy5TIcqqXVi+Urm1A28LgmoMtM1AUUJq6Y6rtCO6wobWGur+9ZaOcymeZvPVc1nLyTNk+xWoGatrAmgNDaXnBPJuyY0qxOkLrj3Iqv2VS2SSinOKtyyknjrlZCSqnTZs2WSwCQX+IvApSzwRtpFpRdevWrbDfbXvTW5Ysq7PPtWQ6uF3rpP7+ouGLLNUeUBLtxMszduxY95nYZ1jU4EiGqly+ydxvZfV9pyb19w9+9uAqve/GW76Fubvsm4fOcK9bjX7F0rKy45pPdS7fVKuXq5qqvu+mStsuVps3b7Y2bdrYgw8+6BrmI0eODOs1K7169bLjjjvOJkyYEHNP21atWrkGvrfM9M4q/2U65K+HJLXXz9xhcxO+TFWxnOJZpu7Pdk9qT9uPh32c8GWqiuUU7zL1+muvhJRTPD045543l3Iqx2VS2Sazp+1n539GOXHMtUSUk9qLDRo02Gd7lp62QDm79NJLbdCgQe5qVJ8+fVyaHlCiEzmhly0AAFWHembsv//+tmLFCjvhhBNczws1zP29bdevXx91DFxPjRo13BRJjX9Nft5JVCTvBCLW9Mj5xpOuE5Fo6SXlsbTpyVgmnRjqhD9S4c//xZpe8PN/kXTSGY3So+WHckrMMiWynKKJts340yPzSjkldpki13+85RRLXRCZ7uWBciqfZfKv67KUU7x1OeXEMTeR5RQLgrZAOfOGP9i+fXsorUePHqHbGwEAQNWxbds2+/LLL+3888+3ww47zDIzM23GjBk2ZMgQ9/7SpUvt66+/dmPfAgAAACUhaAsAAADE6frrr7eBAwe6IRE0XpyGPVIvlHPOOccN43DhhRfatddeaw0bNnS3v1155ZUuYFvSQ8gAAAAAIWgLAJUUD7kDgOTTQz0UoNV4s3qoh4ZCmjNnjnstDz30kLsFTj1tNU7tSSedZI899liysw0AAIAUR9AWACqpJ598MrEPuQMAlNpLL7201/ezs7Nt4sSJbgIAAABiRdAWACopHnIHAAAAAEDVRNAWACopHnIHAAAAAEDVlJbsDAAAAAAAAAAAihC0BQAAAAAAAIAUwvAIAJAqxtWL73u5waLXdzc3ywrEN592reP7HgAAAAAASCh62gIAAAAAAABACiFoCwAAAAAAAAAphKAtAAAAAAAAAKQQxrQFACAFrV271k0lad68uZsAAAAAAFUPQVsAqKTWbi20tduCtjOv6EFkC9YVWE7mngeRNa8dsOZ1uKGisnryySdt/PjxJb4/duxYGzduXIXmCQAAAABQMQjaAkAl9eQnuTZ+Zm5YWp9JO0Kvx/bNsnG/zE5CzpAIl156qQ0aNMh27txpffr0cWmzZs2ynJwc95petgAAAABQdRG0BYBK6tLDsmzQAZklvq+etqi8vOEPtm/fHkrr0aOH1apVK6n5AgAAAACUP4K2AFBJaeiD5nWSnQsAAAAAAJBoDHYIAAAAAAAAACmEoC0AAAAAAAAApBCCtgAAAAAAAACQQhjTFgCAijCuXnzfyw0Wvb67uVlWnA+Ya9c6vu8BAAAAACocPW0BAAAAAAAAIIUQtAUAAAAAAACAFELQFgAAAAAAAABSCEFbAAAAAAAAAEghSX8Q2bfffmu/+93v7O2337YdO3ZYx44dbdKkSXb44Ye794PBoI0dO9aefvpp27x5sx199NH2+OOPW6dOnZKddQAAys3arYW2dlvQduYVPYhswboCy8nc8yCy5rUD1rwO114ro7Vr17qpJM2bN3cTAAAAgOorqUHbH3/80QVhjzvuOBe0bdy4sS1fvtwaNGgQ+sz9999vf/rTn+zZZ5+1du3a2W233WYnnXSSff7555adnZ3M7AMAqrD8bT9YwbYfLJiXG0rLXb/SAplZ7nV67YaWUbthuf3+k5/k2viZRb8tfSbtCL0e2zfLxv2S42Bl9OSTT9r48eNLfF8Xq8eNG1eheQIAAACQWpIatJ0wYYK1atXK9az1KDDrUS/bhx9+2G699Vb79a9/7dKee+45a9q0qb3++ut29tlnJyXfAICqb9uCt23Lhy+Gpa1/4cbQ63pHn2P1+wwrt9+/9LAsG3RAZonvq6ctKqdLL73UBg0aZDt37rQ+ffq4tFmzZllOTo57TS9bAAAAAEkN2r755puu1+yZZ55pM2fOtBYtWtjll19uF198sXt/1apVtm7dOuvfv3/oO/Xq1bMjjjjCZs+eHTVou3v3bjd5fvrpJ/dvfn6+myQtLc1NhYWFbvJ46QUFBS5gvK/09PR0CwQCofn6082Clhlx12peoZlOsTOKpQcsYMGwdP1MfjBgaRa09GjpgaCl+87XC4NmBcGApQeClh/IKsp7sMDSrMAKApkWdL/upedbmhUWS08P5rm8+OfhpWuZCoqlqxdYwM3Hk2mZlmeaT8AyfJtYUPM1/W6apVv6PtMLlT8rcGl6z6M0vad56zci00tXTuY+H0t6RkaGm68/XfPV5yO3pWjp/t9Xmv/vUm17gayElJNbpmCuK39/uuar+RRqCwlkFEtPVDlFpmsb0Lag7ccvMt1bb+VRTplpwWL7U5pvPysI6r2AZQSCFvCnF2o9FE/PL1RpBELzDU+3YnXEnk8lppwKLd0KA0XlpHpA9YHS9F60OsK/7staTp5odUFJ6SqzWPenuOpyC5aqnOr0ONlyOvYqVmfr8/p6jboNLcP3nX3V5f79NZZyalw3yxrXLV5O/jq7sBR1ucomEeUUT13u/i3XY27F1eX+PMa7TLqzSNOuXbtCn+natavVqlUrlPfIPO5tmVxek3TMVbq/TCqqnAAAAICqLqlB25UrV7rxaa+99lq7+eabbe7cuXbVVVdZVlaWDR8+3AVsRT1r/fS3916ke++9N+oth/Pnzw+dDOlEqUOHDi4ovGHDhtBnWrZs6aZly5bZli1bQunt27e3Jk2a2OLFi12vGE/nzp2tfv36bt7+k4pu3bq5YMyITuEnFZOXp1ntDLMz2hWGBXInL0+3FrXMBrQsSt+ca/byqnTrVC9oxzYrOvFbs8Ps7W/S7ZBGQTu0UVH60i0Be39dwI5uGrR5DUcVLdOPc6zlj7NtWdOBtqVmm6Jl2jDdmmxdbItbnGs7s4pu7+289lWrv/Mrm9/mYitIKzrZ7/bNc5aVv9XmtSuatxy+aqLlZtSxha0uCKUNzsmwKTumWLP0ZtYvu18ofUvhFpu6c6q1z2hvvWv0DqWvLVhrM3bNsK6ZXa1bVrdQ+oq8FTYnd471zOppHTM7htIX5i60hXkLrW92X2ueXtQbac7uObYif0Wpyknb2rx588KX6fDDLTc31xYuXBhK00liz5493XaxZMmSULp6RXXv3t02btzotmf/xYUuXbrYd999Z2vWrHFp/jytXr3atm/fHt+2125UQsopvTDXeq6eaFtyWtuS5oOLlin3B+u+5lnbWOdAW9n4hKJl2vGVdVn3asLKaUDOAKuXVi+Urm1A28LgmoMt0xecnLpjqu0I7rChtYa6v73yKo9y8vZZ//50QL2i/ezTTQH7ZGPATmhZaC1rFq1ffVbfOb1todX3xcvfXpNma7abDeuggHBR+iur0mxbfvE6ouDrrISV03cNetmaBkX7WeOti63Dhum26hfH24Y6XaPWEUNrdU5YOXmmbJ9iNQM1bWDNgaG0vGBe1DpC23ms+1M8dbnq09KVU0PbVrfhPurywpjr8nktRiWknOKty4fWzElIOcVTl0t5HnMrsi5PZDtCdxt5Pv3001BP29IukyTrmKs6wp/PiiinTZs2hc0DAAAAqIoCQX9XkAqmxrsa6x999FEoTUFbBW/Vk1bpGvNWJ0v+WwXPOuss19tiypQpMfW01UmRGvh169atsJ627ca8lbSetkuzRya1p22vtq2S2tN2wXkLUrJ3loK0OpH1tkvv5LzU297dzZPa07Z7u7ZJ7Wn78bCPy62cutw+Lak9bZdlDUtqT9uebVsnrJzi6cE597y55drbcf9bpyWknOKty5fljExIOcVbl6tuTlZP2wXDF9DTNkq6etrWqVPHvdbDVv09bUuzTIf89ZCk9rSdO2xuhZaT1pWef6Cgrte2q+rUbtBFhOq0zKng4GcPTurvLxq+KKm/X5VRtlVbMsuXsi1f7LtVV3Ur259ibNsltaetArEHHnhgWJp6tPz97393r5s1a+b+Xb9+fVjQVn/36NEj6jxr1Kjhpkhq/Gvy806iInknELGmR853j4A7sY+kU7Xo6dE/rwBDtLsAFThSYCmSAk0K8BTLuwvmWczp0eZRcnowLF0n+XtSg6HXYXn/+b9Y0wt+/i+STjrLXk6lS9cJY7T0krYlf7r/e0qLNp+Ytj3fui5LOXkCJaQrEJQWJT1R5VRSerRtxp8eud4SWU4KukXuTwrUFst7MOCNZRBTeuR8i9Ij8p3AcvKCf8XSfw7+RasLoq37eMvJr6S6IDLd285j2Z9iSY/cn1SfJqKc4q3LMxJUTvHW5f51XZZyircuL99jbsXV5YlcJuXDn89Y6reS0pN1zFV6tPyUdzkBAAAAVV1SW73qRbt06dKwNN1S2KZNm9BDyRS4nTFjRlg0+r///a8deeSRFZ5fAAAAAAAAAChvSe1pO3r0aDvqqKPsnnvucUMefPzxx/bUU0+5yethcc0119hdd91lnTp1ckHc2267zfbbbz877bTTkpl1AAAAAAAAAKh6QVs9ZOK1116zMWPG2B133OGCsg8//LANG6ZxHfe48cYb3Vigl1xyiRvDrE+fPjZt2jTLzs5OZtYBAAAAAAAAoOoFbeVXv/qVm0qi3rYK6GoCAAAAAAAAgKqOJzkAAAAAAAAAQAohaAsAAAAAAAAAKYSgLQAAAAAAAACkEIK2AAAAAAAAAJBCCNoCAAAAAAAAQArJSHYGgMqm7U1vxfW9wtxdodddbptmaVnZcc1ndXxfAwAAAAAAQCVB0BYAAKAsxtWL73u5waLXdzc3ywrEN592reP7HgAAAICUxfAIAAAAAAAAAJBC6GkLAACAauWLL76wl156yT744AP76quvbMeOHda4cWM75JBD7KSTTrIhQ4ZYjRo1kp1NAAAAVGP0tAUAAEC18Omnn1r//v1dcHbWrFl2xBFH2DXXXGN33nmnnXfeeRYMBu2WW26x/fbbzyZMmGC7d+9OdpYBAABQTdHTFgAAANWCetDecMMN9sorr1j9+vVL/Nzs2bPtj3/8oz3wwAN28803V2geAQAAACFoCwAAgGph2bJllpmZuc/PHXnkkW7Ky8urkHwBAAAAkRgeAQAAANXCvgK2mzdvLtXnAQAAgPJC0BYAAADVjsasnTJlSujvs846yxo1amQtWrSwzz77LKl5AwAAAAjaAgAAoNp54oknrFWrVu719OnT3fT222/bgAED3Li3AAAAQDIxpi0AAACqnXXr1oWCtv/4xz9cT9sTTzzR2rZta0cccUSyswcAAIBqjp62AAAAqHYaNGhg33zzjXs9bdo069+/v3sdDAatoKAgybkDAABAdUdPWwAAAFQ7gwcPtnPPPdc6depkmzZtcsMiyPz5861jx47Jzh4AAACqOYK2AACgWlm7dq2bStK8eXM3oWp76KGH3FAI6m17//33W+3atV26to3LL7882dkDAABANUfQFgAAVCtPPvmkjR8/vsT3x44da+PGjavQPKHiZWZm2vXXX18sffTo0UnJDwAAAOBH0BYAAFQrl156qQ0aNMh27txpffr0cWmzZs2ynJwc95petlXXm2++GfNntY0AAAAAyULQFgAAVCve8Afbt28PpfXo0cNq1apVIb+/dmuhrd0WtJ15wVDagnUFlpMZ2JO/2gFrXodnxZaH0047LezvQCDgHjzm/9vDw8gAAACQTJwRAAAAVKAnP8m1w57abn0m7Qil6bXSNOl9lI/CwsLQ9O9//9sF699++23bvHmzm/75z3/aoYceatOmTUt2VgEAAFDN0dMWAABUam1veiuu7xXm7gq97nLbNEvLyo5rPqtL+bVLD8uyQQdklvi+etqi/F1zzTX2xBNPhIbIkJNOOslq1qxpl1xyiX3xxRdJzR8AAACqN4K2AAAAFUhDHzSvk+xc4Msvv7T69esXS69Xr56tXr06KXkCAAAAPAyPAAAAgGqnZ8+edu2119r69etDaXp9ww03WK9eveKe73333efGxlVPXs+uXbts1KhR1qhRI6tdu7YNGTIk7HcBAACASARtAQBAtZK/7QfbvW6F5a5fGUrTa6Vp0vuo+v7yl7/Y2rVrrXXr1taxY0c36fW3335rzzzzTFzznDt3rj355JPWrVu3sPTRo0fb1KlT7eWXX7aZM2fad999Z4MHD07QkgAAAKAqYngEAABQrWxb8LZt+fDFsLT1L9wYel3v6HOsfp9hScgZKpKCtAsXLrTp06fbkiVLXFqXLl2sf//+rqdsaW3bts2GDRtmTz/9tN11112h9C1btrgg8AsvvGDHH3+8S5s0aZL7rTlz5ljv3r0TuFQAAACoKgjaAgCAaqV2jwGW0/GIEt9Pr92wQvOD5FFw9sQTT3RTWWn4g1NPPdUFff1B208++cTy8vJcuqdz586uV+/s2bOjBm13797tJs9PP/3k/s3Pz3eTpKWluamwsNBNHi+9oKDAgsHgPtPT09PdevDm608XfT6W9IyMDDdff7rmq89H5rGk9FRbJpdXC1iG75QpaEHLt3xLszRLt/R9phdaoRVYgUvTex6l6T3NW78RLd2ff8opscuUyHLyp2sb0LaQaeEPm4xM95aZciqfZfLWc1nLyZNnecXqgpLSlQfKqfyWSWWTiHKKty6nnDjmJrKcYkHQFgAAVCsZtRu6CZgxY4abvv/++2KNZw2fEKuXXnrJPv30Uzc8QqR169ZZVlZWsYeeNW3a1L0Xzb333mvjx48vlj5//nyrVauWe924cWPr0KGDrVq1yjZs2BD6TMuWLd20bNky18vX0759e2vSpIktXrzYdu7cGRZAVt40b/9JhYZ4UL7nzZsXlofDDz/ccnNzXS9lj04+NEawfs/rtSw5OTnWvXt327hxo61cuTLsYW/qaaxhItasWRNKT7Vlkmbpzaxfdr9Q+pbCLTZ151Rrn9HeetcoCrivLVhrM3bNsK6ZXa1bVtHwGCvyVtic3DnWM6undczsGEpfmLvQFuYttL7Zfa15evNQ+pzdc2xF/gobkDMgLJ+UU2KXKZHlVC+tXihd24C2hcE1B1tmoCigNHXHVNsR3GFDaw11f3vLRjmVzzJ567ms5eSZsn2K1QzUtIE1B4bS8oJ5NmXHlGJ1hNYf5VR+y6SySUQ5xVuXU04cc7MSVE6bNm2yWASC/hB5jNRbQI3MHTt2uIJu2DB1T3zUM0EbqVZU3bp1K+x32970liXL6uxzLZkObtc6qb+/aPiilCzbwtxd9s1DZ7jXrUa/YmlZ2XHNh/JdVCX3W6FsU3PfTZTqXL6Ubfmq6vtuebXtFBS94447XEO7efPmxYZEeO2112KazzfffOPmoWEWvLFsf/nLX1qPHj3s4YcfdsMijBw5MqznrOhhZ8cdd5xNmDAhpp62rVq1cg18b5lTrYdMVez1c8hfD0lqr5+5w4ouAlBOiV2m7s92T2pP24+HfZzwZaqK5RTvMvX6a6+k9bSde95cyqkcl0llm8yetp+d/xnlxDHXElFOmzdvtgYNGuyzPRtzT9utW7fa888/73oSfPzxxy6KrB/XDyoKr9vKLrnkEhdJBgAAAFLZE088YZMnT7bzzz+/TPPR8AfqqXvooYeG0tQ4f//99+3RRx+1f/3rX67drMa5v7ft+vXrrVmzZlHnWaNGDTdFUuNfk593EhXJO4GINT1yvvGk67wgWnpJeSxtejKWSSeGOuGPVPjzf7GmF/z8XySddEaj9Gj5oZwSs0yJLKdoom0z/vTIvFJOiV2myPUfbznFUhdEpnt5oJzKZ5n867os5RRvXU45ccxNZDnFIqZPPfjgg9a2bVv30ASNx/X666/bggULXHdpjcU1duxYF4FW4Pbkk0+25cuXx/TjAAAAQDIokHrUUUeVeT79+vWzRYsWubaxN6nnrR5K5r3OzMx0wzB4li5dal9//bUdeeSRZf59AAAAVE0x9bTV+FzqLXDQQQdFfV+3d/3mN79xPRYU2P3ggw+sU6dOic4rAAAAkBAXXXSRG7rgtttuK9N86tSpY127dg1L07izjRo1CqVfeOGFdu2117ohxXQL3JVXXukCttEeQgYAAADEHLR98cUXY1pbuo3rt7/9LWsWAAAAKW3Xrl321FNP2TvvvOPGolVv2Mg7zRLloYcecrfBDRkyxI1Ve9JJJ9ljjz2WsPkDAACg6ol5TNuSHkimIRI0btcBBxwQdewtAAAAINXoCb96WJjoSch+kQ8lK63//Oc/YX9nZ2fbxIkT3QQAAACUa9BWQyCcffbZLnCr8Ww1sO5zzz3nxrQFAAAAUtl7772X7CwAAAAAJYrtcWV6Klth+BPZrrnmGvvrX//qnpb7ww8/2F133WWXXXZZrLMDAAAAUsKaNWvcBAAAAFS6oO0RRxxhn376adgTd1u3bh36W681NhgAAACQ6tQh4Y477rB69epZmzZt3FS/fn278847i3VWAAAAAFJ2eIRHH33UPWW3b9++rlft2LFj7bDDDnNj2WqIhCVLltgjjzxSvrkFAAAAEuCWW26xZ555xu677z47+uijXdqsWbNs3LhxriPC3XffnewsAgAAoBrLKE1P27lz59r999/vgrX6d+nSpfbf//7XPYisZ8+e1qJFi1L9uBrF48ePD0tTEFgBYFGD+brrrrOXXnop7Em7TZs2LdXvAAAAAH7PPvus/fnPf7ZBgwaF0rp16+bas5dffjlBWwCI17h6yf39dkV3BANAtRgeQdLT023MmDH21ltvuV61GsNWAdzTTjut1AFbz0EHHWRr164NTerh4Bk9erRNnTrVXn75ZZs5c6Z99913Nnjw4Lh+BwAAAPDomQydO3culq40vQcAAABUip628r///c/1gj344INt+vTprofCMccc43rDqkdCXBnIyLBmzZoVS9+yZYu7Ze2FF16w448/3qVNmjTJunTpYnPmzLHevXvH9XsAAABA9+7d3fBff/rTn8LSlab3AAAAqpVk9pKnh3zZgrYPPvig3Xrrre62seXLl7vxvy6++GI79dRT7dprr7X/+7//s6eeesoFdEtD89pvv/0sOzvbjjzySLv33nvdQ80++eQTN1Zu//79w3o+6L3Zs2eXGLTVMAqaPD/99JP7Nz8/302SlpbmJj1kwv+gCS9dwz0Eg8F9pqvncSAQCM3Xn24WtMyIfsx5hWYBrfRi6QELWDAsXT+THwxYmgUtPVp6IGjpmtnPCoNmBcGApQeClh/IKsp7sMDSrMAKApkWdL/upedbmhUWS08P5rm8+OfhpWuZCoql55qWSvPxZFqm5ZnmE7AM3yYW1HxNv5tm6Za+z/RC5c8KXJre8yhN72ne+o3I9NKVk7nPx5KuCwyab2ZaMK5yKvR9T+WU4fu7IKgyDFhGIGgBX7kWFGo9hKerbBJRTm6Zgrmu/P3pmq/mU6gtJJBRLD1R5RSZrm1A24K2H7/IdK8c91VO/nSVvz4fuc9Hpntl69+f0vzlUYpycnktVGkEwraZonQrVkfs+VRiyqnQ0q0wUFROqgdUHyhN70WrI/zrvqzl5IlWF5SUrjKLpZxCeS9tXW7BhJRTvHW5f38tSznFW5erbBJRTvHU5e7fKnrMVR3hredkHHM9yTrmKt1fJok+5pZUlyeChvpSO/add95xbVBRG/Obb76xf/7znwn5DQAAAKDcg7Zq2GpYhOOOO86++uorO/nkk13Q9he/+IU999xzruftWWedZV988YWVZpzcyZMnu3FsNTSCxrdVz93FixfbunXrLCsryz3F10/j2eq9kijoGzlOrsyfP99q1arlXjdu3Ng6dOhgq1atsg0bNoQ+07JlSzctW7bM9fT1tG/f3po0aeLytXPnzrAgsvKneftPKhTY1snjiE7hJxWTl6dZ7QyzM9oVhp1UTl6ebi1qmQ1oWZS+Odfs5VXp1qle0I5tVnTSumaH2dvfpNshjYJ2aKOi9KVbAvb+uoAd3TRo8xqOKlqmH+dYyx9n27KmA21LzTZFy7RhujXZutgWtzjXdmY1LFqmta9a/Z1f2fw2F1tBWtHJYrdvnrOs/K02r13RvOXwVRMtN6OOLWx1QShtcE6GTdkxxZqlN7N+2f1C6VsKt9jUnVOtfUZ7612jKOi+tmCtzdg1w7pmdrVuWd1C6SvyVtic3DnWM6undczsGEpfmLvQFuYttL7Zfa15evNQ+pzdc2xF/opSlZO2sXnz5oUv0+GHW25uri1cuDCUppNEjdus7cJfrqUpp9zdhXbHz+/3bhK0rk2K5vPppoB9sjFgJ7QstJY1i/KiMlXZnt620Or/XBzz0kclpJzSC3Ot5+qJtiWntS1pXjTsSE7uD9Z9zbO2sc6BtrLxCaH0eju+si7rXk1YOQ3IGWD10oqu5Gkb0LYwuOZgy/QFJKbumGo7gjtsaK2he5b/5/LaVzl5Y2O7ZcrJcb2mNm7caCtXrixapnr1XO99Db2yZs2aUNn696cD6gXjKid5e02ardluNqyDAsJF6a+sSrNt+cXriIKvsxJWTt816GVrGhTtZ423LrYOG6bbql8cbxvqdI1aRwyt1Tlh5eSZsn2K1QzUtIE1B4bS8oJ5UesI7buxlFNomUpZl2s/TUQ5xVuXz2sxKiHlFG9dPrRmTkLKKZ66XKrqMVd1hOrlRJVTPHW52dSkHXNVR/iPo4k+5karyzdt2mSJoIfr6vkMel6C9zsahkt3j6lDAQAAAJBMgaC/G8teKFj6t7/9zTVwddKsHrD+hrT34DD1mI3X5s2brU2bNq5XrxrmI0eODOs1K7169XKB4wkTJsTc07ZVq1augV+3bt0K62nbbsxbSev1szR7ZFHek9Drp1fbVkntabvgvAXl2tN2/1veiq+nbe4uW/nAme5122tftowa2XH14Pyixsik9rTt3q5tUnvafjzs43Lradvl9mlJ7Wm7LGtYUnva9mzbOqk9beeeN7dce9ruf+u0pPa0XZYzMqk9bVU3J6un7YLhC6rsMVd1hOrlZPa0PaRts6T2tJ07bG6F9rRVe7FBgwYuqOu17ao6tWd1Aas6LXMqPMzo4CTfqrlo+KKk/n5VdvCzpbs7NNGqfNlW4323ypdtkrHvVt19t7odc3+KsW0Xc0/bG264wU455RTXw0G9Yu65555inylLwFbUM2P//fe3FStW2AknnOB6Xqhh7u9tu379+qhj4Hpq1Kjhpkhq/Gvy804MI3knELGmR853j4A7YYyk08/o6dE/rwBDtLsAFTjSSWMknUQqwFMs7+4E0GJOjzaPktODYek6yd+TGgy9Dsv7z//Fml7w83+RdNJZ9nIqXbpOGHXCX5pyyt36gxVs+8GCeUXraOe6VRbI3HMynl67oWXU3tPzSsGBn++RD+NP96/rspRTaJlKSFeAIS1KeqLKqaT0aNuMPz2yXEoqp2jpJe3zXnpk2Wp/UqC2WN5jKKewvEfZZvakR+Q7geXkBf+Kpf8cVIpWF0Rb9/GWk19JdUFkurfv7qucYk2PrAu0nyainOKtyzMSVE7x1uX+dV2Wcoq3Lq+qx1zVEZFlW5HH3KLU5BxzlR6tTBJ1zC2pLk8EPSuhdu3aduaZey6oevQA3B07dtjw4cMT8jsAUi+ox9iJAIDKIOag7fXXX28nnXRS6EFk0Z62W1bbtm2zL7/80s4//3w77LDDLDMz02bMmGFDhgxx7+sWtq+//jo07hhQGWxb8LZt+fDFsLT1L9wYel3v6HOsfh/1sAQAABVFQ2o9+eSTxdI1PMcll1xC0BYAgEhccAFSM2grCtaW9kFj+woEDxw40A2JoLEKx44d63rWnHPOOa6b8IUXXugectawYUPXXfjKK690AduSHkIGpKLaPQZYTscjSnxfPW0BAEDFUkeAdu3aFUtXu1TvAQAAACkftL3vvvvsqquuspo1fU/eKcF///tf9xAZPY13XzQ2rgK0Gm9WD5Tp06ePzZkzx72Whx56yN0Cp562GqdWPX31sAigMsnwDX8AAABSg3rU6gFobdu2DUv/7LPPrFGjRknLFwAAABBz0Pbzzz93vQ405pd6xupJv15gVQ+a0PuzZs2y559/3vWYfe6552Jauy+99NJe39cYuRMnTnQTAAAAkCjqOKBOCXXq1LFjjz3Wpc2cOdOuvvpqO/vss5OdPQAAAFRzMQVtFYRVr4NHH33Uzj33XPeUMw1joAd+6UENcsghh9hFF11kI0aMKPMDyQAAAIDydOedd9rq1autX79+oQeeFRYW2gUXXBD1gbsAAABASo5p2717d3v66afdAxt0K9lXX31lO3futF/84hfWo0cP9y8AAABQGWRlZdmUKVNc8FadE3JyctyzG3R3GQAAAFCpHkQmGmNWQVpNAAAAQGWmMW2DwaB16NAh1OMWAAAASLa0ZGcAAAAAqGga4uvCCy90D9o96KCD7Ouvv3bpV155pXsILwAAAJBMBG0BAABQ7YwZM8YNi/Cf//wn7HkM/fv3d8MmAAAAAMnEPWAAAACodl5//XUXnO3du7cFAoFQunrdfvnll0nNGwAAAEBPWwAAAFQ7GzZssCZNmhRL3759e1gQFwAAAKh0Qds1a9a4CQAAAKhMDj/8cHvrrbdCf3uB2j//+c925JFHJjFnAAAAQBzDIxQWFtpdd91lDzzwgG3bts2l1alTx6677jq75ZZbLC2NzrsAAABIbffcc48NGDDAPv/8c8vPz7c//vGP7vVHH31kM2fOTHb2AAAAUM2VOsKqwOyjjz7qnqo7f/58N6nR+8gjj9htt91WPrkEAAAAEqhPnz62YMECF7A9+OCD7d///rcbLmH27Nl22GGHJTt7AAAAqOZK3dP22WefdbeNDRo0KJTWrVs3a9GihV1++eV29913JzqPAAAAQMJ16NDBnn766WRnAwAAACh7T9sffvjBOnfuXCxdaXoPAAAASHWffvqpLVq0KPT3G2+8YaeddprdfPPNlpubm9S8AQAAAKUO2nbv3t0NjxBJaXoPAAAASHWXXnqpLVu2zL1euXKlDR061GrWrGkvv/yy3XjjjcnOHgAAAKq5Ug+PcP/999upp55q77zzTujJuhr765tvvrF//vOf5ZFHAAAAIKEUsO3Ro4d7rUBt37597YUXXrAPP/zQzj77bHv44YeTnUUAAABUY6XuaasGrRq5p59+um3evNlNgwcPtqVLl9oxxxxTPrkEAAAAEigYDFphYaF7rc4Ip5xyinvdqlUr27hxY5JzBwAAgOqu1D1tZb/99uOBYwAAAKi0Dj/8cLvrrrusf//+NnPmTHv88cdd+qpVq6xp06bJzh4AAKhm2t70VlJ/f3V2Un8e8QZtFy5caF27drW0tDT3em+6desWyywBAACApNHwB8OGDbPXX3/dbrnlFuvYsaNLf+WVV+yoo45KdvYAAABQzcUUtNV4X+vWrbMmTZq414FAwN1SFknpBQUF5ZFPAAAAIGHU0WDRokXF0n//+99benp6UvIEAAAAlCpoq9vEGjduHHoNAAAAVDbqdKBOBnuTnc29gQAAAKgkDyJr06ZNqIH71VdfWYsWLVyaf1Ka3gMAAABS0UEHHWQvvfSS5ebm7vVzy5cvt8suu8zuu+++CssbAAAAUKYHkR133HG2du1aN1SC35YtW9x7DI8AAACAVPTII4/Y7373O7v88svthBNOcA8j0wN21bv2xx9/tM8//9xmzZpl//vf/+yKK65wgVsAAACgUgRtS7qtbNOmTVarVq1E5QsAAABIqH79+tm8efNcYHbKlCn217/+1d0ptnPnTvvFL35hhxxyiF1wwQXuAWUNGjRIdnYBAABQjcUctB08eLD7VwHbESNGWI0aNULvqXftwoULedIuAAAAUl6fPn3cBAAAAFT6oG29evVCPW3r1KljOTk5ofeysrKsd+/edvHFF5dPLgEAAAAACdH2preS+vured4fAACJC9pOmjTJ/du2bVu7/vrrGQoBAAAAAAAAAFJhTNuxY8eWRz4AAAAAAAAAAPEEbeWVV16xv/3tb/b1119bbm5u2HuffvppovIGAAAAAAAAANVOWmm/8Kc//clGjhxpTZs2tfnz51uvXr2sUaNGtnLlShswYED55BIAAAAAAAAAqolSB20fe+wxe+qpp+yRRx5xDyC78cYbbfr06XbVVVfZli1byieXAAAAQIJ9+eWXduutt9o555xj33//vUt7++237X//+1+yswYAAIBqrtTDI2hIhKOOOsq9zsnJsa1bt7rX559/vvXu3dseffTRxOcSAAAASKCZM2e6u8SOPvpoe//99+3uu++2Jk2a2GeffWbPPPOMGw6sumt701tJ/f3V2Un9eQBIOdTLQPVS6p62zZo1sx9++MG9bt26tc2ZM8e9XrVqlQWDwcTnEAAAAEiwm266ye666y53x5juHvMcf/zxofYtAAAAUGmCtmrIvvnmm+61xrYdPXq0nXDCCTZ06FA7/fTTyyOPAAAAQEItWrQoattVvW03btyYlDwBAAAAcQ+PoPFsCwsL3etRo0a5h5B99NFHNmjQILv00ktLOzsAAACgwtWvX9/Wrl1r7dq1C0vXg3ZbtGiRtHwBAAAAcQVt09LS3OQ5++yz3STffvstjVwAAACkPLVff/e739nLL79sgUDAdUr48MMP7frrr7cLLrgg2dkDAABANVfq4RGiWbdunV155ZXWqVOnRMwOAAAAKFf33HOPde7c2Vq1amXbtm2zAw880I499lj3wN1bb7012dkDAABANRdzT9sff/zRLr/88tDDGvTwhiuuuMLGjRtnf/jDH6xbt242adKk8s0tAAAAkABqzz799NN222232eLFi13g9pBDDqETAoBKr+1NbyX191dnJ/XnAaD6BW0VpNXYtSNGjLB//etf7gFk06ZNc0MlvPvuu9a7d+/yzSkAAACQYK1bt3YTAAAAUCmDtm+//bZNnjzZjj/+eNfDtn379tajRw93axkAAABQmQSDQXvllVfsvffes++//z70oF3Pq6++mrS8AQAAADEHbb/77jvr0qWLe922bVvLzs628847rzzzBgAAAJSLa665xp588kk77rjjrGnTpu5hZAAAAEClC9qqN0JGRtHH09PTLScnp7zyBQAAAJSb//u//3O9aU855ZRkZwUAAAAoW9C2X79+ocDtzp07beDAge4hDn6ffvpprLMEAAAAkqJevXpuuC8AAACgUgdtx44dG/b3r3/964Rm5L777rMxY8bY1VdfbQ8//LBL27Vrl1133XX20ksv2e7du+2kk06yxx57zN3CBgAAAMRr3LhxNn78ePvLX/7C3WMAAACoOkHbRJo7d64bU6xbt25h6aNHj7a33nrLXn75ZdcbQg9AGzx4sH344YfllhcAAABUfWeddZa9+OKL1qRJE/e8hszMzLjuHnv88cfdtHr1avf3QQcdZLfffrsNGDDA/U0nBAAAAJRr0La8bNu2zYYNG2ZPP/203XXXXaH0LVu22DPPPGMvvPCCHX/88S5t0qRJ7mFoc+bMsd69eycx1wAAAKjMhg8fbp988ol7sG5ZHkTWsmVLd8dYp06d3HBizz77rLsjbf78+S6ASycEAAAAVMqg7ahRo+zUU0+1/v37hwVt1YjOy8tz6Z7OnTtb69atbfbs2SUGbdWDQZPnp59+cv/m5+e7SdLS0txUWFjoJo+XXlBQ4Brd+0rXw9jUwPfm6083C1pmWnje8grNdDqQUSw9YAELhqXrZ/KDAUuzoKVHSw8ELd13blEYNCsIBiw9ELT8QNE4w2nBAkuzAisIZFrQ/bqXnm9pVlgsPT2Y5/Lin4eXrmUqKJaea1oqzceTaZmWZ5pPwDJ8m1hQ8zX9bpqlW/o+0wuVPytwaXrPozS9p3nrNyLTS1dO5j4fS7rGc9Z8M9OCCSmnNF96QVDvBSwjEDT/OWNBodZDeLrKJhHl5JYpmOvK35+u+Wo+hdpCAhnF0hNVTpHp2ga0LWj78YtM98pxX+XkT1f56/OR+3xkule2iSgnl9dClUYgbJspSrdidcSeTyWmnAot3QoDReWkekD1gdL0XrQ6wr/uy1pOnmh1QUnpKrNYyimU99LW5RZMSDnFW5f799eylFO8dbnKJhHlFE9d7v6tosdc1RHeek7GMdeTrGOu0v1lkuhjbkl1eSIokPqvf/3L+vTpU6b56BkPfnfffbfreatOBgro0gkBAAAAlS5oq9vEdOuZhkeItG7dOveQs/r164elqyeE3ivJvffe68Yni6TeDrVq1XKvGzdubB06dLBVq1bZhg0bQp9Rw1rTsmXLXE9fjx5SoVvnFi9e7B7A5g8iK3+at/+kQsM86ORxRKfwk4rJy9OsdobZGe0Kw04qJy9Ptxa1zAa0LErfnGv28qp061QvaMc2KzppXbPD7O1v0u2QRkE7tFFR+tItAXt/XcCObhq0eQ1HFS3Tj3Os5Y+zbVnTgbalZpuiZdow3ZpsXWyLW5xrO7MaFi3T2let/s6vbH6bi60grehksds3z1lW/lab165o3nL4qomWm1HHFra6IJQ2OCfDpuyYYs3Sm1m/7H6h9C2FW2zqzqnWPqO99a5RdJKytmCtzdg1w7pmdrVuWUVDZKzIW2FzcudYz6ye1jGzYyh9Ye5CW5i30Ppm97Xm6c1D6XN2z7EV+StKVU7axubNmxe+TIcfbrm5ubZw4cJQmk4Se/bs6bYLf7mWpZwOqFeU/ummgH2yMWAntCy0ljWL8qLP6junty20+j8Xx7z0UQkpp/TCXOu5eqJtyWltS5oPDqXn5P5g3dc8axvrHGgrG58QSq+34yvrsu7VhJXTgJwBVi+tXihd24C2hcE1B1umLyAxdcdU2xHcYUNrDd2z/D+X177KacmSJUXLlJNj3bt3t40bN9rKlSuLlqlePXfi/N1339maNWtCZZuIcpK316TZmu1mwzooIFyU/sqqNNuWX7yOKPg6K2Hl9F2DXramQdF+1njrYuuwYbqt+sXxtqFO16h1xNBanRNWTp4p26dYzUBNG1izKKiRF8yLWkdo342lnELLVMq6XPtpIsop3rp8XotRCSmneOvyoTVzElJO8dTlUlWPuaojVC8nqpziqcvNpibtmKs6wn8cTfQxN1pdvmnTJkuEVq1aWd26dRMyL4+WWT1qt2/fbkceeSSdELggkrIXROiEUHU7IYjKN1mdEFRHBBNUTvFe3PbWM50Q6IRQUnq8dXn5HnP37LvJOuaK1jXHXEupTgiBoH8LqkDffPONa6hPnz49NJbtL3/5S+vRo4d7EJl6JIwcOTKswSq9evWy4447ziZMmBBzI1eNcjXwvYZ5RTRy2415K2mN3KXZI4vynoQdrlfbVkntabvgvAXl2tN2/1veSmoj94saI5PayO3erm1SG7kfD/u43Bq5XW6flrByiqfxtCxrWFJ72vZs2zph5RRP42nueXPLtZG7/63TktrIXZYzMqmNXNXNyWrkLhi+oMoec1VHqF7eUx7JaeQe0rZZUhu5c4fNrdBG7ubNm61BgwYuqFuWoKt62j7yyCP2xBNPuDFty2LRokUuSKvxa2vXru3asaecckrc7VnvIWmR3nnnnWKdEL788suoF0S++OKLqBdEPvvss6gXRNSJIjLQ3v2ud0t1QaRlrWDUCyIH1CuMekHksF8URrkgkmbHNit0F0T6pX8adkHki2aDo14Q+azl8KgXROa2HVWmCyK/CUx1FyuiXRDpmNEx6gWRbpndol4Q6Z3VO+oFEc072gWRgTkDbVDrQTGVU2kviGgfmvja+wkrp/CL22k2oFVBlIvbaXZmu4LQRVOVbaLKSRe3N+e0iXpx+/s6XaNe3B62/68SVk7RLm4PrTl0rxe3+7bsG1M5Rbtw9f3330e9uK0L297F7RlffJ+Qciq6uB2wEZ0KYr64/VmtqxJSTmsaHBn14vaXjU+IenHbqyNm1sxJSDnFcnE7so44udPJMZdTPHX52Pc2JKyc4qnLx7f4JGHlFE9drrJNRDnFW5e/3uf1cjvmqi6f8H//TEg5xVuXq27mmGsJP+ZGq8u1z3fs2HGf7dlSB22fe+45Gzp0qNWoUSMsXRlUz9kLLiha8Xvz+uuv2+mnnx5qrItWhhrkOlnT7WrqlfDjjz+G9bZt06aNXXPNNW58sFgoaKsKsqwN+9Jqe1NRYK+irc4+15Lp4HZFgZ9kWDR8UZUtW6F8y698KduqW7ZC+SavfCnb8lXV993yatsp8Ltjxw4XYK5Zs2axB5H98MMPMc9L7eCvv/7a5emVV16xP//5zzZz5kxbsGABnRC4IJKSF0TohFB1OyGIOiIks6ftquzzktrTVheqE1FOoWWiEwKdEH6uIz47/7Ny7Wnrr5uT0dNWdTPHXEupTgilHh5BDc+TTz7ZXTXw27p1q3sv1qBtv379XK+EyHkrov273/3ONUzVeJ4xY4YNGTLEvb906VLXIFZPBgAAACBeurMrUdTrQr0l5LDDDnM9M/74xz+6jg4K6Kph7u+EsH79emvWrFmJ81PniMgOEl7jX5Ofd2IYyd8xIpb0yPnuEXAnjJF0+hk9PfrnFWCIdhegAkc6aYykk0gFlhTkKX4CWFxJ6ZHf33t6MGq6Tgx1wl8s7z//F2t6wc//RdJJZzRKj1Ym0cupdOk6YdQJf6LKqVjegwFvoP4S0/3rOhHlFCghXQGGtCjpiSynaKJtM/70yHIpqZyipZe0z/vT/eVblnIKy3uUbWZPusVcHqUtJy/4Vyz956BSSXVB5PqPt5xiqQsi0706NpZyiiU9ss7WfpqocoqnLs9IYDnFmu7/Tf+6Lks5xVuXl+8xN3r5VdQxN3Jdc8y1hB1zS6rLY1HqoK2ixNGerqsu/ur1EKs6depY165FXeVFt3s1atQolH7hhRfatddeaw0bNnSR5yuvvNIFbHloAwAAAMpi+PDh5TZv9cJRT1kFcOmEAAAAgHjEHLQ95JBDXLBWk3rJ+iPF6uqrB4yoB24iPfTQQy76rEauGr4nnXSSPfbYYwn9DQAAAFQPGmbAuwXNe7hXSWIdemHMmDE2YMAA93Ax3XmmcWz/85//uKG+1KGBTggAAAAo16Dtaaed5v7V2FwKnuohC/5bwvQAB68HQbzUwPXLzs62iRMnugkAAAAoC40dtnbtWjfMl4YriHb3mHdXWeS4ZCXRw2Y0PJjmqyCtHlKhgO0JJ+x5qA6dEAAAAFCuQduxY8e6fxWc1fhcCqgCAAAAlcW7777rerzKe++9l5B5PvPMM3t9n04IAAAAiEdGvON/zZs3z7744gv3+sADD3RjdgEAAACpqm/fvta+fXv3oDC9BgAAAKpM0Pbbb7+1s88+2z788MPQU3D1RNyjjjrKXnrpJWvZsmV55BMAAAAos9WrV8c89AEAAACQLGml/YIeppCXl+d62f7www9u0ms9Jfeiiy4qn1wCAAAAAAAAQDVR6p62M2fOtI8++sgOOOCAUJpeP/LII3bMMcckOn8AAABAQulBYXpo2N4MGjSowvIDAAAAlDlo26pVK9fTNpJuM9tvv/1KOzsAAACgQnnPaChJIBBgCAUAAABUruERfv/739uVV17pHkTm0eurr77a/vCHPyQ6fwAAAEBCrVu3zg3tVdJEwBYAAACVrqftiBEjbMeOHXbEEUdYRsaer+fn57vXv/nNb9zk0Xi3AAAAQKpQL1oAAACgygVtH3744fLJCQAAAFDOgsFgsrMAAAAAJD5ou68xwAAAAIBUpbZsTk5OsrMBAAAAJDZo++2339rf//53W7Zsmfv7gAMOsMGDB1uLFi1KOysAAACgQk2aNCnZWQAAAAASG7R97LHH7Nprr7Xc3FyrW7euS/vpp5/shhtusAcffNAuv/zy0swOAAAAAAAAABAhzWL01ltv2VVXXWVXXHGF6227efNmN+m1grVXX321/fOf/4x1dgAAAAAAAACAsvS0/f3vf2833XST3XXXXWHpzZs3d71sa9asaffff7+dcsopsc4SAAAAAAAAABBvT9tPP/3Uzj///BLf13v6DAAAAAAAAACgAnraFhQUWGZmZonv6z19BgAAAEh1p59+ugUCgWLpSsvOzraOHTvaueee6x66CwAAAKRsT9uDDjrI3njjjRLff/31191nAAAAgFRXr149e/fdd92dYgrUapo/f75Ly8/PtylTplj37t3tww8/THZWAQAAUA3F3NN21KhRdtlll1mNGjXskksusYyMPV9Vo/bJJ5+0W2+91R577LHyzCsAAACQEM2aNXM9aR999FFLS9vTj6GwsNA9XLdOnTr20ksv2W9/+1v73e9+Z7NmzUp2dgEAAFDNxBy0HT58uC1atMiuuOIKGzNmjHXo0MGCwaCtXLnStm3bZldddZWNGDGifHMLAAAAJMAzzzzjetF6AVvR6yuvvNKOOuoou+eee1y795hjjklqPgEAAFA9xRy0lT/84Q92xhln2IsvvmjLly93aX379rWzzz7bevfuXV55BAAAABJKd4stWbLE9t9//7B0pXnPadDYttHGvQUAAABSJmj7l7/8xQYNGuSCswRoAQAAUJmdf/75duGFF9rNN99sPXv2dGlz5851PWwvuOAC9/fMmTN5ZgMAAABSO2j7/PPP2+WXX26HHnqo/frXv3ZT586dyzd3AAAAQDl46KGHrGnTpnb//ffb+vXrXZr+Hj16tBvHVk488UQ7+eSTk5xTAAAAVEcxB231JN0ff/zR3nrrLXvzzTft7rvvdg1b9b5VALdPnz5hY4IBAAAAqSo9Pd1uueUWN/30008urW7dumGfad26dZJyBwAAgOquVFHWBg0a2HnnnWd/+9vfbOPGjfbII4/Yzp07bdiwYdakSRN3K9krr7xi27dvL78cAwAAAAmkYG1kwBYAAABIpri7xmZlZbnbxR577DH75ptvbNq0ada2bVu788477cEHH0xsLgEAAIAE0pAIGtd2v/32s4yMDNfz1j8BAAAAlWJ4hH05/PDD3XTHHXdYXl5eomYLAAAAJNyIESPs66+/tttuu82aN29ugUAg2VkCAAAAShe0vfbaa2P5mGvsPvDAA5aZmRnT5wEAAIBkmDVrln3wwQfWo0ePZGcFAAAAiC9oO3/+/Fg+Rg8FAAAAVAqtWrWyYDCY7GwAAAAA8Qdt33vvvVg+BgAAAFQKDz/8sN1000325JNPuucyAAAAAFVyTFsAAACgshg6dKjt2LHDOnToYDVr1iw2vNcPP/yQtLwBAAAAcQVt582bZ3/729/cwxtyc3PD3nv11VcTlTcAAACg3HraAgAAAFUmaPvSSy/ZBRdcYCeddJL9+9//thNPPNGWLVtm69evt9NPP718cgkAAAAk0PDhw5OdBQAAACBxQdt77rnHHnroIRs1apTVqVPH/vjHP1q7du3s0ksvtebNm5d2dgAAAECF+Omnn6xu3bqh13vjfQ4AAABIhrTSfuHLL7+0U0891b3Oysqy7du3WyAQsNGjR9tTTz1VHnkEAAAAyqxBgwb2/fffu9f169d3f0dOXjoAAABQqXraqhG7detW97pFixa2ePFiO/jgg23z5s3uYQ4AAABAKnr33XetYcOG7vV7772X7OwAAAAAiQvaHnvssTZ9+nQXqD3zzDPt6quvdg1gpfXr16+0swMAAAAqRN++faO+BgAAACpt0FY9art27WqPPvqo7dq1y6XdcsstlpmZaR999JENGTLEbr311vLMKwAAAJAwulPs448/dkMmFBYWhr2nB+8CAAAAKR+07datm/Xs2dMuuugiO/vss11aWlqa3XTTTeWZPwAAACDhpk6dasOGDbNt27a5h47pGQ0evSZoCwAAgErxILKZM2faQQcdZNddd501b97chg8fbh988EH55g4AAAAoB2rT/uY3v3FBW/W4/fHHH0PTDz/8kOzsAQAAoJqLOWh7zDHH2F/+8hdbu3atPfLII7Z69Wo3Ftj+++9vEyZMsHXr1pVvTgEAAIAE+fbbb+2qq66ymjVrJjsrAAAAQPxBW0+tWrVs5MiRruftsmXL3MPIJk6caK1bt7ZBgwaVal6PP/64G3ZBt6RpOvLII+3tt98Ova+xc0eNGmWNGjWy2rVru3Fz169fX9osAwAAAGFOOukkmzdvXrKzAQAAAJRtTNtoOnbsaDfffLO1adPGxowZY2+99Vapvt+yZUu77777rFOnThYMBu3ZZ5+1X//61zZ//nw3FMPo0aPdPF9++WWrV6+eXXHFFTZ48GD78MMPy5JtAAAAVHOnnnqq3XDDDfb555/bwQcf7B6u61fazggAAABASgRt33//fTdcwt///nf3QLKzzjrLLrzwwlLNY+DAgWF/33333a737Zw5c1xA95lnnrEXXnjBjj/+ePf+pEmTrEuXLu793r17x5t1AAAAVHMXX3yx+/eOO+4o9p4eRFZQUJCEXAEAAABxBG2/++47mzx5sptWrFhhRx11lP3pT39yAVsNm1AWahirR+327dvdMAmffPKJ5eXlWf/+/UOf6dy5sxuGYfbs2SUGbXfv3u0mz08//eT+zc/Pd5MoyKypsLDQTR4vXXlRz999paenp7tGvTdff7pZ0DIjBp/IKzTTc4kziqUHLGDBsHT9TH4wYGkWtPRo6YGgpRc95NgKg2YFwYClB4KWH8gqynuwwNKswAoCmRZ0v+6l51uaFRZLTw/mubz45+Gla5kKiqXn6tTGzceTaZmWZ5pPwDJ8m1hQ8zX9bpqlW/o+0wuVPytwaXrPozS9p3nrNyLTS1dOe7a9WNIzMjLcfDPTggkppzRfekFQ7wUsIxA038OrraBQ6yE8XWWTiHJyyxTMdeXvT9d8NZ9CbSGBjGLpiSqnyHRtA9oWtP34RaZ75bivcvKnq/z1+ch9PjLdK9tElJPLa6FKIxC2zRSlW7E6Ys+nElNOhZZuhYGiclI9oPpAaXovWh3hX/dlLSdPtLqgpHSVWSzlFMp7aetyCyaknOKty/37a1nKKd66XGWTiHKKpy53/1bRY67qCG89J+OY60nWMVfp/jJJ9DG3pLo8ERI1HwAAACCpQdsBAwbYO++8Y7/4xS/sggsucE/bPeCAA8qcgUWLFrkgrcav1bi1r732mh144IG2YMECy8rKsvr164d9vmnTpnt96Nm9995r48ePL5auIRe8wHLjxo2tQ4cOtmrVKtuwYUPoM+rdq0lj9W7ZsiWU3r59e2vSpIktXrzYdu7cGRZEVv40b/9Jhcbp1cnjiE7hJwOTl6dZ7QyzM9oVhp1UTl6ebi1qmQ1oWZS+Odfs5VXp1qle0I5tVnTSumaH2dvfpNshjYJ2aKOi9KVbAvb+uoAd3TRo8xqOKlqmH+dYyx9n27KmA21LzTZFy7RhujXZutgWtzjXdmY1LFqmta9a/Z1f2fw2F1tBWtHJYrdvnrOs/K02r13RvOXwVRMtN6OOLWx1QShtcE6GTdkxxZqlN7N+2f1C6VsKt9jUnVOtfUZ7612jKOi+tmCtzdg1w7pmdrVuWd1C6SvyVtic3DnWM6undczsGEpfmLvQFuYttL7Zfa15evNQ+pzdc2xF/opSlZO2scjx7A4//HDLzc21hQsXhtJ0ktizZ0+3XfjLtSzldEC9ovRPNwXsk40BO6FlobX0PQ9Fn9V3Tm9baPV/Lo556aMSUk7phbnWc/VE25LT2pY0HxxKz8n9wbqvedY21jnQVjY+IZReb8dX1mXdqwkrpwE5A6xeWr1QurYBbQuDaw62TF9AYuqOqbYjuMOG1hq6Z/l/Lq99ldOSJUuKliknx7p3724bN260lStXFi1TvXqu974uSK1ZsyZUtokoJ3l7TZqt2W42rIMCwkXpr6xKs235xeuIgq+zElZO3zXoZWsaFO1njbcutg4bptuqXxxvG+p0jVpHDK3VOWHl5JmyfYrVDNS0gTWL7qzIC+ZFrSO078ZSTqFlKmVdrv00EeUUb10+r8WohJRTvHX50Jo5CSmneOpyqarHXNURqpcTVU7x1OVmU5N2zFUd4T+OJvqYG60u37RpU9g8AAAAgKooEPR3Y9kLjeul4Q9+9atfhXpFJIIa6l9//bVrmL/yyiv25z//2T3kTEFbPfDM32tWevXqZccdd5xNmDAh5p62rVq1cg18PeysonrathvzVtJ6/SzNHlmU9yT0+unVtlVSe9ouOG9Bufa03f+Wt5La0/aLGiOT2tO2e7u2Se1p+/Gwj8utp22X26clrJzi6cG5LGtYUnva9mzbOmHlFE8PzrnnzS3Xnrb73zotqT1tl+WMTGpPW9XNyeppu2D4gip7zFUdoXo5mT1tD2nbLKk9becOm1uhPW03b95sDRo0cG1Hr20XK90hdskll1h2drZ7vTdXXXWVpQq1Z3UBK55lLou2N5XueRWJtjr73KT+/sHtio6LybBo+KJymzdlW3XLVijf5JUvZVu+2HerbvlW9bKNt20Xc0/bN99808qDel3ogWZy2GGH2dy5c+2Pf/yjDR061AV01TD397Zdv369NWvWrMT51ahRw02R1PjX5OedGEYqKShdUnrkfPcIuBPGSDr9jJ4e/fMKMES7e0+BI500RtJJpAI8xfLuTgAt5vRo8yg5PRiWrpP8PanB0OuwvP/8X6zpBT//F0knnWUvp9Kl64RRJ/yJKCcFACMpOGD7SPev67KUkydQQroCDGlR0hNVTiWlR9tm/OmR5VJSOUVLL2mf99Ijy7Ys5RSW9yjbzJ70iHwnsJy84F+x9J+DStHqgmjrPt5y8iupLohM9/bdfZVTrOmRdYH200SUU7x1eUaCyineuty/rstSTvHW5VX1mKs6IrJsK/KYW5SanGOu0qOVSaKOuSXV5fF66KGHbNiwYS5oq9cl0W+nUtAWAAAA1U/cDyIrL+qFo56yCuDqKb4zZsywIUOGuPeWLl3qeuVqOAUAAACgNDRMR7TXAAAAQKpJatB2zJgxbqxcPVxs69at9sILL9h//vMf+9e//uW6CWs4hmuvvdYaNmzougtfeeWVLmBb0kPIAAAAAAAAAKCyS2rQ9vvvv3cPNVu7dq0L0uohFQrYnnDCnofq6LY13QKnnrbqfXvSSSfZY489lswsAwAAoIrQww01BJju5NKwXH4PPvhg0vIFAAAAJDVo+8wzz+z1fY03NnHiRDcBAAAAiaIhuPSg3fbt29uSJUusa9eutnr1avcAtEMPPTTZ2QMAAEA1F/+THAAAAIBKSsN0XX/99bZo0SLXUeDvf/+7ffPNN9a3b18788wzk509AAAAVHMEbQEAAFDtfPHFF26YLsnIyLCdO3da7dq17Y477rAJEyYkO3sAAACo5gjaAgAAoNqpVatWaBzb5s2b25dffhl6b+PGjUnMGQAAAJDkMW0BAACAZOjdu7fNmjXLunTpYqeccopdd911bqiEV1991b0HAAAAJBNBWwAAAFQ7Dz74oG3bts29Hj9+vHs9ZcoU69Spk3sPAAAASCaCtgAAAKhWCgoKbM2aNdatW7fQUAlPPPFEsrMFAAAAhDCmLQAAAKqV9PR0O/HEE+3HH39MdlYAAACAqAjaAgAAoNrp2rWrrVy5sszzuffee61nz55Wp04da9KkiZ122mm2dOnSsM/s2rXLRo0aZY0aNbLatWvbkCFDbP369WX+bQAAAFRdBG0BAABQ7dx11112/fXX2z/+8Q9bu3at/fTTT2FTrGbOnOkCsnPmzLHp06dbXl6e68W7ffv20GdGjx5tU6dOtZdfftl9/rvvvrPBgweX05IBAACgKmBMWwAAAFQbd9xxh1133XV2yimnuL8HDRpkgUAg9H4wGHR/a9zbWEybNi3s78mTJ7set5988okde+yxtmXLFnvmmWfshRdesOOPP959ZtKkSdalSxcX6O3du3dClw8AAABVA0FbAAAAVBvjx4+33/72t/bee++Vy/wVpJWGDRu6fxW8Ve/b/v37hz7TuXNna926tc2ePTtq0Hb37t1u8ng9f/Pz890kaWlpbiosLHSTx0tX0FkB6H2la3xfBam9+frTzYKWGXFfXl6hmULcGcXSAxawYFi6fiY/GLA0C1p6tPRA0NKL4uVWGDQrCAYsPRC0tIBZfiBrT96DBZZmBVYQyLSg+/WflymYb2lWWCw9PZjn8uJ935+uZSoolp5rWirNJ5KWKsN3yhTUfE2/m2bplr7P9ELlzwpcmt7zKE3vad76jWjp/jLZezntebheLOkZGRmu/DPTggkrp1Deg3ovYBkBXfjwpRdqPYSnq2wSVU4ZwVxX/v50zVfzKdQWEsgolp7IcvKnaxvQtpBp4XmMTPfKcV/l5E9X+evzkft8tHSVbyLKyeW1UKURCNtmitL1W8XriGCCyqnQ0q0wUFROqgdUHyhN74XSI+oIbz2XtZxCy2R5xeqCktJVZrGWU1x1uQUTVk7x1OX+/bWs5RRPXa6ySUQ5xVuXl+8xd8++m6xjrmhdc8y1hB9zS6rLY0HQFgAAANWGd/LUt2/fhM9bDfBrrrnGjj76aDdmrqxbt86ysrKsfv36YZ9t2rSpe6+kcXIVXI40f/58q1WrlnvduHFj69Chg61atco2bNgQ+kzLli3dtGzZslAAWdq3b+96AC9evNh27twZFkBW3jRv/0lFt27d3En+iE7hJxWTl6dZ7QyzM9oVhp1UTl6ebi1qmQ1oWZS+Odfs5VXp1qle0I5tVnQiumaH2dvfpNshjYJ2aKOi9KVbAvb+uoAd3TRoB9QL2rz0UXuW6cc51vLH2bas6UDbUrNN0TJtmG5Nti62xS3OtZ1ZDYuWae2rVn/nVza/zcVWkFZ0stjtm+csK3+rzWu3Z76ew1dNtNyMOraw1QWhtPRCnVROtWbpzaxfdr9Q+pbCLTZ151Rrn9HeetcoCrivLVhrM3bNsK6ZXa1bVrdQ+oq8FTYnd471zOppHTM7htIX5i60hXkLrW92X2ue3jyUPmf3HFuRv8IG5AywefPmxVRO2r78n3XLdPjhlpubawsXLixapvR0N/6ytgt/uZa1nDyfbgrYJxsDdkLLQmtZsygv+qy+c3rbQqv/c3GobBNVTj1XT7QtOa1tSfOiIUdycn+w7muetY11DrSVjU8Ipdfb8ZV1WfdqQsupXlq9ULq2AW0Lg2sOtkxfQGLqjqm2I7jDhtYaumf5fy6vfZXTkiVLipYpJ8e6d+9uGzduDBuPu169eq7nvoZdWbNmjUtT+SainOTtNWm2ZrvZsA6FYYG/V1al2bb86HXEzsyGCSmn7xr0sjUNivazxlsXW4cN023VL463DXX21LHR6oihNXMSUk6eKdunWM1ATRtYc2AoLS+YZ1N2TClWR6iOjbWc4qnLtZ8mqpziqcvntRiVsHKKpy5X2SainOKty8vzmKu6PJnHXK9u5phrCT/mRqvLN23aZLEIBP1h/ypIPRNUQWpF1a1bt8J+t+1Nb1myrM4+15Lp4Hatk/r7i4YvqrJlK5Rv+ZUvZVt1y1Yo3+SVL2Vbvqr6vpvotp16vughYDpRTrTLLrvM3n77bZs1a5Y7iRMNizBy5MiwnrPSq1cvO+6442zChAkx9bRt1aqVa+B7y1wRPW3bjXkrqT1tv6gxck/ek9Tr55C2zZLa62fusLnl1utn/1veSmpPW5VtMnvadm/XNqk9bT8e9nG59rTtcvu0pPa0XZV9XlJ72vZq2yoh5RRPD865580t1562+986Lak9bZfljExqT1uVbTJ72n52/mfl2tPWXzcno6et6maOuVYhPW03b95sDRo02Gd7lp62AAAAqFb233//sHFso/nhhx9KNc8rrrjCPdTs/fffDwVspVmzZq73hRrn/t62ChzrvWhq1Kjhpkhq/Gvy804MI3knELGmR853j4A7YYyk08/o6dE/rwBDtLsAFTjSSWMknUQqsKQgT/ETwOJKSo/8/t7Tg1HTdWKoE/5ief/5v1jTC37+L5JOOqNRerQyiV5OpUvXtq8T/kSVU7G8BwN7NpK9pPvXdSLKKVBCugIMaVHSE1lO0UTbZvzpkeVSUjlFSy9pn/en+8u3LOUUlvco28yedIu5PEpbTl7wr1j6z0GlkuqCyPUfbznFUhdEpnt1bCzlFEt6ZJ2t/TRR5RRPXZ6RwHKKNd3/m/51XZZyircuL99jbvTyq6hjbuS65phrCTvmllSXx4KgLQAAAKoVDT2g3rqJoB4UV155pb322mv2n//8x9q1axf2/mGHHWaZmZk2Y8YMGzJkiEtbunSpff3113bkkUcmJA8AAACoegjaAgAAoFo5++yz3VhziTBq1Cg3BMIbb7xhderUCY1Tq6Cwxi3TvxdeeKFde+217uFkugVOQV4FbKM9hAwAAAAQgrYAAACoNvY1LEJpPf744+7fX/7yl2HpkyZNshEjRrjXDz30kLsNTj1tNVbtSSedZI899lhC8wEAAICqhaAtAAAAqo1EP4M3lvllZ2fbxIkT3QQAAADEgqAtAAAAqg3/U58BAACAVBXb48oAAAAAAAAAABWCoC0AAAAAAAAApBCCtgAAAAAAAACQQgjaAgAAAAAAAEAKIWgLAAAAAAAAACmEoC0AAAAAAAAApBCCtgAAAAAAAACQQgjaAgAAAAAAAEAKIWgLAAAAAAAAACmEoC0AAAAAAAAApBCCtgAAAAAAAACQQgjaAgAAAAAAAEAKIWgLAAAAAAAAACmEoC0AAAAAAAAApBCCtgAAAAAAAACQQgjaAgAAAAAAAEAKIWgLAAAAAAAAACmEoC0AAAAAAAAApBCCtgAAAAAAAACQQgjaAgAAAAAAAEAKIWgLAAAAAAAAACmEoC0AAAAAAAAApJCkBm3vvfde69mzp9WpU8eaNGlip512mi1dujTsM7t27bJRo0ZZo0aNrHbt2jZkyBBbv3590vIMAAAAAAAAAFU2aDtz5kwXkJ0zZ45Nnz7d8vLy7MQTT7Tt27eHPjN69GibOnWqvfzyy+7z3333nQ0ePDiZ2QYAAAAAAACAcpNhSTRt2rSwvydPnux63H7yySd27LHH2pYtW+yZZ56xF154wY4//nj3mUmTJlmXLl1coLd3795JyjkAAAAAAAAAVMGgbSQFaaVhw4buXwVv1fu2f//+oc907tzZWrdubbNnz44atN29e7ebPD/99JP7Nz8/302SlpbmpsLCQjd5vPSCggILBoP7TE9PT7dAIBCarz/dLGiZEf2Y8wrNAlrpxdIDFrBgWLp+Jj8YsDQLWnq09EDQ0jWznxUGzQqCAUsPBC0/kFWU92CBpVmBFQQyLeh+3UvPtzQrLJaeHsxzefHPw0vXMhUUS881LZXm48m0TMszzSdgGb5NLKj5mn43zdItfZ/phcqfFbg0vedRmt7TvPUbkemlKydzn48lPSMjw803My2YkHJK86UXBPVewDICQQv40wu1HsLTVTaJKCe3TMFcV/7+dM1X8ynUFhLIKJaeqHKKTNc2oG1B249fZLpXjvsqJ3+6yl+fj9znI9O9sk1EObm8Fqo0AmHbTFG6Fasj9nwqMeVUaOlWGCgqJ9UDqg+Upvei1RH+dV/WcvJEqwtKSleZxVJOobyXti63YELKKd663L+/lqWc4q3LVTaJKKd46nL3bxU95qqO8NZzMo65nmQdc5XuL5NEH3NLqssBAACAqi5lgrZqgF9zzTV29NFHW9euXV3aunXrLCsry+rXrx/22aZNm7r3Shond/z48cXS58+fb7Vq1XKvGzdubB06dLBVq1bZhg0bQp9p2bKlm5YtWxYKIEv79u1dD+DFixfbzp07wwLIypvm7T+p6Natmzt5HNEp/KRi8vI0q51hdka7wrCTysnL061FLbMBLYvSN+eavbwq3TrVC9qxzYpOWtfsMHv7m3Q7pFHQDm1UlL50S8DeXxewo5sGbV7DUUXL9OMca/njbFvWdKBtqdmmaJk2TLcmWxfb4hbn2s6shkXLtPZVq7/zK5vf5mIrSCs6Wez2zXOWlb/V5rUrmrccvmqi5WbUsYWtLgilDc7JsCk7pliz9GbWL7tfKH1L4RabunOqtc9ob71rFAXc1xastRm7ZljXzK7WLatbKH1F3gqbkzvHemb1tI6ZHUPpC3MX2sK8hdY3u681T28eSp+ze46tyF9RqnLS9jVv3rzwZTr8cMvNzbWFCxeG0nSSqPGXtV34y7Us5XRAvaL0TzcF7JONATuhZaG1rFmUF31W3zm9baHV/7k45qWPSkg5pRfmWs/VE21LTmtb0rxoyJGc3B+s+5pnbWOdA21l4xNC6fV2fGVd1r2asHIakDPA6qXVC6VrG9C2MLjmYMv0BSSm7phqO4I7bGitoXuW/+fy2lc5LVmypGiZcnKse/futnHjRlu5cmXRMtWr53rua9iVNWvWhMo2EeUkb69JszXbzYZ1UEC4KP2VVWm2Lb94HVHwdVbCyum7Br1sTYOi/azx1sXWYcN0W/WL421DnT11bGQdMbRW54SVk2fK9ilWM1DTBtYcGErLC+ZFrSO078ZSTqFlKmVdrv00EeUUb10+r8WohJRTvHX50Jo5CSmneOpyqarHXNURqpcTVU7x1OVmU5N2zFUd4T+OJvqYG60u37RpU9g8AAAAgKooEPR3Y0miyy67zN5++22bNWuWO4kTDYswcuTIsJ6z0qtXLzvuuONswoQJMfW0bdWqlWvg161bt8J62rYb81bSev0szR5ZlPck9Prp1bZVUnvaLjhvQbn2tN3/lreS2tP2ixojk9rTtnu7tkntafvxsI/Lradtl9unJbWn7bKsYUntaduzbeuElVM8PTjnnje3XHva7n/rtKT2tF2WMzKpPW1VNyerp+2C4Quq7DFXdYTq5WT2tD2kbbOk9rSdO2xuhfa03bx5szVo0MAFdb22XVWn9qwuYFX0Mre9qajNkwyrs89N6u8f3K7ouJgMi4YvKrd5U7ZVt2yF8k1e+VK25Yt9t+qWb1Uv23jbdinR0/aKK66wf/zjH/b++++HArbSrFkz1/tCjXN/b9v169e796KpUaOGmyKp8a/JzzsxjOSdQMSaHjnfPQLuhDGSTj+jp0f/vAIM0e4CVOBIJ42RdBKpAE+xvLsTQIs5Pdo8Sk4PhqXrJH9PajD0OizvP/8Xa3rBz/9F0kln2cupdOk6YdQJfyLKSQHASAoO2D7S/eu6LOXkCZSQrgBDWpT0RJVTSenRthl/emS5lFRO0dJL2ue99MiyLUs5heU9yjazJz0i3wksJy/4Vyz956BStLog2rqPt5z8SqoLItO9fXdf5RRremRdoP00EeUUb12ekaByircu96/rspRTvHV5VT3mqo6ILNuKPOYWpSbnmKv0aGWSqGNuSXU5AAAAUNUltdWrHhQK2L722mv27rvvWrt27cLeP+ywwywzM9NmzJgRSlu6dKl9/fXXduSRRyYhxwAAAAAAAABQvpLa03bUqFFuCIQ33njD6tSpExqnVl2ENW6Z/r3wwgvt2muvdQ8nU5fhK6+80gVsoz2EDAAAAAAAAAAqu6QGbR9//HH37y9/+cuw9EmTJtmIESPc64ceesjdBjdkyBA3Vu1JJ51kjz32WFLyCwAAAAAAAABVOmgbyzPQsrOzbeLEiW4CAAAAAAAAgKqOJzkAAAAAAAAAQAohaAsAAAAAAAAAKYSgLQAAAAAAAACkEIK2AAAAAAAAAJBCCNoCAAAAAAAAQAohaAsAAAAAAAAAKYSgLQAAAAAAAACkEIK2AAAAAAAAAJBCCNoCAAAAAAAAQAohaAsAAAAAAAAAKYSgLQAAAAAAAACkEIK2AAAAAAAAAJBCCNoCAAAAAAAAQAohaAsAAAAAAAAAKYSgLQAAAAAAAACkEIK2AAAAAAAAAJBCCNoCAAAAAAAAQAohaAsAAAAAAAAAKYSgLQAAAAAAAACkEIK2AAAAAAAAAJBCMpKdgVRRUFBgeXl5CZtfizrpliy7arSqmB8KBi1z1yZLL9hZMb8HAAAAAAAAVAPVPmgbDAZt3bp1tnnz5oTOd9xxTSxZVgUeqLgfK8i1+l+9bc2Wv2ABC1bc7wIAAAAAAABVVLUP2noB2yZNmljNmjUtEAgkZL65OT9ZsrSroEEvgkGzHXlm32ed4f5uvvyvFfPDAAAAAAAAQBWWVt2HRPACto0aNbKcnBzLzs5OyBTIyEralJ0RqJApJzNgjWoGrEnD+ra5zQArSM9JdpECAABUuPfff98GDhxo++23n+sA8Prrrxe7s+v222+35s2bu/Zm//79bfny5UnLLwAAAFJftQ7aemPYqoct4lcz08zSsywvu1GyswIAAFDhtm/fbt27d7eJEydGff/++++3P/3pT/bEE//f3p3A21jtjx//7jMf4qDMx3BM0RUqpCSKyK2Q/BD9zLlJ3VyVy61ocK+iURQqFNWV0OUv5EdxM2XIVJkyZHaIYzrOtJ//ay0929777ONMe5+9n2d/3r125+y1B2uf717r+T7rWc96Jsm6deukePHi0q5dO7l06VKR1xUAAADWEPbLIyj+WhIhXLn+fPwdAQBAGGrfvr2++aJm2b799tvy/PPPS8eOHXXZJ598IuXLl9czcrt3717EtQUAAIAVMGgLAAAABMi+ffv0NRTUkgimhIQEufXWW2XNmjU+B23T0tL0zXT27OVrJWRmZuqbEhERoW9Op1PfTGa5WgZMDRjnVh4ZGaknMJjv614uYki013l5GU4RdZg+Klu5Q1+U1r1c/TOZhkMixJBIX+UOQyLdjvk7DZEswyGRDkMiHCKZjpjLdTeyJEKyJMsRLYb+1//4TEamRIgzW3mkkaHrYr7evVx9pqxs5elq9oF+H2/qU0W57TIZ6n1F/bsREimRuZY7Vf0kS5epx0yqTD2m3lv9G77K3WNy9ThdXvYtL+VRUVE6/tERht/i5Kq7oR5zSJTD8JjLkeVUfwfPchUbf8UpykjX8XcvV++r3sepviGOqGzl/oyTe7n6DqjvQrR41tG73IxjbnFyL1fxV8/3bvO+ylV8/REnXVeniobD4ztzpVz9W9n7CMNPcXJKpDgdV+Kk+gHVH6gy9Zir3KuPMP/OhY2T6zNJRra+IKdyFbO8xqlAfbkYfotTQfpy9/Za2DgVpC9XsfFHnAralwd2m3u57QZrm6uovzXbXPH7NjenvjwvGLQFAAAAAkQN2CpqZq07dd98zNuYMWPkpZdeylb+448/6qUVlLJly0rNmjX1oHBycrLrOYmJifq2a9cuSUlJcZXXqFFDX8dh+/btkpqa6iqvW7eulCpVSr+3+05FgwYN9E5+n9qeOxXTd0fINVEiXZKcHjuV03dHSuXiIu0Tr5SfSReZvS9SaicYcmeFKzuihy6KLDoYKTdda8jN114p35nikJXHHNK8vCHXJxiyIXLw5c90eq0knl4ju8o/ICnFql35TMlLpdy57bK9cg9JjSlz5TMdnSulUg/Ij9UelayIKzuLDQ5+IjGZ52RD0uX3NTXeN1HSo0rI1iq9XGWRTrVTuUAqRFaQ1nGtXeUpzhRZkLpAakTVkGaxzVzlR7OOyrJLy6R+dH1pENPAVb4nY4+sTV8rTWKaSK3oWq7yrelbZWvGVmkZ11IqRlZ0la9NWyt7MvdI+/j2smHDhjzFKSYmxuO5+jM1bizp6emydevWK58pMlKaNGmivxfucS1snEybTjlk40mH3JPolES31efUc9VrHqzulFJ/hEPF1l9xarJ/oqTEV5UdFTu7yuPTf5eGhz6WkyVukL1l73GVJ1w8IPWOzfVrnBIiElzl6jugvgudi3WWaLcBiQUXF8hF46J0K97t8uf/I165xWnHjh1XPlN8vF6G5eTJk7J3794rnykhQerVqydHjhyRQ4cO6TIVX3/ESVl0KEIOXRDpWdPpMfD35b4IOZ/pu49IjS7jlzgdKd1UDpW+0s7KntsuNZOXyr7r7pbkEvVd5d59RLdi8X6Jk2nWhVlSzFFMHij2gKssw8iQWRdnZesjVB+b1zgVpC9X7dRfcSpIX76h8mC/xakgfbmKrT/iVNC+PJDbXNWXB3Oba/bNbHPF79tcX335qVOnJC8chvuwvw2pmQmqg1R/qJIlS3o8ptYRU40uKSlJXzzMVH34wiKt4/wnmhfodVs2/iB9OreX5q1ay4SPv3CVG78skVcnTpPvf9gsJ0+fkeqJFeWx/+0iTw3o4fH69PQMefvDT+XTuYtk976DUiw+Tq6vWU0G9Ogkj3T+s0RHZz/y4culTEP2HU6WpFVPS9z5g3JjUlUJpm29twX0/Yv6++Ftf5xnHIuaneNLbO0bW4X4Bi++xDaw7N5285PbhQI1g2LevHnSqVMnfX/16tXSvHlzvaOuLkRm6tq1q37urFmz8jTTtkqVKjrBNz9zUcy0TRqxMKgzbX+J7Xu57kGa9XNT9QpBnfWzvuf6gM36qfPcwqDOtFWxDeZM24ZJ1YM60/aHnj8EdKZtvZGLgzrTdl/cI0Gdadu0ehW/xKkgMzjXP7I+oDNt6zy/OKgzbXfF9w3qTFsV22DOtN3yv1sCOtPWvW8Oxkxb1TezzZUimWl75swZKV26dK75LDNtLWzev2fKw30H6p8njh2VchUu7whs3PazlLuujMx8d7RUqVReVm/YIgOH/VMiIyPkib7dXQO27XoMli2/7JJXnh0kzRs3kpIlisvaTdvk9Ukz5KY/1ZVG9a8P8icEAACwtgoVKuifx48f9xi0VfcbNWrk8zWxsbH65k0l/+rmztwx9GbuQOS13Pt9L3PoHUZvavfTd7nv56sBBl9nAaqBI7XT6E3tRKqBJTXIk30HMLucyr1ff/Vyw2e52jFUO/zZ6v7Hf3ktz/rjP29qp9MXVe4rJr7jlL9ytcOodvj9FadsdTccl78kVyl3/1v7I06OHMrVAEOEj3J/xskXX98Z93LvuOQUJ1/lObV593L3+BYmTh519/GduVwueY5HfuNkDv5lK/9jUCmnvsD771/QOOWlL/AuN/vYvMQpL+XefbZqp/6KU0H68ig/ximv5e7/pvvfujBxKmhfHthtru/4FdU21/tvzTZX/LbNzakvzwsGbS3q4oXzsmTBPPl84XI5eeK4zJ/9mQx48mn9WL/ul2d2mGpUS5Q1G7fK3K+XuwZt1Qzbles2yYZFM+Wm+nU9nvs/97eR9AzfX2YAAADknTqjSw3cLlu2zDVIq2bOrlu3TgYNGhTs6gEAACBE5W1oFyFnyYKvJKlmbales7bc17mrfDXrU49p995Szp2XMqWurOOjlkRo06Kpx4CtSS2LUPyPdYAAAABwdefPn5fNmzfrm6KW31K///bbb3qGxZAhQ2T06NEyf/582bZtm/Tq1UsqVarkWkIBAAAA8MagrUV9NWuGHqxVmrdqI+fPnZUNa1f5fO7q9Vtk1vylMvCRK4u+qzVs69ZKKrL6AgAA2JW6IMVNN92kb8rQoUP17yNHjtT3hw0bJk8++aQMHDhQX5RCDfIuXrzY45oKAAAAgDuWR7Cg/b/ulu2bN8mbH8zU99X6GG0feFDm/XuGNLntDo/nbt+xRzr2+5uM+ttAadvyNo+1QgAAAFB4rVq1uuoZT2q27csvv6xvAAAAQF4waGtBanBWXcXunsb1XGVqRyEmJlbOvTJWpNTlsp937ZXW3R6TgT07y/NDBni8R52kqrJjz76irjoAAAAAAACAXLA8gsWowdoFc2bJ0y+MllmLV7puXyz5r5QtX0EW/WeOft5PO3+Vu/5noPT+n/vln8OfyPY+PR5sL//33x/kx+07sj2WkZEhFy6mFsnnAQAAAAAAAOCJQVuLWfl/S+Rsyhl5sPsjUrvuDR631n9+QL7690y9JIIasG17ZzMZOvAROXbipL4lnzrtep8hA3pI8yYN9UzcidNnyZafdsneA4fki/nfSLMHesvuvb8F9XMCAAAAAAAA4YrlESxm3qwZ0uyOllKiZEK2x9q07yDT3x8vI19/Xw/Qzpz7tb6ZqiVWlP3rFurfY2NjZOnn78tbH3wqk2fOkWdeeVuKxcVJvdpJ8td+D0v9ujWL9HMBAAAAAAAAuIxBWx/2v3pfod9j66EzEgjvTvt3jo/deNMtsuXgaWkQkbe1atXA7fAn+uobAAAAAAAAgNDA8ggAAAAAAAAAEEKCOmi7cuVKeeCBB6RSpUricDjkq6++8njcMAwZOXKkVKxYUeLj46VNmzaye/fuoNUXAAAAAAAAAGw9aHvhwgVp2LChTJw40efjY8eOlfHjx8ukSZNk3bp1Urx4cWnXrp1cunSpyOsKAAAAAAAAALZf07Z9+/b65ouaZfv222/L888/Lx07dtRln3zyiZQvX17PyO3evXsR1xYAAAAAAAAAwvhCZPv27ZNjx47pJRFMCQkJcuutt8qaNWtyHLRNS0vTN9PZs2f1z8zMTH1TIiIi9M3pdOrBYfOmqGUazN/d5bdcP+Z13yhAuXdZXsoNj0cNH2UFK8+plsYfz8+UaMl0xEi0REuGZIhDHBLl9hVTz8yUTImQCImUyFzLneKULMnSZeoxkypTj6n3Vv+Gd3lWVpZHTCIjI3WczPi7l+vXZWXlqTwqKkq/b3TElfdW/0ym4ZAIMSTSbd66q9xhSKTbn8xpiGQZDol0GBLhVp5lqMccEuUwxOFe7lR/B89y9TeONNTf19C/e9TdyNB/0axs5ek6dlmOaM/PZKTr2LmXq/dV7+OUCHE6orKV+ytO3uXqO6C+C+r748673IxjbnFyL1fxV89XbV7dcio3Y+uPOOm6Oi+3DffvzJVykWivcx3+6IX8EienRIrTcSVOEZIlEUaWLlOPucqNLP2Yem/3v31h42Ty1RfkVK5ilpc4ueru1pf7KvfuC1Q79UecMpyXe8KobOXqExke5e59hHt7LUyc3PvnCEP1nc5s5b76CBUbf8SpIH25/pnXOOVQfvW+XPXN/olTQfpy8+/sjzgVpC9XgrXNVeXuMfH3NjenvhwAAACwu5AdtFUDtoqaWetO3Tcf82XMmDHy0ksvZSv/8ccf9fIKStmyZaVmzZpy6NAhSU9Pl4sXL+qdgpiYGH1Tyy+47yTExsZKdHS0pKameuwoxMXF6Z0K9Xr3HUu1/q7arbkuzrMOJy+J3ukrHXulTL3sZJpITIRIgtu+WaYhcjpNJDZSpITbvlm6UyQlXSQ+SqS4W/QuZYmcyxC5JlrkQmQ5V3lM1nmJybogl6ISJCviyj8cm3lWop2pkhpdxmPAJy7jtB4guhhznRhuO23xGaf0zuiFmCvvrRRPP6EHFtKjSsj2xJ4i6eelc3yUzLo4SypEVpDWca1dz01xpsiC1AVSI6qGNItt5io/mnVUll1aJvWj60uDmAau8j0Ze2Rt+lppEtNEakXXcpVvTd8qWzO2Ssu4llIxsqKrfG3aWtmTuUe2b9+uY2WqW7eulCpVSn8H3OPaoEEDHe8NGzZ4fKbGjRvr78XWrVtdZWonsUmTJpKSkiJ9al/5DpxJF5m9L1JqJxhyZ4Ur34FDF0UWHYyUm6415OZrr5TvTHHIymMOaV7ekOsTrpRvOuWQjScdck+iUxKLXamLeq56zYPVnVLqj+/HhsjBUvfoXCmVekB+rPaoZEVc+eI0OPiJxGSekw1Jgz0/076JOkZbq/S68pmc6dJk/0RJia8qOyp2dpXHp/8uDQ99LCdL3CB7y97jKk+4eEDqHZvrtzi1j28vCREJrnL1HVDfhc7FOku024DEgosL5KJxUboV73b58/8Rr9zitGPHjiufKT5eL8Vy8uRJ2bt375XPlJAg9erVkyNHjuj+wIytP+KkLDoUIYcuiPSsqQaEr5R/uS9CzmeKx3dJyfotxm9xOlK6qRwqfaWdlT23XWomL5V9190tySXqu8oTT6+VxNNrZFf5B6Rb8bp+i5Np1oVZUsxRTB4o9oCrLMPI8NlHqLablzi5PtMffbk6yJecnHzlMyUm6tuuXbv0d8Gk2qk/4jR9d4RcEyXSJcnpMUA4fXekVC4u0j7Rdx+xofJgv8QppVg1V3mN5KVS7tx22V65h6TGlHGV++ojuhWL90ucCtKXK3mNU40aNaRcuXL56stV3PwVp4L05apf9lecCtKXiywI2jZX9RHu21F/b3N99eWnTp3yeA8AAADAjhxGTtNEi5iaPTFv3jzp1KmTvr969Wpp3ry53klXFyIzde3aVT931qxZeZ5pW6VKFZ3glyxZ0mMWjxps3b9/vyQlJekBWH/OtN12OCVoM23rR+wv0pm2lzIN2Xf4pFRd9XeJu3BImlavEtSZtpsf2RzQmbZ1nlsY1Jm2v8T2DepM24ZJ1YM60/aHnj8EbKZtvZGL/Rangszg3BXTM6gzbZtUr+q3OBVkBuf6R9YHdKZtnecXB3Wm7a74vkGdaav65mDNtN3ce3NAZ9omjVgY1Jm2ql8O5kzbm6pXCOpM2/U91xfpTNszZ85I6dKl9aCumdvZncpn1QGsov7M1YdfyXmCYX9cj6D++zcmXdkuBsO23tsC9t7E1r6xVYhv8OJLbAOLtmvf+No9tgXN7UJ2pm2FChX0z+PHj3sM2qr7jRo1yvF1alasunlTyb+6uVM7hWoHwLyZ3H93l9/ynEbD81NekPdQO4DZ6pjDK/Jb7utfVp9e7wBLhh5cUjv5l59puH53p3byzNNl81Ke9cd/3tROpy/mDqA37/gXpFzFWu3wZ6+7Q3ydrakG+NTOvTe1s68GAL2pwQHJpVz9jV11dPvdo+4+yw2f5Y4cytUAQ4SPcn/FKadyX98Z93LvuOQUJ1/l5mBQTuXesS1MnDzq7uM7c7ncq95+jJM5+Jet/I9BJW9qkMjX376gcXKXU1/gXW623dzilNdy775AtVN/xOly3XMqd/gs14PFfoqTLzmVu/+b7n/rwsSpoH15XuOUW7nvPtvhtzgVpC/3jm1h4pR7ue++IFjbXFXuKyb+2ubm1JcDAAAAdheyWa+a/aoGbpctW+YxEr1u3Tq57bbbglo3AAAAAAAAAAiUoM60PX/+vOzZc3mtO3O9u82bN0uZMmWkatWqMmTIEBk9erTUrl1bD+K+8MILUqlSJdcSCgAAAAAAAABgN0EdtFUXo7jrrrtc94cOHap/9u7dW6ZPny7Dhg2TCxcuyMCBA/X6ZXfccYcsXrzYtf5swLx45aI7BXXl0h652zrgQKH/PQAAAAAAAAD2ENRB21atWvm8iJf7WmYvv/yyvsHTC397XOZ/+bn+Xa33VrJUaalT709yb4eHpH732zzWe1u9fouMHv+hrNm4VVIvpUntpKrSt2sHeWrAwx5rBjoq3yyxsTGyc+VcqZZYyVXeqd9QKVWyhEx/+6Ui/pQAAAAAAABA+AnZNW2Ru+atWsuyjTvk69Vb5L1PZkuT2+6QsS+OkPt7P+W6avO8RculZZdHJbFiOfn2iymyY8Vcear/w3oQt/ugEdkGzdVA+chxk4L0iQAAAAAAAAAEdaYtCicmJlauK1de/16+YiWpd2NDufHmJjKwe0eZ/sUCebjTvfLos6OlQ9s7ZcrYF1yvG9DjQSl/XRnp0Pdv8sX8b6Rbx3aux57o01XenPKpPDuol9SvWysonwsAAAAAAAAIZ8y0tZlbm98pDW+oI3MXLZdvVqyRU6fPyDN/+d9sz3ugbUupU6OafP6fJR7lzZs0kvvbtJDh/xpfhLUGAAAAAAAAYGLQ1obq1qou+w8ekV17f9P369WukePzdu3NfhG0MSOelMXfrZH/rtsU8LoCAAAAAAAA8MSgrQ2pdWrV2rTu93MSEx2dreyGOjWkV5f7ZPi/3g1YHQEAAAAAAAD4xqCtDf2yZ58kVakktZOqXL6/e5/v5+3ep5dI8OWlpx+TTdt3yFeLvw1oXQEAAAAAAAB4YtDWZtatWinbftkjD93XWtq1ul3KlEqQN6bMyPa8+d+skN37fpM+XR/w+T5VKlfQFyX7x6sTJCsrqwhqDgAAAAAAAEBh0NbC0tPT5OSJ43L86BH5ZdsW+fDdN2RI/576QmK9utwvxYvFy+TXnpP/LFkhA4e9Ilt/3qXXuv3o86+kz99GyaM9H5Q/t74jx/cf8UQ/OXI8Wf7v+x+K9HMBAAAAAAAA4Swq2BUISS+mFPotth46I4G26rtl0vqWuhIVFSUlEkrJ9TfUl7+/9Ko8362ZRERcHo/vcn8b+bZsGfnn+I+kRecBcvbceV3+2nN/lWGP97nq+5cpnSB/f7yPnm0LAAAAAAAAoGgwaGtRr7z1nr75EhHhuYZti1tvlsWf3qx/v3QpTTr2+5tM/2KB9O3WUcpeW9r1POPwpmzvNeLJfvoGAAAAAAAAoGiwPEKYiYuLlf9MfUsvn7BybfZBWgAAAAAAAADBxUzbMB24Hf5E32BXAwAAAAAAAIAPzLQFAAAAAAAAgBDCoC0AAAAAAAAAhBAGbQEAAAAAAAAghDBoCwAAAAAAAAAhhEFbAAAAAAAAAAghDNoCAAAAAAAAQAhh0BYAAAAAAAAAQkhUsCsQim78+MYi/fc+bf3ffL/mhb89LvO//Fz/HhUdLRUrJcr9XbrLgCeGyncbNshd/zPQ9dxy15WRO5o2knHPD5Ea1RJd5avXb5HR4z+UNRu3SuqlNKmdVFX6du0gTw14WCIjI/306QAAAAAAAADkBzNtLax5q9aybOMOWbByg/QaOFgmvfmqfDxpvOvxnSvnyZFNS2T25Nfkp5175YE+QyQrK0s/Nm/RcmnZ5VFJrFhOvv1iiuxYMVee6v+wHsTtPmiEGIYRxE8GAAAAAAAAhC8GbS0sJiZWritXXiolVpWuvfrLrXe0ku+WLvaYYVuxfFm5s9ktMvJvj8rPu/bKnn0H5cLFVHn02dHSoe2dMmXsC9Ko/vVSvUolGdDjQfn4rZfky4X/J1/M/yaonw0AAAAAAAAIVwza2khcXJxkZKT7fCw+Llb/TM/IkG9WrJFTp8/IM3/532zPe6BtS6lTo5p8/p8lAa8vAAAAAAAAgOwYtLUBtZTB2v9+J6tXLpemt7fI9vjR48ny+qQZUrlCObm+ZnXZtfc3XV6vdg2f71e3lnrOgYDXGwAAAAAAAEB2XIjMwlYuWyLNrk+UzMwMMZxOad+pizw2dLhc2vq1fjyx8b16QPdi6iVpeEMdmfPBOImJiXa9nnVrAQAAAAAAgNDDoK2FNbm9hTz3zzckOiZaypavKFFRl8N56Y/H/zvvIyl5TXG9tm2Ja4q7XlenRlX985fd++T2Jg2zva8qv6GO71m4AAAAAAAAAAKL5REsLD6+mFRNqiEVK1dxDdi6S6pSWWpWr+IxYKu0bXmblCmVIG9MmZHtNfO/WSG79/0mD3dsF9C6AwAAAAAAAPCNQdswVLxYvEx+7Tn5z5IVMnDYK7L1512y/+AR+ejzr6TP30ZJl/vaSNcObYNdTQAAAAAAACAssTxCmOpyfxv5tmwZ+ef4j6RF5wFyKS1NaidVleee7C9DHu0hDocj2FUEAAAAAAAAwhKDtj5s672t0O+x9dAZCaRX3novx8da3d5YjMObcn2PFrfeLIs/vdnPNQMAAAAAAABQGCyPAAAAAAAAAAAhhEFbAAAAAAAAAAghDNoCAAAAAAAAQAhh0BYAAAAAAAAAQgiDtgAAAAAAAAAQQhi0FRGn0xnsKlia01D/N0ScWcGuCgAAAAAAAGB5URLGYmJiJCIiQo4cOSJly5bV9x0Oh1/e28hMl2C5FKFHUQPOMETSnSLJKZckIvV3iUk9UST/LgAAAAAAAGBnYT1oqwZsk5KS5OjRo3rg1p9OnE6VYIlxJBfdP+bMlGLJP0rVHdMkwsgsun8XAAAAAAAAsKmwHrRV1OzaqlWrSmZmpmRl+e/0/gFzv5NgWRb7TNH8Q4YhkRnnJCr9rDjU8ggAAAAAAAAACi3sB20VtSRCdHS0vvnL4XPBW981LuNg0P5tAAAAAAAAAIVjiQuRTZw4UapXry5xcXFy6623yg8//BDsKgEAAAD5Qk4LAAAA2wzazpo1S4YOHSqjRo2STZs2ScOGDaVdu3Zy4gQXvQIAAIA1kNMCAADAVoO2b775pjz66KPSt29fueGGG2TSpElSrFgxmTp1arCrBgAAAOQJOS0AAABss6Ztenq6bNy4UUaMGOEqi4iIkDZt2siaNWt8viYtLU3fTCkpKfrn77//ri82Zr6HujmdTn1zf291UxckMwwj1/LIyEi9Hq75vu7lzrQLEu01JJ7hFHGoP3q2coe+kJd7ufpnMg2HRIghkb7KHYZEqjf7g9MQyTIcEukw5HfHlbBGiFMiJEuyJEoM/a+b5Vn6Me/ySMnUdckUz/V9VbmIIVnZyjPUqsD6fVzvnRohGZIh6lNFuZUb+n0zJUIiJFIicy136vpl6TL1mEmVqcfUe6t/w7v89OnTeY6Tfp3XBehyKo+KitLvG5lxwS9xinArzzLUYw6JchjicC93qr+DZ7mKrz/ipD+TZOj4u5er91Xvo745Trd4mOVGquGXOHmXq++A+i5Ee9Xdu1y15bzEyb1cxV+3S682711uxtYfcdJ1d6poOCQ6wvNCfZfLJVsfkeIw/BYnVaYe8+4LcipX763arr/iZPLVF+RUrtpuXuLkqns++3JJu+CXOBW0L3fvmwsTp4L25Sq+/ohTQfrys2fP2nabq/oIM7bB2OYqWalZQdvmqnKzXw7ENtdXX37mzJnLn8W9fYe4/Oa05LO0rUC3LfJZ++az+n0zLgQtn1V9RIpDgpbPqn/DzGnJZ8lncyovaF+ucpBAbXP1T7e+uai3uYqKL9tcCa181ghhhw8fVrU3Vq9e7VH+7LPPGk2bNvX5mlGjRunXcOPGjRs3bty4cbPv7eDBg4ZV5DenJZ/lxo0bN27cuHETI9zz2ZCeaVsQagaDWi/MpI6CqBHza6+9Vo9o4+rUbKgqVarIwYMHpWTJksGuDvyM+NoXsbU34mtfxDb/1IyEc+fOSaVKlcSuyGcLj7ZlX8TW3oivfRFbeyO+gclnQ3rQ9rrrrtPTho8fP+5Rru5XqFDB52tiY2P1zV2pUqUCWk87Uo2MhmZfxNe+iK29EV/7Irb5k5CQIFaS35yWfNZ/aFv2RWztjfjaF7G1N+Lr33w2pC9EFhMTI7fccossW7bMY6aBun/bbbcFtW4AAABAXpDTAgAAIL9Ceqatok4N6927tzRu3FiaNm0qb7/9tly4cEFfeRcAAACwAnJaAAAA2GrQtlu3bpKcnCwjR46UY8eOSaNGjWTx4sVSvnz5YFfNltSpeKNGjcp2Sh7sgfjaF7G1N+JrX8Q2fJDTFi3aln0RW3sjvvZFbO2N+AaGQ12NLEDvDQAAAAAAAADIp5Be0xYAAAAAAAAAwg2DtgAAAAAAAAAQQhi0BQAAAAAAAIAQwqAtAAAAAAAAAIQQBm1R5Lj2HWAdTqcz2FVAgNAX2xttFwg8+lHAOtgu2hP9sP05w7ztMmiLIrNx40b90+Fw6J/h3visiriFj5SUFImIYDNh1zZs9sWwH9ouEFjktPZA3MIH20X7IZ8NDym0XQZtUTQ+++wzefjhh6Vbt27yzjvvyKVLl8K+8VnNmjVr9E8zbhzVtLcJEybIDTfcIE888YTMmDEj2NWBn6h4tm/fXrp37y4//fSTnDt3LthVgp/RdoHAIqe1PnLa8MJ20X7IZ8MDbfcyh8FWCkXg1KlTkpWVJW+++aasW7dO9u7dKx988IE0b95cihcvHuzqIRcff/yxfPjhh3qD2L9/f7n77rvlT3/6U7CrhQBbsmSJbNiwQV599VW55557pE+fPtKhQ4dgVwuFcPLkSdm8ebNu0ytXrpS2bdtKjx495K677gp21eBHtF0gcMhprY2cNjyxXbQX8tnwsYS2q48sAgEzePBg/TMrK0v/zMjIME6cOGH07t3bKF26tPHOO+8YycnJQa4lcnP+/Hn98+WXXza6dOlilC1b1vj444+NzMzMYFcNfqbaZHp6ukfZ7t27jTZt2hh33nmnMXbs2KDVDQX32WefZetrVVm3bt2MOnXqGLNmzQpa3eAftF0gsMhp7YGcNnywXbQf8tnwQNv1xLk8CJi1a9fK4cOHJTMz03X6kVpzpmzZsjJ9+nR57LHH5LXXXpMvv/ySNaVCmJqMHx8fr39/4YUX5K233pIhQ4boo1yjRo2SM2fOBLuK8JMVK1boI9bup3mq2US1atWSmTNnSv369WXevHkyfvz4oNYT+fP+++/ruJYpU8ajXJ3e+9xzz8m9994rgwcPlrlz5watjigc2i4QWOS09kBOGz7YLtoP+Wx4oO364DWIC/iNmoHgdDr175988omrPDU11fX7M888YyQkJBg7duzQ983nI/R4x2bmzJmGw+HQMxV8PQ5rMuO4dOlSIy0tzWNW0cmTJ40BAwYYd999t7Fly5ag1hP5Y84gWrNmjXH8+HGPx/bt22c8/vjjRrNmzYxNmzYFqYYoLNouEDjktPZCThse2C7aD/lseKDtemKmLQImKipKz0L49ddfZdiwYXLnnXfq8ri4OElLS9O/jxs3Tlq0aKHXlFJHULj6Y+jYtGmT7N6923XfPTZqpkLPnj1l2rRpemaCWmuG2NmDiuOOHTv02lCq3WZkZOgjnSrm1157rbz88sty8OBBmTRpUrCrijwwZ3ypGC5fvlzatGmjZ4WptcBM1atX1+25WLFisnTpUo/XwTpou0DgkNNaGzlteGK7aB/ks+GFtuvFaxAX8Du1HsnChQuNG2+80bjrrrtc5ZcuXdI/165da7Ru3dpYt26dvs/R7eD79NNPjbi4OKNfv37Gzp07r/rcp556Sh/RPHz4cJHVD4E3e/ZsIz4+3hg6dKhrTSHzCOfKlSuNxMREfZQb1vLss88aNWrUMF5//fVsa4KpsooVKxpnz54NWv1QeLRdIHDIaa2HnBZsF+2HfDY80HYvY6YtAi46Olpf6U+t9XX8+HF9lVYlNjZW/7z55pv1UZM5c+bo+xzdDq5Vq1bJP//5T2nZsqVs375d3n77bdm1a1eOz+/atauO8W+//abvq1jC+rp06aLXDXr33Xdl+PDhriOcSqNGjaRp06aumCP0qVlfytixY3WbVetAqfWikpOTXc95+umnpUGDBq6+GNZE2wUCh5zWWshpobBdtA/y2fBC272MQVsUCZUAqdMYXn/9dZ3ktm7d2uOxkSNH6p+pqalBrSdEjh07Jn/605/0KSfqFD918Y2rJbm33367JCYmyptvvqnvs4NiH507d5Z///vfekM5YsQISU9P1+UlSpSQZs2ayerVq9mhsYjIyEjXKWJjxoyRHj166ET3k08+cZ1aph5Xi/tzIRbro+0CgUNOax3ktDCxXbQH8tnw05m2y/IIKFpqWvuiRYv0aWXqZlILSm/dujWodcNlFy5cMLZt2+a6/9577xk33XSTMWjQINfFNdwXglfUaYBjxoxxnR4Ie5kzZ44+NaV///6uxeDVxVe2b98e7Kohn9zb7fDhw/WpZaNGjTJ+//13XXb69Glj2bJlQawh/Im2CwQOOW3oI6eFN7aL9kA+G37mhHHbdaj/BXvgGNamjmaZ09QzMzP1xRquRk1r/3//7//pUxbU6QzqiBlCm1rke8qUKfpo1tChQ6VSpUoyaNAgefHFFyUpKUnOnz+vL/Bw0003BbuqyEebVd1/XmeRfPrpp/LBBx/oxf/N9o7Q7YtzO7XM7HcHDx6sZyJ9+eWXzCiyUYzd0XaBvCOntT9yWnshp7Uf8tnwQE6bdwzawm/UqUS1atWS++67L9ek1T0RzktSjOB3pirJ/fDDD/UaQZs3b5aUlBTZuXMnsbMwddXNKlWq5CvR9U6SEHrOnTunTxm6Wpzc27YZ//x+DxA8b731ltSsWVM6dOiQr9fRdoG8Iae1H3JaeyOntR/y2fBATpu78Bmeht+Z68koU6dOlVGjRkm1atVyPeqhGhjJrTWoWJpxfuyxx6R79+56XTDVQe7YsUPHzlwQHtayZMkSueWWW3Qcc0tsvI/thcsG0oqmTZsmjRs3dsUpp+Oyqm2rGWKKGX/3Ph2hxT02aobBuHHj9Oyw3NB2gbwhp7U/clr7Iqe1H/JZ+yKnzT8GbVFgZiK7dOlSOXv2rF7Yv2HDhrk2NrOBqdMX1BR3OtbQZp5ypBZ3/+qrr/QGdM2aNfoiG2oHJZw6TCvzbmfXXXedTnAXLFjgWtDdF/ej1WoR+Llz5wa8rsh/XM1Epm3btrps9OjR+n5OOy/q+aoNK+qqrIcOHaItW2B7u2HDBtm2bZu8+uqrrp2ZnNB2gbwjpw0P5LT2QE5rP+Sz4YOcNv8YtEWBO1X1c//+/dKuXTu9JtSJEydy7VTNx9RpSepqj5UrVw6r9UisSsVNXZlRxXvVqlV6NgIzSqzFbGe//PKL/qmS2+bNm8vkyZP1GlCK9wwT7zarZqYUL168yOuO3ONqXiG3QoUK+grZqp1u2bLF52vc46qOcPfq1Uu2bt1ahLVGQXZi1MDCHXfcIR999JGkpaVd9XW0XSBvyGnDDzmt9ZHT2g/5rP2R0xZCsK+EBus6cOCA/rlixQqjUqVKRrt27Yzk5GSfz3U6na7fJ02aZJQqVcr48ssvi6yu8A8zjhkZGcGuCgpg3LhxhsPhMP7xj38Y586d02V//vOfjRYtWmSLsXebTUhIMGbPnh2EWiM3b731lhEdHW188sknxt69e/WVy+vXr28MHTo023O941qyZElj7ty5RVxj5JfZXt955x2jRIkSRteuXXWsfaHtAvlHTht+yGmtjZzWfshnwwM5bf4xaIsCWbx4sVG2bFnj559/1ve/++473eh69eplnD9/PtdOleTWWkhorcm97SkqCVIJrmqr/fr1MyZMmGAsW7bMuO+++/SG09frJk+eTJsN8bgOHz5cx7V79+5G7969ja+++srYuHGjERMTo/tqU1ZWlut3+mLrmDp1qlGjRg3X/TfffNOoWLGiMXLkSOPgwYMez6XtAvlHThteyGmtiZzWfshnww85bcEwaIs8ce8clQ0bNhj33nuvMXbsWOPSpUu67Ntvv9UbTtXJeie5ZmO75pprjDlz5hRZvXF1vo5A5/QcZefOncbZs2eLpG4IzA7KqFGjjMGDBxsvvvii0adPH6NWrVpG27Zt9VHOEydOeLxu4sSJRvHixWmzISolJcX1e8uWLXUcP//8c538qB2YVq1a6X76t99+83jd22+/bZQuXTpsEx+rbG/NvvfQoUO6naq26z7DqHLlyjrJVY97o+0COSOntSdy2vBATms/5LP2RU7rHwzaIl/MWQjKK6+8oo+UmKeUmbMT1GliHTp0MFJTU12N9MiRI/p0lXBubKFExcTsPJcsWWK88cYbPpNc97Lx48cbjRo18og3Qp/aELZp00YfoVYbThVvlcz++OOPemdl2LBh+silOrI9bdo01+vUaSrq9NAvvvgiqPWHb++//77xl7/8xfj666/1/eXLlxvdunUzVq9erROezp07G3Xq1NFxdT9dTLXfG2+80fjss8+CWHvkxe+//65/ZmZmGmPGjNE7LGrGiUn121WrVjWGDBnisXNK2wXyhpzWHshpwwc5rf2Qz4YHctrCYdAWfl07SPnmm2+Me+65J9tMhpzWBkPwzJs3z4iPj9dHM/OyZpuv5yH0d0rVUeu7777b6N+/v5GWlqZnDqkNoGnhwoW6XXufMnj48OEg1Bh5MWXKFOOhhx4ykpKSdPKza9cuY+DAgcbo0aP142rnRbXvJ598UidIpvT0dOPo0aNBrDn8ua6bml3UsWPHbAMUtF3g6shp7Yec1v7Iae2HfNb+yGkLj0Fb+GXtIHV6gi8qyb3aaUoInlWrVul4qlP8vPlas40ZJdZjJqxqh3TGjBlGkyZN9NFqNfsgMTHRZ7tVr6HNWsP+/fuN6dOn61N01WmBql8uU6aMPq1XcY8ja/jZc10399e6zzYD4Imc1t7Iae2PnNa+yGfthZzW/xzqfwJcRWZmpkRFRenfX3zxRTl58qSULVtW9u/fL99//73UqFFDSpUqJe+++66UK1cu2NVFPixatEjat2+f4+OTJ0+WYcOGydSpU+Whhx4q0rqhcMyu3eFwyOnTp6V06dK67K9//ausWrVKt98qVarIvHnzdBuGdWRlZUlkZKRcuHBBihcvLnv27NF9c0ZGhsyePVvq168vixcvlkqVKgW7qsins2fPSsmSJfXvrVq1ktjYWOnbt68MHTpU99V79+6VuLg4mTJlim6/JtW2VVsHcHXktPZFTmtf5LT2RD5rb+S0/hPhx/eCDb3++uu6US1ZskScTqfcfvvtkpycLB07dpTx48dL586dZe3atbpj/frrr4NdXXjJ6ZiM2mlRrpbcqpgOGTJEpk2bRnJrUWqDpxLYBx98UG8Y1X21IzpmzBi5//779Y5p9erVg11N5LNNqwR3zpw50rJlS90f16pVSyZMmCD9+/eXFi1aSHx8vFSoUCHYVUU+TZo0SQ8oqIEHZdSoUXrHtFq1arJ+/Xo5c+aMHDlyRG+PN2zY4PFaklsgd+S01kZOG97Iae2FfNbeyGn9i5m2uKpffvlFBg0apDvVpKQkee+992TgwIFy7NgxfeRLUYmtOsr50ksvuWYvIHiWL1+uO8IOHTroeBT0aNXu3bvlwIED0qZNm4DUE/5xtfjOmjVLHn30Ub2jqtqt2kmNiLh8rO7cuXNyzTXX6Ne6lyP4couH2mnp1auXjBs3Th577LFs3wHz9cTVWj744AOdvG7atEm3VzWwoNpu1apV5bnnntNtdtmyZbqPf+utt/R2GUDekdNaDzlteCGntRfy2fBFTutnAVhyAWG+dhCCR11ZUa0Zc/PNNxvz5893Ldie3zVhvC+4gdCjrmqdExXvCxcuGDVr1jTeeeedbI9d7T6C6/jx41d9/ODBg0aDBg1yXbePNmxNrOsGBAY5rfWQ04YPclr7IZ8FOa3/MNMWPrF2kPX8/PPP0rt3b2ndurX88MMPen0gdSTrvvvu00evWB/GPlRcjx49Kh999JG+r+LqK77qKGaJEiWCVEvkl+pf9+3bJwsWLPDog72pNb/UKWSwD9Z1AwKHnNZ6yGnDBzmt/ZDPhjdyWv9jnjlyxNpB1qJOG1Hr/6h1gBYuXCjFihWTf/3rX/p31XmaSZBJnWoCa3r44Yf1ou0qprt27dJl3vFVSG6tRZ0+NHfuXP37+fPndUxV2/VusyS49sK6bkDgkdNaCzlt+CCntR/y2fBFThsYzLQNc6wdZB/q6NWpU6dcnaC6YqO6uEZqaqqMGDFC75SoTlRtPFXsYH1qg/jyyy/LyJEjXRfWYPaJ9c2cOVOeeuop2bx5s579ZR6xhnWxrhsQeOS09kFOG37Iae2HfNaeyGmLHn+lMLVixQr909eGUDWsixcv6tNVRo8erZNbRTUqc4xfHe00j4LS2EJDdHS0K7lVyW7JkiVl/vz5+miWmkmirt54+PBheeSRR2TixInBri78QMVbncqp4mke0fY1OwHWoi6Qo04datu2rRw6dEgnuO4zFGAtJ06cuOp2UsVYnTb2xhtv6OTWfdtstmWSWyBn5LT2Q04bfshp7Yd81n7IaYODmbZhiLWDwoN5NFPFsVOnTvrnyZMnJTY2VrZt28ZVkW1CrfU2duxYffqJOprduXNnXc7sBGtbv369DB8+XH777Tf59ttvJTExkRkKFsS6bkBgkdOGB3La8EBOaz/ks/ZBThs8DNqGoe3bt0vdunV1grNz5065/vrrdTkbRPsxN4q//vqr1K5dW5o1a6ZnpKgZDGww7ZnkDhkyRK/Zp9Cmrcc9Ziqu6jRQ90Q3MzOTnVOLbW/VNlb1ueagkXvfy0wDoHDIacMHOW14IKe1B/JZ+yGnDR7+qmFInaagOkm1dlDXrl31T4VTUOxHdaJqJoKK8w033CArV67UHa3aUJLc2kfTpk1l2LBhUq5cOX1hlc8++0yXk9xaj3s/rOKqTgOtVq2atGnTRg4cOECCa8Htrepz1bpu6iJHBw8e9Dg9kOQWKBxy2vBBThseyGntgXzWfshpg4e/bBhj7aDwoDrQhg0byqZNm/QGkiOb1pGfqyGrhOjZZ5/VbXj16tUBrRcKx72P9dXf+kp01Smgf//734u0nvAf1nUDAoucNjyQ01oXOa39kM+GJ3LaosfyCGGOtYPCi7qYgzpCBmtRpxLdddddeXruzz//rE8VNS+yQjsOXWZ8coqTe7l7XGFNrOsGBBY5bXghp7Umclr7IZ8NP+S0RYvWEubMU1DKli0r77zzjsybN0+XMzvBnke1SW6tFze1BtS9996rTyW6WptUj6nXqVMGzatyktyGrmnTpskTTzyhf88pTu79sBlXWI8ZwyZNmuhZJlWrVtU7rObsBDVTDEDhkdPaGzmtNZHT2hv5bHghpw0OWgxYOyiEeZ9q4OvUopySHlVubhTVhRrUujOwBjNu6gqdagO4aNEivQ5Ubm3SfN2PP/4oKSkpRVJX5J9KaNRi/lu3bnUlN3kZUFBxPXXqVBHUEP7Eum5A0SGnDV3ktOGJnNa+yGfDDzltcDBoa2OsHWR9Krm5ePGiTJ8+3ZXAmBvFLVu2yLFjx3I9DeX999/XR8DU6YIIbe6JzuzZs6VmzZp6h1PNGsrtdWa81Xp+d955pxw/fjzg9UX+qViphEb1t9u2bdOzwZTc2vGECROkZ8+e+iIsCD2s6wYEFjmt9ZHThhdyWnsjn7UvctoQpNa0hb0tX748z8/96aefjKysLP270+kMYK2QV0uXLjVKlixpjB071lX2xRdfGNWqVTO+//77bM93j9ukSZOM0qVLG7Nnzy6y+qLwVAx37dpldO/e3YiJiTG+/fZbXZ6Zmenzue7xLlOmjDFr1qwirS8K5l//+pfRpk0bY//+/bnGNSEhgbhagBm3nLaf7uXu21sAeUNOa23ktOGHnNb+yGftiZw2dDBoa0PuDWb48OF6A6k60aslrOox99fR6ELHpUuXdIJaq1YtY/LkyXqHpUSJEsaECRNy3TCqxPjLL78s4hqjMKZOnWo8+eST+vetW7ca999/v95J2bJlS7Ykl3hbx6uvvmo888wzxvbt211l3333nVGxYkVj3rx5+r6vwQUzrnPmzAlCrZHftvv444/n+jwGj4C8I6e1F3La8EJOaz/ks+GBnDa0MGhrY3v37jWee+45Y9myZflqcJs2bTJ+//33ANcO+ZGamqqPTKsNYmxsrPH5559fdUfkvffe00enSXasJSMjwxg6dKhx++23u8o2b95sdOrUyahUqZLPJNd99gnxDt2dVLVDWrlyZeOOO+4wHn74YePo0aP6sZdeesmoU6eOkZycnO1177//PjstFmu7Kr7q97zOTFDb25MnTxZZPQGrIqe1D3La8EBOaz/ks+GBnDb0MGhrI+6NRp1q5HA4jKSkJH1kM6+vUx3xNddcY/zyyy8BrSuyM3dE3OOhfjfvq1NJ4uLijHLlyhmvv/666zneR6lVQqRir74DsA4zzir5UacOuZ86qBLbBx980EhMTDQ2bNjg8To1S0XFm0Qo9KlE5uOPPzaaNm1qVKlSxRg4cKAxbtw4o23btsbcuXM9nrtw4ULjuuuu4zRQC7Zd9/45p+cq7777rlGvXj1jx44dRVJPwErIaa2NnDa8kdPaG/msfZHThiYGbW2ItYOs57///a9x7bXXGocOHfL5uNoAlipVSu+AqFNPateu7ZEAedu5c2cAa4uiWhtKzSwybdu2zWjZsqXRoUOHbM9fv359EdcQvnj3sWrWUE5HplVy06dPHyMqKkrvoDz99NMej+/Zs8fn+n4IbazrBvgXOa31kNPCHTmt9ZDPQiGnDR0M2toMawdZ04ULF/TpQubMBPNUBMWcZaBipKSlpek4qTXAZs6c6fE+rNtmz7WhTL/++qtHjH3ttCL4bXnatGmu+2ZbVu34yJEjHs9Vjy1ZskSvGeXe5lkfyhpY1w0ILHJaayKnDV/ktPZBPhteyGlDG4O2NsLaQdbWq1cvfZqJyb1D9D5CqdYUUrNNSHDCc20odmSsfWXsnK7G6p7oIrSxrhsQWOS01kZOG37Iae2FfDZ8kNOGPgZtbYK1g6wfu8OHDxv169c3nn/+eddjagZCbkhyw2ttKNjnytiwPtZ1A/yPnNa6yGlBTmsP5LPhh5w2dDnU/wS2MmbMGFm+fLlMmTJFkpKSdNn27dvliSeekISEBPnPf/7j8fwNGzZI48aNg1RbmC5duiSvvfaaLFu2TPr06SP9+vXT5U6nUyIiIoJdPRRCVlaWREZGuu6rmDocDn3zNmHCBNm4caPMnDlTv27o0KHy+uuvF3GNUdi2vHbtWunRo4f8/vvvMn36dOnevTttOczb7q+//irHjh2T5s2bF1n9Aasjp7Umclr7IqcNH+Sz9kJOa120NotTCdGzzz4rP/30k6vs9ttv1/e3bNniKqtfv75MnTpV5s2b5ypTDVAhuQ0NcXFxMmDAAKlYsaLMmDFDJk2apMvVRlF1qrAutYG8ePGiTnbMmJrtT7XTo0ePup6rdkQ/+OADWbhwoQwaNEheffXVoNUbOVODCIr7cc8/zl7RbfnEiRNy+vRpPahw+PDhbHFHeLVd9b2oWbMmyS1wFeS09kFOa1/ktPZCPhs+yGktLNhTfVFwrB1kT+oKjWotsNtuu83o27evR7yInXWxNpR9+PvK2AhttF0g8Mhp7Ymc1p7YLtoD+Wz4oe1aE4O2NsDaQfZz4sQJY8aMGUbDhg2NRo0aGSNGjDB++OGHYFcLhcDaUPbhrytjwxpou0DRIae1H3Ja+2G7aA/ks+GHtmtNrGlrAawdFN5UTPfu3atPTRk5cqRrTTdYD2tD2Ufv3r1lx44dsm7dOn1fbUrNPnnVqlUepwylpaXJmjVrpEWLFh59OayDtgv4BzlteCOntQ+2i/ZAPht+aLvWQ1QsgLWDwpN5PEXF9M0335R33nmH5NYCWBvK3sy4qovjqH75hRde0PdVgpuenq5/917jKTY2Vlq1aqX7cuIcumi7QOCR04YnclprYrtoX+Sz9kbbtRcGbS1i9erV8tRTT8m4ceP0/aioKJk9e7Z07NhRH7F2b5SqI23btq1MnDhRPy8zMzOodUfBeM86KVmypP7J5PjQ9f3330vXrl31xs89fuYsInXRlL/85S96ptDkyZP1zWzTHLG2BjOuZcqUkS5dusiKFSv0BXGUmJiYXC+wQpxDE20XKDrktOGHnNZ62C7aG/msfdF27Scq2BVA3qjTED766CMZMWKEPiJSu3Zt6d+/vz46Zh4FMxuld2KkklzYh69TCBEabr75Zt1Wd+7cKZUrV9Y7l2b7UzOIHnroIXn//ff1hlIdxVZHM/v27SuVKlWSnj17Brv6KMCVsX/++Wd9ZWwVz8cee8x1ZWxOL7IW2i5QdMhpYSKnDV1sF8MD+az90HbthzVtLYT1R4DQx9pQ4eXAgQN6Xb7du3dL3bp15cMPP3T1x/TN1kLbBYoOOS0Q+tguhg/yWXuh7doLrS/EsP4IYE2sDRWeqlWrpk8vevzxx2XTpk1yyy23yD/+8Q9Zv349Ca5F0HaBwCCnBayJ7WL4IZ+1B9quPdECQwjrjwDWxdpQ4ats2bLyyCOPyObNm/UpvmoG2XvvvSf79u0LdtWQB7RdwP/IaQHrYrsYnshnrY+2a08sDBVCWH8EsD7WhgpP5mlH6srYytmzZ10XWoE10HYB/yGnBayP7WL4IZ+1B9quvbCmbYhh/RHAHlgbCt59OKyBtgv4BzktYA9sF0E+a020XXtg0DbEOsIjR45Iu3btpFOnTvLKK6/ox9SRETWd/WrUDAWSXCC0JCcny5IlS/Tpn6p9t2/fXh588EFp0qRJsKsG4Cpou0DBkdMC9sN2EbAm2q71MWgbYtTaMa+99posW7ZM+vTpI/369dPlHAkBrG3ChAmyd+9efdEVdcQzKSkp2FUCkAe0XaBgyGkBe2K7CFgTbdeaGLQNQeqiDUOHDtVX1e3WrZtef0QhyQWsfzoRa0MB1kDbBQqPnBawD7aLgDXRdq2NQdsQxfojgL2xNhRgTbRdIH/IaQF7Y7sIWBNt1xoYtA1hrD8CAAAAqyOnBQAAyD8GbS2C9UcAAABgdeS0AAAAecOgbYhj/REAAABYHTktAABA/jBoa1GsPwIAAACrI6cFAADwjUFbAAAAAAAAAAghXK4VAAAAAAAAAEIIg7YAAAAAAAAAEEIYtAUAAAAAAACAEMKgLQAAAAAAAACEEAZtAQAAAAAAACCEMGgLAAAAAAAAACGEQVsAAAAAAAAACCEM2gIAAAAAAABACGHQFgAAAAAAAABCCIO2AAAAAAAAACCh4/8Dwl73NJ6O6swAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1400x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_results_with_error_bars(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
