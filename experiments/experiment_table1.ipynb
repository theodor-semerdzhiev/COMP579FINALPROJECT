{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import go here\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))  # Add parent directory to path\n",
    "\n",
    "from environment.knapsackgym import KnapsackEnv, _1_positive_reward, _1_negative_reward, v_i_positive_reward, vr_i_positive_reward, w_i_negative_reward, wr_i_negative_reward\n",
    "from typing import List, Callable, Optional, Union, Tuple, Dict, Any\n",
    "from models.DP_Knapsack import solve_knapsack_dp, solve_KP_instances_with_DP\n",
    "from models.Greedy_Knapsack import solve_problem_instances_greedy\n",
    "from models.KnapsackPPO import KnapsackPPOSolver\n",
    "from models.KnapsackA2C import KnapsackA2C\n",
    "from models.KnapsackQLearning import KnapsackDQN\n",
    "from util.instance_gen import KnapsackInstanceGenerator\n",
    "from util.metrics import evaluate_knapsack_performance\n",
    "from models.KnapsackDRLSolver import KnapsackDRLSolver, run_KPSolver\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Any, Tuple, Callable\n",
    "import time\n",
    "import itertools\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_reward_functions_single_run(\n",
    "    KPSolver_A2C: KnapsackA2C,\n",
    "    KPSolver_DQN: KnapsackDQN,\n",
    "    KPSolver_PPO: KnapsackPPOSolver,\n",
    "    M: int = 10,\n",
    "    instance_type: str = \"RI\",\n",
    "    N: int = 50,\n",
    "    r_range: int = 500,\n",
    "    seed: int = 42,\n",
    "    t_max: int = None,\n",
    "    use_state_aggregation: bool = False,\n",
    "    n_test_instances: int = 5,\n",
    "    verbose: bool = True\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Test different reward function combinations across multiple RL models for the Knapsack problem.\n",
    "    \n",
    "    Args:\n",
    "        M (int): Number of problem instances to generate for training\n",
    "        instance_type (str): Type of knapsack instances to generate ('RI', 'FI', 'HI', 'SS')\n",
    "        N (int): Maximum number of items per problem instance\n",
    "        r_range (int): Range parameter for instance generation\n",
    "        seed (int): Random seed for reproducibility\n",
    "        t_max (int): Maximum training steps (if None, will use default 3*N*10000)\n",
    "        use_state_aggregation (bool): Whether to use state aggregation\n",
    "        n_test_instances (int): Number of test instances to evaluate on\n",
    "        verbose (bool): Whether to print detailed progress information\n",
    "        \n",
    "    Returns:\n",
    "        Dict: Results and metrics for all experiments\n",
    "    \"\"\"\n",
    "    # Set random seeds for reproducibility\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Define the reward function combinations to test\n",
    "    positive_reward_functions = {\n",
    "        'v_i': v_i_positive_reward,\n",
    "        'vr_i': vr_i_positive_reward,\n",
    "        '_1': _1_positive_reward\n",
    "    }\n",
    "    \n",
    "    negative_reward_functions = {\n",
    "        'w_i': w_i_negative_reward,\n",
    "        'wr_i': wr_i_negative_reward,\n",
    "        '_1': _1_negative_reward\n",
    "    }\n",
    "    \n",
    "    # Generate problem instances\n",
    "    gen = KnapsackInstanceGenerator(seed=seed)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Generating {M} {instance_type} training instances with N={N}, R={r_range}\")\n",
    "    \n",
    "    if instance_type == \"RI\":\n",
    "        training_instances = gen.generate_random_instances(M, N, r_range, seed=seed)\n",
    "        test_instances = gen.generate_random_instances(n_test_instances, N, r_range, seed=seed+100)\n",
    "    elif instance_type == \"FI\":\n",
    "        training_instances = gen.generate_fixed_instances(M, N, seed=seed)\n",
    "        test_instances = gen.generate_fixed_instances(n_test_instances, N, seed=seed+100)\n",
    "    elif instance_type == \"HI\":\n",
    "        training_instances = gen.generate_hard_instances(M, N, r_range, seed=seed)\n",
    "        test_instances = gen.generate_hard_instances(n_test_instances, N, r_range, seed=seed+100)\n",
    "    elif instance_type == \"SS\":\n",
    "        training_instances = gen.generate_subset_sum_instances(M, N, r_range, seed=seed)\n",
    "        test_instances = gen.generate_subset_sum_instances(n_test_instances, N, r_range, seed=seed+100)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown instance type: {instance_type}\")\n",
    "    \n",
    "    # Solve instances with DP and Greedy for baselines\n",
    "    if verbose: print(\"Computing DP optimal solutions for training instances...\")\n",
    "    dp_sols_items_train, dp_values_train, dp_weight_train = solve_KP_instances_with_DP(training_instances)\n",
    "\n",
    "    if verbose: print(\"Computing Greedy solutions for training instances...\")\n",
    "    greedy_values_train, greedy_sols_items_train, greedy_weights_train = solve_problem_instances_greedy(training_instances)\n",
    "    \n",
    "    if verbose: print(\"Computing DP optimal solutions for test instances...\")\n",
    "    dp_sols_items_test, dp_values_test, dp_weight_test = solve_KP_instances_with_DP(test_instances)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Computing Greedy solutions for test instances...\")\n",
    "    greedy_values_test, greedy_sols_items_test, greedy_weights_test = solve_problem_instances_greedy(test_instances)\n",
    "    \n",
    "    # Define models to test\n",
    "    model_constructors = {}\n",
    "    if KPSolver_A2C is not None: model_constructors[\"A2C\"] = KPSolver_A2C\n",
    "    if KPSolver_DQN is not None: model_constructors[\"DQN\"] = KPSolver_DQN\n",
    "    if KPSolver_PPO is not None: model_constructors[\"PPO\"] = KPSolver_PPO\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    results = {\n",
    "        'training': {},\n",
    "        'test': {},\n",
    "        'metrics': {},\n",
    "        'config': {\n",
    "            'num_instances': M,\n",
    "            'instance_type': instance_type,\n",
    "            'n_items': N,\n",
    "            'r_range': r_range,\n",
    "            'seed': seed,\n",
    "            't_max': t_max,\n",
    "            'use_state_aggregation': use_state_aggregation\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create all combinations of reward functions and models\n",
    "    reward_combinations = list(itertools.product(\n",
    "        positive_reward_functions.items(),\n",
    "        negative_reward_functions.items()\n",
    "    ))\n",
    "    \n",
    "    # Total count of experiments\n",
    "    total_experiments = len(reward_combinations) * len(model_constructors)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Running {total_experiments} experiments...\")\n",
    "    \n",
    "    experiment_counter = 0\n",
    "    \n",
    "    # Run experiments for each model and reward function combination\n",
    "    for model_name, model in model_constructors.items():\n",
    "        results['training'][model_name] = {}\n",
    "        results['test'][model_name] = {}\n",
    "        results['metrics'][model_name] = {}\n",
    "        \n",
    "        for (pos_name, pos_func), (neg_name, neg_func) in reward_combinations:\n",
    "            experiment_counter += 1\n",
    "            reward_combo_name = f\"(+{pos_name} -{neg_name})\"\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"\\nExperiment {experiment_counter}/{total_experiments}: Testing {model_name} with {reward_combo_name}\")\n",
    "                print(f\"Positive reward: {pos_name}, Negative reward: {neg_name}\")\n",
    "            \n",
    "            # Create environment with specific reward functions\n",
    "            env = KnapsackEnv(\n",
    "                problem_instance=None,\n",
    "                N=N,\n",
    "                positive_reward_function=pos_func,\n",
    "                negative_reward_function=neg_func\n",
    "            )\n",
    "            \n",
    "            # Initialize the model\n",
    "            kp_solver = model\n",
    "            \n",
    "            # Train the model\n",
    "            start_time = time.time()\n",
    "            \n",
    "            solver, solution_values = run_KPSolver(\n",
    "                env=env,\n",
    "                KPSolver=kp_solver,\n",
    "                training_problem_instances=training_instances,\n",
    "                t_max=t_max,\n",
    "                use_state_aggregation=use_state_aggregation,\n",
    "                verbose=verbose\n",
    "            )\n",
    "            \n",
    "            training_time = time.time() - start_time\n",
    "            \n",
    "            # Store training results\n",
    "            results['training'][model_name][reward_combo_name] = {\n",
    "                'solution_values': solution_values,\n",
    "                'training_time': training_time\n",
    "            }\n",
    "            \n",
    "            # Evaluate on test instances\n",
    "            test_values = []\n",
    "            for instance in test_instances:\n",
    "                env.change_problem_instance(instance)\n",
    "                # value, weight, _ = kp_solver.solve(instance)\n",
    "                value, weight, _ = solver.solve(instance)\n",
    "                test_values.append(value)\n",
    "            \n",
    "            # Calculate performance metrics\n",
    "            \n",
    "            # For training instances\n",
    "            train_best_values = solution_values['instance_best_values']\n",
    "            train_metrics = evaluate_knapsack_performance(\n",
    "                train_best_values, \n",
    "                dp_values_train, \n",
    "                greedy_values_train\n",
    "            )\n",
    "            \n",
    "            # For test instances\n",
    "            test_metrics = evaluate_knapsack_performance(\n",
    "                test_values,\n",
    "                dp_values_test,\n",
    "                greedy_values_test\n",
    "            )\n",
    "            \n",
    "            # Store test results and metrics\n",
    "            results['test'][model_name][reward_combo_name] = {\n",
    "                'values': test_values,\n",
    "                'metrics': test_metrics\n",
    "            }\n",
    "            \n",
    "            results['metrics'][model_name][reward_combo_name] = {\n",
    "                'train': train_metrics,\n",
    "                'test': test_metrics\n",
    "            }\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Training metrics for {model_name} with {reward_combo_name}:\")\n",
    "                print(f\"  Val/Opt Ratio: {train_metrics['ValOptRatio']:.2f}%\")\n",
    "                print(f\"  #opt: {train_metrics['#opt']}/{M}\")\n",
    "                print(f\"  Mean percentage error: {train_metrics['mean_percentage_error']:.4f}\")\n",
    "                print(f\"  Mean improvement over greedy: {train_metrics['mean_improvement_over_greedy']:.4f}\")\n",
    "                \n",
    "                print(f\"Test metrics for {model_name} with {reward_combo_name}:\")\n",
    "                print(f\"  Val/Opt Ratio: {test_metrics['ValOptRatio']:.2f}%\")\n",
    "                print(f\"  #opt: {test_metrics['#opt']}/{n_test_instances}\")\n",
    "                print(f\"  Mean percentage error: {test_metrics['mean_percentage_error']:.4f}\")\n",
    "                print(f\"  Mean improvement over greedy: {test_metrics['mean_improvement_over_greedy']:.4f}\")\n",
    "    \n",
    "    # Generate summary table\n",
    "    summary = create_summary_table(results)\n",
    "    results['summary'] = summary\n",
    "    \n",
    "    # Generate visualizations\n",
    "    visualize_results(results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def create_summary_table(results: Dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a summary table of all experiments.\n",
    "    \n",
    "    Args:\n",
    "        results: Results dictionary from test_reward_functions\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Summary table\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for model_name in results['metrics']:\n",
    "        for reward_combo_name, metrics in results['metrics'][model_name].items():\n",
    "            train_metrics = metrics['train']\n",
    "            test_metrics = metrics['test']\n",
    "            \n",
    "            row = {\n",
    "                'Model': model_name,\n",
    "                'Reward': reward_combo_name,\n",
    "                'Train_ValOptRatio': train_metrics['ValOptRatio'],\n",
    "                'Train_#opt': train_metrics['#opt'],\n",
    "                'Train_MAE': train_metrics['mean_absolute_error'],\n",
    "                'Train_MPE': train_metrics['mean_percentage_error'],\n",
    "                'Train_vs_Greedy': train_metrics['mean_improvement_over_greedy'],\n",
    "                'Test_ValOptRatio': test_metrics['ValOptRatio'],\n",
    "                'Test_#opt': test_metrics['#opt'],\n",
    "                'Test_MAE': test_metrics['mean_absolute_error'],\n",
    "                'Test_MPE': test_metrics['mean_percentage_error'],\n",
    "                'Test_vs_Greedy': test_metrics['mean_improvement_over_greedy']\n",
    "            }\n",
    "            \n",
    "            rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "def visualize_results(results: Dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    Generate visualizations for the experiment results.\n",
    "    \n",
    "    Args:\n",
    "        results: Results dictionary from test_reward_functions\n",
    "    \"\"\"\n",
    "    # Compare Val/Opt Ratio across models and reward functions\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    summary_df = results['summary']\n",
    "    \n",
    "    # Create data for grouped bar chart\n",
    "    models = summary_df['Model'].unique()\n",
    "    rewards = summary_df['Reward'].unique()\n",
    "    \n",
    "    width = 0.8 / len(rewards)\n",
    "    x = np.arange(len(models))\n",
    "    \n",
    "    # Training ValOptRatio chart\n",
    "    for i, reward in enumerate(rewards):\n",
    "        values = [summary_df[(summary_df['Model'] == model) & (summary_df['Reward'] == reward)]['Train_ValOptRatio'].values[0] \n",
    "                 for model in models]\n",
    "        ax1.bar(x + i*width - 0.4 + width/2, values, width, label=reward)\n",
    "    \n",
    "    ax1.set_ylabel('Val/Opt Ratio (%)')\n",
    "    ax1.set_title('Training Val/Opt Ratio by Model and Reward')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(models)\n",
    "    ax1.legend(title='Reward')\n",
    "    ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Test ValOptRatio chart\n",
    "    for i, reward in enumerate(rewards):\n",
    "        values = [summary_df[(summary_df['Model'] == model) & (summary_df['Reward'] == reward)]['Test_ValOptRatio'].values[0] \n",
    "                 for model in models]\n",
    "        ax2.bar(x + i*width - 0.4 + width/2, values, width, label=reward)\n",
    "    \n",
    "    ax2.set_ylabel('Val/Opt Ratio (%)')\n",
    "    ax2.set_title('Test Val/Opt Ratio by Model and Reward')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(models)\n",
    "    ax2.legend(title='Reward')\n",
    "    ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('val_opt_ratio_comparison.png')\n",
    "    \n",
    "    # Create heatmap for reward function performance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Reshape data for heatmap\n",
    "    pos_rewards = list(set([r.split('_')[0] for r in rewards]))\n",
    "    neg_rewards = list(set([r.split('_')[1] for r in rewards]))\n",
    "    \n",
    "    heatmap_data = np.zeros((len(models), len(pos_rewards), len(neg_rewards)))\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        for j, pos in enumerate(pos_rewards):\n",
    "            for k, neg in enumerate(neg_rewards):\n",
    "                reward = f\"{pos}_{neg}\"\n",
    "                try:\n",
    "                    val = summary_df[(summary_df['Model'] == model) & (summary_df['Reward'] == reward)]['Test_ValOptRatio'].values[0]\n",
    "                    heatmap_data[i, j, k] = val\n",
    "                except:\n",
    "                    heatmap_data[i, j, k] = 0\n",
    "    \n",
    "    # Create subplots for each model\n",
    "    fig, axes = plt.subplots(1, len(models), figsize=(16, 6))\n",
    "    if len(models) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        im = axes[i].imshow(heatmap_data[i], cmap='viridis')\n",
    "        axes[i].set_title(f'{model}')\n",
    "        axes[i].set_xticks(np.arange(len(neg_rewards)))\n",
    "        axes[i].set_yticks(np.arange(len(pos_rewards)))\n",
    "        axes[i].set_xticklabels(neg_rewards)\n",
    "        axes[i].set_yticklabels(pos_rewards)\n",
    "        axes[i].set_xlabel('Negative Reward')\n",
    "        if i == 0:\n",
    "            axes[i].set_ylabel('Positive Reward')\n",
    "            \n",
    "        # Loop over data dimensions and create text annotations\n",
    "        for j in range(len(pos_rewards)):\n",
    "            for k in range(len(neg_rewards)):\n",
    "                text = axes[i].text(k, j, f\"{heatmap_data[i, j, k]:.1f}\",\n",
    "                            ha=\"center\", va=\"center\", color=\"w\" if heatmap_data[i, j, k] < 70 else \"black\")\n",
    "    \n",
    "    fig.colorbar(im, ax=axes, shrink=0.8, label='Val/Opt Ratio (%)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('reward_function_heatmap.png')\n",
    "    \n",
    "    # Plot convergence over time\n",
    "    for model_name in results['training']:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        for reward_combo_name in results['training'][model_name]:\n",
    "            solution_values = results['training'][model_name][reward_combo_name]['solution_values']\n",
    "            best_sum_over_time = solution_values['best_sum_over_time']\n",
    "            t_values = np.arange(len(best_sum_over_time))\n",
    "            \n",
    "            plt.plot(t_values, best_sum_over_time, label=reward_combo_name)\n",
    "        \n",
    "        plt.xlabel('Training Iterations')\n",
    "        plt.ylabel('Sum of Best Values')\n",
    "        plt.title(f'Convergence for {model_name}')\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'convergence_{model_name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_reward_functions(\n",
    "    KPSolver_A2C: KnapsackA2C,\n",
    "    KPSolver_DQN: KnapsackDQN,\n",
    "    KPSolver_PPO: KnapsackPPOSolver,\n",
    "    M: int = 10,\n",
    "    instance_type: str = \"RI\",\n",
    "    N: int = 50,\n",
    "    r_range: int = 500,\n",
    "    seed: int = 42,\n",
    "    t_max: int = None,\n",
    "    use_state_aggregation: bool = False,\n",
    "    n_test_instances: int = 5,\n",
    "    verbose: bool = True,\n",
    "    n_runs: int = 10  # Number of runs to average results over\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Test different reward function combinations across multiple RL models for the Knapsack problem.\n",
    "    Runs each experiment n_runs times and averages the results.\n",
    "    \n",
    "    Args:\n",
    "        M (int): Number of problem instances to generate for training\n",
    "        instance_type (str): Type of knapsack instances to generate ('RI', 'FI', 'HI', 'SS')\n",
    "        N (int): Maximum number of items per problem instance\n",
    "        r_range (int): Range parameter for instance generation\n",
    "        seed (int): Base random seed for reproducibility\n",
    "        t_max (int): Maximum training steps (if None, will use default 3*N*10000)\n",
    "        use_state_aggregation (bool): Whether to use state aggregation\n",
    "        n_test_instances (int): Number of test instances to evaluate on\n",
    "        verbose (bool): Whether to print detailed progress information\n",
    "        n_runs (int): Number of runs to average results over\n",
    "        \n",
    "    Returns:\n",
    "        Dict: Results and metrics for all experiments, including averaged metrics\n",
    "    \"\"\"\n",
    "    # Define the reward function combinations to test\n",
    "    positive_reward_functions = {\n",
    "        'v_i': v_i_positive_reward,\n",
    "        'vr_i': vr_i_positive_reward,\n",
    "        '_1': _1_positive_reward\n",
    "    }\n",
    "    \n",
    "    negative_reward_functions = {\n",
    "        'w_i': w_i_negative_reward,\n",
    "        'wr_i': wr_i_negative_reward,\n",
    "        '_1': _1_negative_reward\n",
    "    }\n",
    "    \n",
    "    # Create all combinations of reward functions and models\n",
    "    reward_combinations = list(itertools.product(\n",
    "        positive_reward_functions.items(),\n",
    "        negative_reward_functions.items()\n",
    "    ))\n",
    "    \n",
    "    # Define models to test\n",
    "    model_constructors = {}\n",
    "    if KPSolver_A2C is not None: model_constructors[\"A2C\"] = KPSolver_A2C\n",
    "    if KPSolver_DQN is not None: model_constructors[\"DQN\"] = KPSolver_DQN\n",
    "    if KPSolver_PPO is not None: model_constructors[\"PPO\"] = KPSolver_PPO\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    results = {\n",
    "        'training': {},\n",
    "        'test': {},\n",
    "        'metrics': {},\n",
    "        'config': {\n",
    "            'num_instances': M,\n",
    "            'instance_type': instance_type,\n",
    "            'n_items': N,\n",
    "            'r_range': r_range,\n",
    "            'base_seed': seed,\n",
    "            't_max': t_max,\n",
    "            'use_state_aggregation': use_state_aggregation,\n",
    "            'n_runs': n_runs\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Total count of experiments\n",
    "    total_experiments = len(reward_combinations) * len(model_constructors)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Running {total_experiments} experiments, each with {n_runs} runs...\")\n",
    "    \n",
    "    experiment_counter = 0\n",
    "    \n",
    "    # Run experiments for each model and reward function combination\n",
    "    for model_name, model in model_constructors.items():\n",
    "        results['training'][model_name] = {}\n",
    "        results['test'][model_name] = {}\n",
    "        results['metrics'][model_name] = {}\n",
    "        \n",
    "        for (pos_name, pos_func), (neg_name, neg_func) in reward_combinations:\n",
    "            experiment_counter += 1\n",
    "            reward_combo_name = f\"(+{pos_name} -{neg_name})\"\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"\\nExperiment {experiment_counter}/{total_experiments}: Testing {model_name} with {reward_combo_name}\")\n",
    "                print(f\"Positive reward: {pos_name}, Negative reward: {neg_name}\")\n",
    "                print(f\"Running {n_runs} times and averaging results...\")\n",
    "            \n",
    "            # Initialize storage for multiple runs\n",
    "            all_training_values = []\n",
    "            all_test_values = []\n",
    "            all_training_times = []\n",
    "            all_train_metrics = []\n",
    "            all_test_metrics = []\n",
    "            \n",
    "            # Run the experiment n_runs times\n",
    "            for run in range(n_runs):\n",
    "                # Set different seed for each run\n",
    "                run_seed = seed + run * 1000\n",
    "                np.random.seed(run_seed)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"\\nRun {run+1}/{n_runs} (seed={run_seed}):\")\n",
    "                \n",
    "                # Generate problem instances for this run\n",
    "                gen = KnapsackInstanceGenerator(seed=run_seed)\n",
    "                \n",
    "                if instance_type == \"RI\":\n",
    "                    training_instances = gen.generate_random_instances(M, N, r_range, seed=run_seed)\n",
    "                    test_instances = gen.generate_random_instances(n_test_instances, N, r_range, seed=run_seed+100)\n",
    "                elif instance_type == \"FI\":\n",
    "                    training_instances = gen.generate_fixed_instances(M, N, seed=run_seed)\n",
    "                    test_instances = gen.generate_fixed_instances(n_test_instances, N, seed=run_seed+100)\n",
    "                elif instance_type == \"HI\":\n",
    "                    training_instances = gen.generate_hard_instances(M, N, r_range, seed=run_seed)\n",
    "                    test_instances = gen.generate_hard_instances(n_test_instances, N, r_range, seed=run_seed+100)\n",
    "                elif instance_type == \"SS\":\n",
    "                    training_instances = gen.generate_subset_sum_instances(M, N, r_range, seed=run_seed)\n",
    "                    test_instances = gen.generate_subset_sum_instances(n_test_instances, N, r_range, seed=run_seed+100)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown instance type: {instance_type}\")\n",
    "                \n",
    "                # Solve instances with DP and Greedy for baselines\n",
    "                if verbose: print(\"Computing DP optimal solutions for training instances...\")\n",
    "                dp_sols_items_train, dp_values_train, dp_weight_train = solve_KP_instances_with_DP(training_instances)\n",
    "\n",
    "                if verbose: print(\"Computing Greedy solutions for training instances...\")\n",
    "                greedy_values_train, greedy_sols_items_train, greedy_weights_train = solve_problem_instances_greedy(training_instances)\n",
    "                \n",
    "                if verbose: print(\"Computing DP optimal solutions for test instances...\")\n",
    "                dp_sols_items_test, dp_values_test, dp_weight_test = solve_KP_instances_with_DP(test_instances)\n",
    "                \n",
    "                if verbose: print(\"Computing Greedy solutions for test instances...\")\n",
    "                greedy_values_test, greedy_sols_items_test, greedy_weights_test = solve_problem_instances_greedy(test_instances)\n",
    "                \n",
    "                # Create environment with specific reward functions\n",
    "                env = KnapsackEnv(\n",
    "                    problem_instance=None,\n",
    "                    N=N,\n",
    "                    positive_reward_function=pos_func,\n",
    "                    negative_reward_function=neg_func\n",
    "                )\n",
    "                \n",
    "                # Initialize the model\n",
    "                kp_solver = model\n",
    "                \n",
    "                # Train the model\n",
    "                start_time = time.time()\n",
    "                \n",
    "                solver, solution_values = run_KPSolver(\n",
    "                    env=env,\n",
    "                    KPSolver=kp_solver,\n",
    "                    training_problem_instances=training_instances,\n",
    "                    t_max=t_max,\n",
    "                    use_state_aggregation=use_state_aggregation,\n",
    "                    verbose=verbose\n",
    "                )\n",
    "                \n",
    "                training_time = time.time() - start_time\n",
    "                all_training_times.append(training_time)\n",
    "                \n",
    "                # Store training results for this run\n",
    "                all_training_values.append(solution_values)\n",
    "                \n",
    "                # Evaluate on test instances\n",
    "                test_values = []\n",
    "                for instance in test_instances:\n",
    "                    env.change_problem_instance(instance)\n",
    "                    value, weight, _ = solver.solve(instance)\n",
    "                    test_values.append(value)\n",
    "                \n",
    "                all_test_values.append(test_values)\n",
    "                \n",
    "                # Calculate performance metrics for this run\n",
    "                # For training instances\n",
    "                train_best_values = solution_values['instance_best_values']\n",
    "                train_metrics = evaluate_knapsack_performance(\n",
    "                    train_best_values, \n",
    "                    dp_values_train, \n",
    "                    greedy_values_train\n",
    "                )\n",
    "                all_train_metrics.append(train_metrics)\n",
    "                \n",
    "                # For test instances\n",
    "                test_metrics = evaluate_knapsack_performance(\n",
    "                    test_values,\n",
    "                    dp_values_test,\n",
    "                    greedy_values_test\n",
    "                )\n",
    "                all_test_metrics.append(test_metrics)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"Run {run+1} training metrics for {model_name} with {reward_combo_name}:\")\n",
    "                    print(f\"  Val/Opt Ratio: {train_metrics['ValOptRatio']:.2f}%\")\n",
    "                    print(f\"  #opt: {train_metrics['#opt']}/{M}\")\n",
    "                    print(f\"  Mean percentage error: {train_metrics['mean_percentage_error']:.4f}\")\n",
    "                    print(f\"  Mean improvement over greedy: {train_metrics['mean_improvement_over_greedy']:.4f}\")\n",
    "                    \n",
    "                    print(f\"Run {run+1} test metrics for {model_name} with {reward_combo_name}:\")\n",
    "                    print(f\"  Val/Opt Ratio: {test_metrics['ValOptRatio']:.2f}%\")\n",
    "                    print(f\"  #opt: {test_metrics['#opt']}/{n_test_instances}\")\n",
    "                    print(f\"  Mean percentage error: {test_metrics['mean_percentage_error']:.4f}\")\n",
    "                    print(f\"  Mean improvement over greedy: {test_metrics['mean_improvement_over_greedy']:.4f}\")\n",
    "            \n",
    "            # Calculate averages across all runs\n",
    "            avg_training_time = np.mean(all_training_times)\n",
    "            \n",
    "            # Average training metrics\n",
    "            avg_train_metrics = {\n",
    "                'ValOptRatio': np.mean([m['ValOptRatio'] for m in all_train_metrics]),\n",
    "                '#opt': np.mean([m['#opt'] for m in all_train_metrics]),\n",
    "                'mean_percentage_error': np.mean([m['mean_percentage_error'] for m in all_train_metrics]),\n",
    "                'mean_improvement_over_greedy': np.mean([m['mean_improvement_over_greedy'] for m in all_train_metrics])\n",
    "            }\n",
    "            \n",
    "            # Calculate std dev of metrics for error bars\n",
    "            std_train_metrics = {\n",
    "                'ValOptRatio': np.std([m['ValOptRatio'] for m in all_train_metrics]),\n",
    "                '#opt': np.std([m['#opt'] for m in all_train_metrics]),\n",
    "                'mean_percentage_error': np.std([m['mean_percentage_error'] for m in all_train_metrics]),\n",
    "                'mean_improvement_over_greedy': np.std([m['mean_improvement_over_greedy'] for m in all_train_metrics])\n",
    "            }\n",
    "            \n",
    "            # Average test metrics\n",
    "            avg_test_metrics = {\n",
    "                'ValOptRatio': np.mean([m['ValOptRatio'] for m in all_test_metrics]),\n",
    "                '#opt': np.mean([m['#opt'] for m in all_test_metrics]),\n",
    "                'mean_percentage_error': np.mean([m['mean_percentage_error'] for m in all_test_metrics]),\n",
    "                'mean_improvement_over_greedy': np.mean([m['mean_improvement_over_greedy'] for m in all_test_metrics])\n",
    "            }\n",
    "            \n",
    "            # Calculate std dev of test metrics for error bars\n",
    "            std_test_metrics = {\n",
    "                'ValOptRatio': np.std([m['ValOptRatio'] for m in all_test_metrics]),\n",
    "                '#opt': np.std([m['#opt'] for m in all_test_metrics]),\n",
    "                'mean_percentage_error': np.std([m['mean_percentage_error'] for m in all_test_metrics]),\n",
    "                'mean_improvement_over_greedy': np.std([m['mean_improvement_over_greedy'] for m in all_test_metrics])\n",
    "            }\n",
    "            \n",
    "            # Store averaged results\n",
    "            results['training'][model_name][reward_combo_name] = {\n",
    "                'solution_values': all_training_values,  # Store all runs\n",
    "                'avg_training_time': avg_training_time,\n",
    "                'avg_metrics': avg_train_metrics,\n",
    "                'std_metrics': std_train_metrics\n",
    "            }\n",
    "            \n",
    "            results['test'][model_name][reward_combo_name] = {\n",
    "                'values': all_test_values,  # Store all runs\n",
    "                'avg_metrics': avg_test_metrics,\n",
    "                'std_metrics': std_test_metrics\n",
    "            }\n",
    "            \n",
    "            results['metrics'][model_name][reward_combo_name] = {\n",
    "                'train': {\n",
    "                    'avg': avg_train_metrics,\n",
    "                    'std': std_train_metrics,\n",
    "                    'all_runs': all_train_metrics\n",
    "                },\n",
    "                'test': {\n",
    "                    'avg': avg_test_metrics,\n",
    "                    'std': std_test_metrics,\n",
    "                    'all_runs': all_test_metrics\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"\\nAVERAGED RESULTS ({n_runs} runs) for {model_name} with {reward_combo_name}:\")\n",
    "                print(f\"Training metrics:\")\n",
    "                print(f\"  Val/Opt Ratio: {avg_train_metrics['ValOptRatio']:.2f}% ± {std_train_metrics['ValOptRatio']:.2f}%\")\n",
    "                print(f\"  #opt: {avg_train_metrics['#opt']:.2f} ± {std_train_metrics['#opt']:.2f}\")\n",
    "                print(f\"  Mean percentage error: {avg_train_metrics['mean_percentage_error']:.4f} ± {std_train_metrics['mean_percentage_error']:.4f}\")\n",
    "                print(f\"  Mean improvement over greedy: {avg_train_metrics['mean_improvement_over_greedy']:.4f} ± {std_train_metrics['mean_improvement_over_greedy']:.4f}\")\n",
    "                \n",
    "                print(f\"Test metrics:\")\n",
    "                print(f\"  Val/Opt Ratio: {avg_test_metrics['ValOptRatio']:.2f}% ± {std_test_metrics['ValOptRatio']:.2f}%\")\n",
    "                print(f\"  #opt: {avg_test_metrics['#opt']:.2f} ± {std_test_metrics['#opt']:.2f}\")\n",
    "                print(f\"  Mean percentage error: {avg_test_metrics['mean_percentage_error']:.4f} ± {std_test_metrics['mean_percentage_error']:.4f}\")\n",
    "                print(f\"  Mean improvement over greedy: {avg_test_metrics['mean_improvement_over_greedy']:.4f} ± {std_test_metrics['mean_improvement_over_greedy']:.4f}\")\n",
    "    \n",
    "    # Generate summary table with averaged results\n",
    "    summary = create_summary_table_with_std(results, n_runs)\n",
    "    results['summary'] = summary\n",
    "    \n",
    "    # Generate visualizations with error bars\n",
    "    visualize_results_with_error_bars(results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def create_summary_table_with_std(results, n_runs):\n",
    "    \"\"\"\n",
    "    Create a summary table of the experiment results across all models and reward functions,\n",
    "    including standard deviations.\n",
    "    \n",
    "    Args:\n",
    "        results: Dictionary containing experiment results\n",
    "        n_runs: Number of runs performed for each experiment\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Summary table with metrics and standard deviations\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for model_name in results['metrics']:\n",
    "        for reward_combo in results['metrics'][model_name]:\n",
    "            # Training metrics\n",
    "            train_metrics = results['metrics'][model_name][reward_combo]['train']['avg']\n",
    "            train_std = results['metrics'][model_name][reward_combo]['train']['std']\n",
    "            \n",
    "            # Test metrics\n",
    "            test_metrics = results['metrics'][model_name][reward_combo]['test']['avg']\n",
    "            test_std = results['metrics'][model_name][reward_combo]['test']['std']\n",
    "            \n",
    "            # Average training time\n",
    "            avg_training_time = results['training'][model_name][reward_combo]['avg_training_time']\n",
    "            \n",
    "            row = {\n",
    "                'Model': model_name,\n",
    "                'Reward Function': reward_combo,\n",
    "                'Train Val/Opt (%)': f\"{train_metrics['ValOptRatio']:.2f} ± {train_std['ValOptRatio']:.2f}\",\n",
    "                'Train #opt': f\"{train_metrics['#opt']:.2f} ± {train_std['#opt']:.2f}\",\n",
    "                'Train MPE': f\"{train_metrics['mean_percentage_error']:.4f} ± {train_std['mean_percentage_error']:.4f}\",\n",
    "                'Train Imp/Greedy': f\"{train_metrics['mean_improvement_over_greedy']:.4f} ± {train_std['mean_improvement_over_greedy']:.4f}\",\n",
    "                'Test Val/Opt (%)': f\"{test_metrics['ValOptRatio']:.2f} ± {test_std['ValOptRatio']:.2f}\",\n",
    "                'Test #opt': f\"{test_metrics['#opt']:.2f} ± {test_std['#opt']:.2f}\",\n",
    "                'Test MPE': f\"{test_metrics['mean_percentage_error']:.4f} ± {test_std['mean_percentage_error']:.4f}\",\n",
    "                'Test Imp/Greedy': f\"{test_metrics['mean_improvement_over_greedy']:.4f} ± {test_std['mean_improvement_over_greedy']:.4f}\",\n",
    "                'Training Time (s)': f\"{avg_training_time:.2f}\"\n",
    "            }\n",
    "            rows.append(row)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    summary_df = pd.DataFrame(rows)\n",
    "    \n",
    "    # Add note about number of runs\n",
    "    summary_df.attrs['note'] = f\"Results averaged over {n_runs} runs. ± values indicate standard deviation.\"\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "\n",
    "def visualize_results_with_error_bars(results, save_fig:bool=False):\n",
    "    \"\"\"\n",
    "    Generate visualizations of the experiment results with error bars.\n",
    "    \n",
    "    Args:\n",
    "        results: Dictionary containing experiment results\n",
    "    \"\"\"\n",
    "    # Create matplotlib figure\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    models = list(results['metrics'].keys())\n",
    "    reward_combos = []\n",
    "    for model in models:\n",
    "        reward_combos.extend(list(results['metrics'][model].keys()))\n",
    "    reward_combos = list(set(reward_combos))  # Remove duplicates\n",
    "    \n",
    "    # Prepare data for Val/Opt Ratio (test set)\n",
    "    x = np.arange(len(reward_combos))\n",
    "    width = 0.8 / len(models)  # Width of bars\n",
    "    \n",
    "    # Plot Val/Opt Ratio for test set with error bars\n",
    "    plt.subplot(2, 2, 1)\n",
    "    for i, model in enumerate(models):\n",
    "        values = []\n",
    "        errors = []\n",
    "        for reward in reward_combos:\n",
    "            if reward in results['metrics'][model]:\n",
    "                values.append(results['metrics'][model][reward]['test']['avg']['ValOptRatio'])\n",
    "                errors.append(results['metrics'][model][reward]['test']['std']['ValOptRatio'])\n",
    "            else:\n",
    "                values.append(0)\n",
    "                errors.append(0)\n",
    "        \n",
    "        plt.bar(x + i*width - width*(len(models)-1)/2, values, width, label=model, yerr=errors, capsize=3)\n",
    "    \n",
    "    plt.ylabel('Val/Opt Ratio (%)')\n",
    "    plt.title('Test Set Val/Opt Ratio by Model and Reward Function')\n",
    "    plt.xticks(x, reward_combos, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Plot #opt for test set with error bars\n",
    "    plt.subplot(2, 2, 2)\n",
    "    for i, model in enumerate(models):\n",
    "        values = []\n",
    "        errors = []\n",
    "        for reward in reward_combos:\n",
    "            if reward in results['metrics'][model]:\n",
    "                values.append(results['metrics'][model][reward]['test']['avg']['#opt'])\n",
    "                errors.append(results['metrics'][model][reward]['test']['std']['#opt'])\n",
    "            else:\n",
    "                values.append(0)\n",
    "                errors.append(0)\n",
    "        \n",
    "        plt.bar(x + i*width - width*(len(models)-1)/2, values, width, label=model, yerr=errors, capsize=3)\n",
    "    \n",
    "    plt.ylabel('Number of Optimal Solutions')\n",
    "    plt.title('Test Set #opt by Model and Reward Function')\n",
    "    plt.xticks(x, reward_combos, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Plot Mean Percentage Error for test set with error bars\n",
    "    plt.subplot(2, 2, 3)\n",
    "    for i, model in enumerate(models):\n",
    "        values = []\n",
    "        errors = []\n",
    "        for reward in reward_combos:\n",
    "            if reward in results['metrics'][model]:\n",
    "                values.append(results['metrics'][model][reward]['test']['avg']['mean_percentage_error'])\n",
    "                errors.append(results['metrics'][model][reward]['test']['std']['mean_percentage_error'])\n",
    "            else:\n",
    "                values.append(0)\n",
    "                errors.append(0)\n",
    "        \n",
    "        plt.bar(x + i*width - width*(len(models)-1)/2, values, width, label=model, yerr=errors, capsize=3)\n",
    "    \n",
    "    plt.ylabel('Mean Percentage Error')\n",
    "    plt.title('Test Set Mean Percentage Error by Model and Reward Function')\n",
    "    plt.xticks(x, reward_combos, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Plot Mean Improvement over Greedy for test set with error bars\n",
    "    plt.subplot(2, 2, 4)\n",
    "    for i, model in enumerate(models):\n",
    "        values = []\n",
    "        errors = []\n",
    "        for reward in reward_combos:\n",
    "            if reward in results['metrics'][model]:\n",
    "                values.append(results['metrics'][model][reward]['test']['avg']['mean_improvement_over_greedy'])\n",
    "                errors.append(results['metrics'][model][reward]['test']['std']['mean_improvement_over_greedy'])\n",
    "            else:\n",
    "                values.append(0)\n",
    "                errors.append(0)\n",
    "        \n",
    "        plt.bar(x + i*width - width*(len(models)-1)/2, values, width, label=model, yerr=errors, capsize=3)\n",
    "    \n",
    "    plt.ylabel('Mean Improvement over Greedy')\n",
    "    plt.title('Test Set Mean Improvement over Greedy by Model and Reward Function')\n",
    "    plt.xticks(x, reward_combos, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_fig: plt.savefig('experiment_results_with_error_bars.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Create additional visualizations for training performance\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Plot Val/Opt Ratio for training set with error bars\n",
    "    plt.subplot(2, 2, 1)\n",
    "    for i, model in enumerate(models):\n",
    "        values = []\n",
    "        errors = []\n",
    "        for reward in reward_combos:\n",
    "            if reward in results['metrics'][model]:\n",
    "                values.append(results['metrics'][model][reward]['train']['avg']['ValOptRatio'])\n",
    "                errors.append(results['metrics'][model][reward]['train']['std']['ValOptRatio'])\n",
    "            else:\n",
    "                values.append(0)\n",
    "                errors.append(0)\n",
    "        \n",
    "        plt.bar(x + i*width - width*(len(models)-1)/2, values, width, label=model, yerr=errors, capsize=3)\n",
    "    \n",
    "    plt.ylabel('Val/Opt Ratio (%)')\n",
    "    plt.title('Training Set Val/Opt Ratio by Model and Reward Function')\n",
    "    plt.xticks(x, reward_combos, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Plot Training Times\n",
    "    plt.subplot(2, 2, 2)\n",
    "    for i, model in enumerate(models):\n",
    "        values = []\n",
    "        for reward in reward_combos:\n",
    "            if reward in results['training'][model]:\n",
    "                values.append(results['training'][model][reward]['avg_training_time'])\n",
    "            else:\n",
    "                values.append(0)\n",
    "        \n",
    "        plt.bar(x + i*width - width*(len(models)-1)/2, values, width, label=model)\n",
    "    \n",
    "    plt.ylabel('Training Time (seconds)')\n",
    "    plt.title('Average Training Time by Model and Reward Function')\n",
    "    plt.xticks(x, reward_combos, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_fig: plt.savefig('training_performance_with_error_bars.png', dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting\n",
    "This jupyter notebook will be used to generate relevant plots relating to our experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'values': [9, 70, 21, 10, 53], 'weights': [78, 66, 44, 44, 86], 'capacity': 293}, {'values': [76, 20, 37, 47, 50, 5, 55, 16, 75, 69, 93, 75, 37, 97, 42, 33, 91, 38, 8, 47, 80, 19, 47, 13, 69, 48, 34, 23, 57, 67, 95, 44, 17, 84, 63, 71, 10], 'weights': [77, 72, 79, 52, 13, 84, 46, 51, 38, 19, 93, 79, 65, 41, 83, 55, 45, 46, 23, 10, 56, 89, 7, 86, 83, 28, 64, 17, 76, 71, 36, 7, 98, 45, 90, 68, 78], 'capacity': 100}, {'values': [58, 64, 57, 56, 10, 56, 80, 31, 61, 4, 35, 44, 99, 22, 28, 41, 100, 86, 4, 24, 83, 6, 86, 29, 92, 30, 44, 67, 13, 56, 51, 79, 100, 67, 41, 41, 42, 82, 33], 'weights': [84, 44, 81, 85, 39, 90, 29, 24, 69, 64, 14, 84, 20, 81, 1, 80, 79, 79, 67, 48, 71, 28, 79, 56, 46, 51, 57, 4, 14, 25, 12, 44, 67, 66, 48, 86, 57, 8, 77], 'capacity': 58}, {'values': [17, 39, 24, 31, 69, 64, 61, 37, 96, 9, 35, 12, 34, 97, 37, 91, 50], 'weights': [3, 11, 10, 78, 73, 70, 47, 72, 17, 91, 51, 94, 16, 50, 70, 50, 45], 'capacity': 213}, {'values': [55, 18, 47, 86, 2, 76, 50, 72, 67, 44, 31, 63, 15, 59, 10, 65, 63, 9, 76, 42, 79, 5, 18], 'weights': [27, 77, 97, 27, 78, 27, 72, 79, 45, 74, 28, 8, 10, 45, 91, 13, 46, 71, 21, 73, 31, 81, 58], 'capacity': 153}, {'values': [93, 99, 59, 45, 35, 62, 60, 30, 3, 16], 'weights': [33, 67, 15, 68, 11, 18, 59, 80, 18, 30], 'capacity': 288}, {'values': [85, 44, 29, 3, 37, 83, 1, 90, 55, 15, 31, 56, 32, 11, 67, 68, 12, 29, 25, 66, 74], 'weights': [49, 47, 79, 7, 9, 28, 49, 68, 50, 45, 94, 17, 58, 55, 48, 81, 27, 96, 34, 55, 53], 'capacity': 221}, {'values': [47, 32, 3, 78, 34, 67, 42, 38, 89, 10, 74, 75, 38, 27, 1, 94, 95, 25, 4, 13, 7, 84, 90, 16, 75, 18, 37, 60, 72, 88, 5, 20, 29, 32, 100, 78, 33, 98, 50, 51, 44, 15, 94, 2, 18, 23, 28], 'weights': [77, 33, 11, 62, 92, 98, 24, 24, 4, 15, 56, 55, 38, 31, 83, 47, 81, 97, 32, 21, 96, 64, 30, 63, 52, 91, 26, 100, 94, 19, 17, 54, 5, 30, 44, 97, 100, 16, 90, 10, 75, 85, 90, 23, 90, 12, 52], 'capacity': 48}, {'values': [97], 'weights': [68], 'capacity': 45}, {'values': [44, 13, 57, 93, 9, 40, 98, 31, 14, 49, 51, 67, 32, 96, 53], 'weights': [51, 93, 70, 77, 59, 42, 20, 87, 81, 3, 72, 9, 74, 83, 14], 'capacity': 93}, {'values': [12, 66, 97, 87, 28, 46, 54, 25, 27, 24, 100, 75, 85, 82, 96, 11, 89, 7, 48, 60, 36, 15, 20, 83, 32, 32, 93, 15, 92, 93, 60, 17, 16, 29, 58, 16, 46, 12, 55, 3, 71, 6, 20, 18, 84, 6, 43, 60, 52], 'weights': [93, 50, 3, 60, 56, 15, 64, 85, 11, 73, 15, 75, 42, 1, 97, 17, 60, 19, 94, 74, 81, 44, 47, 64, 79, 85, 2, 67, 11, 29, 83, 26, 80, 47, 24, 34, 54, 77, 61, 94, 87, 76, 61, 29, 42, 12, 38, 93, 43], 'capacity': 208}, {'values': [24, 98, 33, 81, 58, 78, 63, 65, 62, 78, 74, 14, 83, 54, 33, 52, 97, 86, 84, 47, 79, 39, 69, 64, 25, 27, 7, 14, 44, 48, 17, 42, 61, 24, 34, 37, 51, 37, 74, 33, 44], 'weights': [40, 83, 32, 99, 51, 74, 88, 80, 86, 54, 5, 50, 19, 89, 24, 23, 25, 65, 58, 95, 42, 29, 5, 1, 38, 93, 53, 90, 11, 10, 84, 11, 6, 41, 93, 69, 10, 84, 85, 81, 91], 'capacity': 120}, {'values': [33, 47, 54, 97, 85, 49, 66, 21, 81, 56], 'weights': [69, 24, 30, 80, 95, 68, 92, 86, 49, 78], 'capacity': 165}, {'values': [73, 60, 6, 10, 53, 62, 17, 18, 13, 57, 1, 58, 48, 47, 68, 53, 73, 77, 93, 80, 52, 50, 24, 60, 14, 94, 85, 12, 79, 12, 73, 9, 49, 66, 73, 42, 93, 78, 21], 'weights': [64, 8, 29, 18, 74, 4, 21, 60, 70, 51, 87, 92, 14, 96, 62, 64, 10, 63, 73, 59, 9, 53, 94, 73, 14, 96, 96, 17, 81, 41, 60, 45, 79, 100, 80, 94, 95, 10, 26], 'capacity': 205}, {'values': [85, 96, 43, 12, 28, 86, 88, 64, 13, 13, 48, 59, 4, 69, 55, 2, 10, 46, 73, 83, 44, 30, 97, 46, 32, 45, 2, 31, 52, 92, 74, 79, 55, 12, 40, 100, 5], 'weights': [34, 74, 90, 82, 77, 64, 28, 80, 37, 54, 32, 32, 16, 97, 15, 9, 94, 56, 44, 74, 39, 13, 73, 18, 56, 95, 94, 37, 79, 62, 48, 14, 38, 66, 99, 1, 72], 'capacity': 265}, {'values': [82, 61, 99, 81, 97, 24, 29, 85, 25, 6, 67, 81, 97, 93, 13, 78, 85, 70, 82, 84, 45, 5, 46, 21, 12, 13, 70, 51, 54, 75, 55, 64, 9, 86, 45], 'weights': [29, 78, 84, 5, 11, 67, 100, 3, 67, 14, 66, 63, 10, 69, 90, 87, 3, 25, 25, 46, 15, 86, 78, 81, 20, 2, 92, 29, 66, 91, 4, 1, 1, 16, 6], 'capacity': 55}, {'values': [55, 31, 42, 58, 54, 70, 26, 65, 45, 95, 16, 15, 47, 51, 70, 41, 92, 48, 13, 12, 98, 14, 95, 28, 10, 31, 62, 43, 79, 62, 41, 64, 98, 42, 16, 41, 85, 22, 95, 59, 61], 'weights': [74, 6, 20, 2, 28, 10, 71, 53, 99, 75, 62, 51, 6, 8, 62, 1, 5, 22, 89, 46, 71, 42, 18, 38, 10, 78, 19, 38, 99, 60, 46, 55, 79, 26, 64, 88, 58, 45, 15, 25, 95], 'capacity': 102}, {'values': [39, 50, 5, 12, 6, 8, 87, 85, 83, 6, 8, 29, 57, 34, 49, 18, 74, 32, 7, 75, 91, 2, 44, 83, 71, 86, 42, 38, 71, 16, 24, 61, 67, 12, 51, 37, 51, 96, 8, 100, 45, 78, 43, 32, 78, 69, 15], 'weights': [4, 30, 42, 48, 48, 15, 23, 10, 58, 36, 57, 59, 71, 55, 65, 59, 66, 62, 32, 25, 79, 35, 55, 20, 44, 53, 63, 53, 37, 97, 52, 81, 74, 56, 89, 13, 93, 86, 51, 74, 53, 27, 80, 25, 32, 52, 84], 'capacity': 215}, {'values': [16, 31, 19, 25, 91, 95, 5, 64, 24, 20, 30, 20, 50, 100, 59, 73, 50, 2, 9, 27, 25, 85, 85, 86, 64, 56, 65, 41, 68, 80, 77, 62, 6, 73, 37, 75, 54, 89], 'weights': [39, 93, 65, 34, 2, 68, 21, 76, 53, 47, 17, 72, 17, 42, 84, 93, 99, 96, 56, 21, 84, 81, 100, 66, 15, 51, 45, 85, 40, 33, 9, 84, 76, 5, 44, 48, 47, 92], 'capacity': 108}, {'values': [42, 28, 18, 71, 53, 64, 72, 99, 81, 63, 88, 48, 99, 77, 66, 91, 52, 73, 29, 97, 63, 79, 47, 87, 8, 12, 51, 74, 81, 45, 65, 56, 97, 66, 42, 97, 11, 99, 16, 29, 83, 74, 98, 75, 64, 35, 1], 'weights': [85, 34, 49, 54, 77, 69, 86, 37, 51, 44, 91, 31, 59, 13, 86, 39, 35, 59, 50, 85, 54, 52, 11, 3, 40, 100, 92, 63, 64, 40, 18, 1, 34, 32, 20, 26, 3, 61, 93, 70, 45, 43, 31, 15, 60, 57, 1], 'capacity': 46}, {'values': [65, 9, 23, 56, 55, 81, 27, 93, 45, 83, 24, 4, 6, 38, 96], 'weights': [5, 51, 78, 97, 49, 88, 99, 86, 47, 33, 98, 25, 42, 8, 80], 'capacity': 24}, {'values': [24, 86, 45, 1, 96, 52, 27, 68, 54, 3, 76, 41, 70, 90, 62, 68, 26, 24, 42], 'weights': [11, 94, 68, 77, 72, 66, 78, 1, 87, 74, 74, 40, 81, 39, 5, 91, 24, 11, 63], 'capacity': 258}, {'values': [78, 41, 54, 14, 12, 58, 19, 100, 86, 71, 74, 60, 7, 40, 50, 92, 22, 50, 35, 14, 11, 37, 9, 7, 36, 21, 56], 'weights': [35, 78, 86, 91, 30, 71, 60, 45, 40, 12, 28, 55, 89, 87, 19, 68, 9, 68, 35, 45, 72, 43, 81, 54, 100, 64, 30], 'capacity': 15}, {'values': [90, 39, 24, 57, 33, 90, 91, 31, 53, 99, 75, 22, 60, 62, 66, 3], 'weights': [46, 97, 64, 89, 35, 45, 43, 89, 96, 97, 76, 51, 55, 99, 29, 35], 'capacity': 97}, {'values': [14, 4, 94, 96, 74, 11, 30, 5, 6, 25, 58, 7, 99, 46, 27, 52, 80, 32, 5, 6, 86, 12, 64, 39, 78, 7, 90, 70, 45, 21, 98, 31, 50, 40, 24, 42, 16, 1, 29, 12, 42, 87, 17], 'weights': [25, 30, 33, 18, 16, 35, 88, 1, 29, 7, 57, 26, 80, 59, 79, 64, 44, 87, 48, 95, 100, 59, 68, 26, 82, 68, 91, 27, 79, 48, 19, 18, 57, 32, 11, 43, 66, 32, 96, 78, 52, 94, 44], 'capacity': 10}]\n",
      "Running 27 experiments, each with 10 runs...\n",
      "\n",
      "Experiment 1/27: Testing A2C with (+v_i -w_i)\n",
      "Positive reward: v_i, Negative reward: w_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 5.4\n",
      "Run 1 training metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 65.65%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2787\n",
      "  Mean improvement over greedy: -0.2539\n",
      "Run 1 test metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 76.91%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.1526\n",
      "  Mean improvement over greedy: -0.1161\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -36.34375\n",
      "Run 2 training metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 74.82%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.1832\n",
      "  Mean improvement over greedy: -0.1631\n",
      "Run 2 test metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 60.12%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2419\n",
      "  Mean improvement over greedy: -0.2419\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -25.86111111111111\n",
      "Run 3 training metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 64.26%\n",
      "  #opt: 1/25\n",
      "  Mean percentage error: 0.3305\n",
      "  Mean improvement over greedy: -0.3171\n",
      "Run 3 test metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 56.68%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4751\n",
      "  Mean improvement over greedy: -0.4552\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -45.24390243902439\n",
      "Run 4 training metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 63.21%\n",
      "  #opt: 7/25\n",
      "  Mean percentage error: 0.2596\n",
      "  Mean improvement over greedy: -0.2381\n",
      "Run 4 test metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 54.71%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4337\n",
      "  Mean improvement over greedy: -0.4143\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -48.09090909090909\n",
      "Run 5 training metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 61.89%\n",
      "  #opt: 2/25\n",
      "  Mean percentage error: 0.3402\n",
      "  Mean improvement over greedy: -0.3183\n",
      "Run 5 test metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 54.85%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4956\n",
      "  Mean improvement over greedy: -0.4579\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -33.375\n",
      "Run 6 training metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 57.96%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2935\n",
      "  Mean improvement over greedy: -0.2782\n",
      "Run 6 test metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 47.54%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4416\n",
      "  Mean improvement over greedy: -0.4324\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -13.0\n",
      "Run 7 training metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 61.95%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2937\n",
      "  Mean improvement over greedy: -0.2820\n",
      "Run 7 test metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 52.01%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3561\n",
      "  Mean improvement over greedy: -0.3431\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -41.40909090909091\n",
      "Run 8 training metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 61.54%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2915\n",
      "  Mean improvement over greedy: -0.2733\n",
      "Run 8 test metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 70.80%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2676\n",
      "  Mean improvement over greedy: -0.2481\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -19.636363636363637\n",
      "Run 9 training metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 61.80%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.3298\n",
      "  Mean improvement over greedy: -0.3140\n",
      "Run 9 test metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 54.30%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3769\n",
      "  Mean improvement over greedy: -0.3660\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -35.708333333333336\n",
      "Run 10 training metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 70.93%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2422\n",
      "  Mean improvement over greedy: -0.2316\n",
      "Run 10 test metrics for A2C with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 61.14%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3438\n",
      "  Mean improvement over greedy: -0.3174\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for A2C with (+v_i -w_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 64.40% ± 4.72%\n",
      "  #opt: 4.50 ± 1.86\n",
      "  Mean percentage error: 0.2843 ± 0.0449\n",
      "  Mean improvement over greedy: -0.2670 ± 0.0456\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 58.91% ± 8.42%\n",
      "  #opt: 0.80 ± 0.60\n",
      "  Mean percentage error: 0.3585 ± 0.1048\n",
      "  Mean improvement over greedy: -0.3393 ± 0.1052\n",
      "\n",
      "Experiment 2/27: Testing A2C with (+v_i -wr_i)\n",
      "Positive reward: v_i, Negative reward: wr_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 28.385665529010236\n",
      "Run 1 training metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 65.39%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2714\n",
      "  Mean improvement over greedy: -0.2466\n",
      "Run 1 test metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 63.31%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2891\n",
      "  Mean improvement over greedy: -0.2525\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 8.204966641957006\n",
      "Run 2 training metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 80.32%\n",
      "  #opt: 9/25\n",
      "  Mean percentage error: 0.1513\n",
      "  Mean improvement over greedy: -0.1313\n",
      "Run 2 test metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 69.06%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.1811\n",
      "  Mean improvement over greedy: -0.1811\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 9.829924242424244\n",
      "Run 3 training metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 63.43%\n",
      "  #opt: 0/25\n",
      "  Mean percentage error: 0.3331\n",
      "  Mean improvement over greedy: -0.3197\n",
      "Run 3 test metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 65.78%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3855\n",
      "  Mean improvement over greedy: -0.3656\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 1.8465982028241337\n",
      "Run 4 training metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 69.58%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2089\n",
      "  Mean improvement over greedy: -0.1874\n",
      "Run 4 test metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 63.66%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.2885\n",
      "  Mean improvement over greedy: -0.2691\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 15.064516129032258\n",
      "Run 5 training metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 71.02%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2403\n",
      "  Mean improvement over greedy: -0.2184\n",
      "Run 5 test metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 50.60%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4780\n",
      "  Mean improvement over greedy: -0.4403\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 7.65625\n",
      "Run 6 training metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 65.57%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2401\n",
      "  Mean improvement over greedy: -0.2248\n",
      "Run 6 test metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 40.07%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5856\n",
      "  Mean improvement over greedy: -0.5764\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 14.547029702970297\n",
      "Run 7 training metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 67.85%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2483\n",
      "  Mean improvement over greedy: -0.2365\n",
      "Run 7 test metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 41.99%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4359\n",
      "  Mean improvement over greedy: -0.4229\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 4.042207792207792\n",
      "Run 8 training metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 69.09%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2445\n",
      "  Mean improvement over greedy: -0.2263\n",
      "Run 8 test metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 82.57%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.1731\n",
      "  Mean improvement over greedy: -0.1536\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 15.656149732620321\n",
      "Run 9 training metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 70.18%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.2569\n",
      "  Mean improvement over greedy: -0.2411\n",
      "Run 9 test metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 50.91%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4762\n",
      "  Mean improvement over greedy: -0.4654\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 10.709469696969705\n",
      "Run 10 training metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 74.63%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2145\n",
      "  Mean improvement over greedy: -0.2039\n",
      "Run 10 test metrics for A2C with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 49.14%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3626\n",
      "  Mean improvement over greedy: -0.3362\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for A2C with (+v_i -wr_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 69.71% ± 4.67%\n",
      "  #opt: 4.90 ± 2.21\n",
      "  Mean percentage error: 0.2409 ± 0.0442\n",
      "  Mean improvement over greedy: -0.2236 ± 0.0453\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 57.71% ± 12.68%\n",
      "  #opt: 0.70 ± 0.64\n",
      "  Mean percentage error: 0.3656 ± 0.1271\n",
      "  Mean improvement over greedy: -0.3463 ± 0.1271\n",
      "\n",
      "Experiment 3/27: Testing A2C with (+v_i -_1)\n",
      "Positive reward: v_i, Negative reward: _1\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 30.4\n",
      "Run 1 training metrics for A2C with (+v_i -_1):\n",
      "  Val/Opt Ratio: 64.67%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2839\n",
      "  Mean improvement over greedy: -0.2591\n",
      "Run 1 test metrics for A2C with (+v_i -_1):\n",
      "  Val/Opt Ratio: 58.34%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3183\n",
      "  Mean improvement over greedy: -0.2818\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 5.2105263157894735\n",
      "Run 2 training metrics for A2C with (+v_i -_1):\n",
      "  Val/Opt Ratio: 73.72%\n",
      "  #opt: 8/25\n",
      "  Mean percentage error: 0.1999\n",
      "  Mean improvement over greedy: -0.1798\n",
      "Run 2 test metrics for A2C with (+v_i -_1):\n",
      "  Val/Opt Ratio: 43.13%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.3512\n",
      "  Mean improvement over greedy: -0.3512\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 14.972222222222221\n",
      "Run 3 training metrics for A2C with (+v_i -_1):\n",
      "  Val/Opt Ratio: 67.79%\n",
      "  #opt: 0/25\n",
      "  Mean percentage error: 0.2935\n",
      "  Mean improvement over greedy: -0.2801\n",
      "Run 3 test metrics for A2C with (+v_i -_1):\n",
      "  Val/Opt Ratio: 73.98%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3268\n",
      "  Mean improvement over greedy: -0.3069\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 5.7317073170731705\n",
      "Run 4 training metrics for A2C with (+v_i -_1):\n",
      "  Val/Opt Ratio: 68.25%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2346\n",
      "  Mean improvement over greedy: -0.2131\n",
      "Run 4 test metrics for A2C with (+v_i -_1):\n",
      "  Val/Opt Ratio: 60.56%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2760\n",
      "  Mean improvement over greedy: -0.2567\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 1.048780487804878\n",
      "Run 5 training metrics for A2C with (+v_i -_1):\n",
      "  Val/Opt Ratio: 71.62%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.2491\n",
      "  Mean improvement over greedy: -0.2272\n",
      "Run 5 test metrics for A2C with (+v_i -_1):\n",
      "  Val/Opt Ratio: 52.88%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3869\n",
      "  Mean improvement over greedy: -0.3492\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 65.5\n",
      "Run 6 training metrics for A2C with (+v_i -_1):\n",
      "  Val/Opt Ratio: 67.13%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2454\n",
      "  Mean improvement over greedy: -0.2301\n",
      "Run 6 test metrics for A2C with (+v_i -_1):\n",
      "  Val/Opt Ratio: 44.55%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5545\n",
      "  Mean improvement over greedy: -0.5453\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 15.25\n",
      "Run 7 training metrics for A2C with (+v_i -_1):\n",
      "  Val/Opt Ratio: 65.12%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2725\n",
      "  Mean improvement over greedy: -0.2607\n",
      "Run 7 test metrics for A2C with (+v_i -_1):\n",
      "  Val/Opt Ratio: 42.67%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4104\n",
      "  Mean improvement over greedy: -0.3974\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 6.545454545454546\n",
      "Run 8 training metrics for A2C with (+v_i -_1):\n",
      "  Val/Opt Ratio: 66.42%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.2749\n",
      "  Mean improvement over greedy: -0.2568\n",
      "Run 8 test metrics for A2C with (+v_i -_1):\n",
      "  Val/Opt Ratio: 82.09%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.1695\n",
      "  Mean improvement over greedy: -0.1499\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 16.545454545454547\n",
      "Run 9 training metrics for A2C with (+v_i -_1):\n",
      "  Val/Opt Ratio: 75.50%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.2374\n",
      "  Mean improvement over greedy: -0.2216\n",
      "Run 9 test metrics for A2C with (+v_i -_1):\n",
      "  Val/Opt Ratio: 48.21%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4608\n",
      "  Mean improvement over greedy: -0.4500\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 5.166666666666667\n",
      "Run 10 training metrics for A2C with (+v_i -_1):\n",
      "  Val/Opt Ratio: 76.14%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2085\n",
      "  Mean improvement over greedy: -0.1979\n",
      "Run 10 test metrics for A2C with (+v_i -_1):\n",
      "  Val/Opt Ratio: 64.49%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3223\n",
      "  Mean improvement over greedy: -0.2959\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for A2C with (+v_i -_1):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 69.64% ± 4.05%\n",
      "  #opt: 4.20 ± 2.04\n",
      "  Mean percentage error: 0.2500 ± 0.0297\n",
      "  Mean improvement over greedy: -0.2326 ± 0.0298\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 57.09% ± 12.79%\n",
      "  #opt: 0.70 ± 0.64\n",
      "  Mean percentage error: 0.3577 ± 0.0994\n",
      "  Mean improvement over greedy: -0.3384 ± 0.1035\n",
      "\n",
      "Experiment 4/27: Testing A2C with (+vr_i -w_i)\n",
      "Positive reward: vr_i, Negative reward: w_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -8.798621472714654\n",
      "Run 1 training metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 70.14%\n",
      "  #opt: 7/25\n",
      "  Mean percentage error: 0.2427\n",
      "  Mean improvement over greedy: -0.2178\n",
      "Run 1 test metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 48.73%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3713\n",
      "  Mean improvement over greedy: -0.3347\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -29.88961547060138\n",
      "Run 2 training metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 75.26%\n",
      "  #opt: 8/25\n",
      "  Mean percentage error: 0.1834\n",
      "  Mean improvement over greedy: -0.1633\n",
      "Run 2 test metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 56.66%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2762\n",
      "  Mean improvement over greedy: -0.2762\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -41.83057678541408\n",
      "Run 3 training metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 70.34%\n",
      "  #opt: 2/25\n",
      "  Mean percentage error: 0.2576\n",
      "  Mean improvement over greedy: -0.2443\n",
      "Run 3 test metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 68.15%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2664\n",
      "  Mean improvement over greedy: -0.2466\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -51.52915062045357\n",
      "Run 4 training metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 65.53%\n",
      "  #opt: 8/25\n",
      "  Mean percentage error: 0.2389\n",
      "  Mean improvement over greedy: -0.2174\n",
      "Run 4 test metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 69.03%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2156\n",
      "  Mean improvement over greedy: -0.1962\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -50.27795808200018\n",
      "Run 5 training metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 65.86%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.3068\n",
      "  Mean improvement over greedy: -0.2849\n",
      "Run 5 test metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 56.55%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3257\n",
      "  Mean improvement over greedy: -0.2880\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -44.99778268417875\n",
      "Run 6 training metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 61.56%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.3323\n",
      "  Mean improvement over greedy: -0.3171\n",
      "Run 6 test metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 45.85%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4669\n",
      "  Mean improvement over greedy: -0.4577\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -32.991776677667765\n",
      "Run 7 training metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 64.87%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2865\n",
      "  Mean improvement over greedy: -0.2747\n",
      "Run 7 test metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 45.59%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4183\n",
      "  Mean improvement over greedy: -0.4053\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -33.41757121362957\n",
      "Run 8 training metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 63.64%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2967\n",
      "  Mean improvement over greedy: -0.2785\n",
      "Run 8 test metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 61.81%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3563\n",
      "  Mean improvement over greedy: -0.3367\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -36.17922340232389\n",
      "Run 9 training metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 75.34%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2054\n",
      "  Mean improvement over greedy: -0.1895\n",
      "Run 9 test metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 45.63%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5481\n",
      "  Mean improvement over greedy: -0.5373\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -44.28408680321983\n",
      "Run 10 training metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 79.21%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.1980\n",
      "  Mean improvement over greedy: -0.1873\n",
      "Run 10 test metrics for A2C with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 43.03%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4671\n",
      "  Mean improvement over greedy: -0.4407\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for A2C with (+vr_i -w_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 69.18% ± 5.56%\n",
      "  #opt: 4.90 ± 1.97\n",
      "  Mean percentage error: 0.2548 ± 0.0476\n",
      "  Mean improvement over greedy: -0.2375 ± 0.0478\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 54.10% ± 9.25%\n",
      "  #opt: 1.10 ± 0.54\n",
      "  Mean percentage error: 0.3712 ± 0.0992\n",
      "  Mean improvement over greedy: -0.3519 ± 0.1010\n",
      "\n",
      "Experiment 5/27: Testing A2C with (+vr_i -wr_i)\n",
      "Positive reward: vr_i, Negative reward: wr_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.005276762817043792\n",
      "Run 1 training metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 69.72%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2344\n",
      "  Mean improvement over greedy: -0.2096\n",
      "Run 1 test metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 52.82%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3192\n",
      "  Mean improvement over greedy: -0.2826\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.5140925096030731\n",
      "Run 2 training metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 73.85%\n",
      "  #opt: 7/25\n",
      "  Mean percentage error: 0.1807\n",
      "  Mean improvement over greedy: -0.1607\n",
      "Run 2 test metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 51.33%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.3090\n",
      "  Mean improvement over greedy: -0.3090\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.20395254671522786\n",
      "Run 3 training metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 68.73%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.2907\n",
      "  Mean improvement over greedy: -0.2773\n",
      "Run 3 test metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 43.43%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.6155\n",
      "  Mean improvement over greedy: -0.5956\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -1.3542035984269623\n",
      "Run 4 training metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 66.37%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2359\n",
      "  Mean improvement over greedy: -0.2144\n",
      "Run 4 test metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 61.46%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2735\n",
      "  Mean improvement over greedy: -0.2541\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -1.7180260512282546\n",
      "Run 5 training metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 67.38%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.2827\n",
      "  Mean improvement over greedy: -0.2609\n",
      "Run 5 test metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 62.12%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4132\n",
      "  Mean improvement over greedy: -0.3755\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.5292102357825647\n",
      "Run 6 training metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 61.53%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2881\n",
      "  Mean improvement over greedy: -0.2729\n",
      "Run 6 test metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 48.15%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4804\n",
      "  Mean improvement over greedy: -0.4712\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.1493463299818354\n",
      "Run 7 training metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 65.63%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2752\n",
      "  Mean improvement over greedy: -0.2635\n",
      "Run 7 test metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 45.02%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4563\n",
      "  Mean improvement over greedy: -0.4433\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.31444494094755415\n",
      "Run 8 training metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 65.27%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2659\n",
      "  Mean improvement over greedy: -0.2477\n",
      "Run 8 test metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 78.93%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2077\n",
      "  Mean improvement over greedy: -0.1881\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.1668184291252342\n",
      "Run 9 training metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 69.25%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2705\n",
      "  Mean improvement over greedy: -0.2546\n",
      "Run 9 test metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 47.94%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4939\n",
      "  Mean improvement over greedy: -0.4831\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.3383086460069052\n",
      "Run 10 training metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 82.11%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.1820\n",
      "  Mean improvement over greedy: -0.1713\n",
      "Run 10 test metrics for A2C with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 46.51%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4219\n",
      "  Mean improvement over greedy: -0.3955\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for A2C with (+vr_i -wr_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 68.98% ± 5.35%\n",
      "  #opt: 4.80 ± 1.33\n",
      "  Mean percentage error: 0.2506 ± 0.0392\n",
      "  Mean improvement over greedy: -0.2333 ± 0.0398\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 53.77% ± 10.35%\n",
      "  #opt: 0.80 ± 0.75\n",
      "  Mean percentage error: 0.3990 ± 0.1155\n",
      "  Mean improvement over greedy: -0.3798 ± 0.1170\n",
      "\n",
      "Experiment 6/27: Testing A2C with (+vr_i -_1)\n",
      "Positive reward: vr_i, Negative reward: _1\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.19871635759007772\n",
      "Run 1 training metrics for A2C with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 73.68%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.1986\n",
      "  Mean improvement over greedy: -0.1738\n",
      "Run 1 test metrics for A2C with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 57.18%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3402\n",
      "  Mean improvement over greedy: -0.3036\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.8404822876653862\n",
      "Run 2 training metrics for A2C with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 78.43%\n",
      "  #opt: 10/25\n",
      "  Mean percentage error: 0.1543\n",
      "  Mean improvement over greedy: -0.1343\n",
      "Run 2 test metrics for A2C with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 54.53%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2874\n",
      "  Mean improvement over greedy: -0.2874\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.7725922198475861\n",
      "Run 3 training metrics for A2C with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 65.83%\n",
      "  #opt: 0/25\n",
      "  Mean percentage error: 0.2935\n",
      "  Mean improvement over greedy: -0.2801\n",
      "Run 3 test metrics for A2C with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 64.71%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3351\n",
      "  Mean improvement over greedy: -0.3153\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.8389538661468485\n",
      "Run 4 training metrics for A2C with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 67.13%\n",
      "  #opt: 7/25\n",
      "  Mean percentage error: 0.2438\n",
      "  Mean improvement over greedy: -0.2223\n",
      "Run 4 test metrics for A2C with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 51.44%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3896\n",
      "  Mean improvement over greedy: -0.3702\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.6449726466704395\n",
      "Run 5 training metrics for A2C with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 67.70%\n",
      "  #opt: 2/25\n",
      "  Mean percentage error: 0.2886\n",
      "  Mean improvement over greedy: -0.2668\n",
      "Run 5 test metrics for A2C with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 67.14%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3369\n",
      "  Mean improvement over greedy: -0.2992\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.8727277521342068\n",
      "Run 6 training metrics for A2C with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 61.81%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2805\n",
      "  Mean improvement over greedy: -0.2653\n",
      "Run 6 test metrics for A2C with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 44.72%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5222\n",
      "  Mean improvement over greedy: -0.5130\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.4917766776677668\n",
      "Run 7 training metrics for A2C with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 61.55%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.3030\n",
      "  Mean improvement over greedy: -0.2912\n",
      "Run 7 test metrics for A2C with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 45.64%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4206\n",
      "  Mean improvement over greedy: -0.4076\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.800252870660824\n",
      "Run 8 training metrics for A2C with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 67.81%\n",
      "  #opt: 8/25\n",
      "  Mean percentage error: 0.2426\n",
      "  Mean improvement over greedy: -0.2245\n",
      "Run 8 test metrics for A2C with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 75.83%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2493\n",
      "  Mean improvement over greedy: -0.2298\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.6329797782955222\n",
      "Run 9 training metrics for A2C with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 73.98%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.2336\n",
      "  Mean improvement over greedy: -0.2177\n",
      "Run 9 test metrics for A2C with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 59.68%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4062\n",
      "  Mean improvement over greedy: -0.3953\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.8265754778902986\n",
      "Run 10 training metrics for A2C with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 76.53%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2043\n",
      "  Mean improvement over greedy: -0.1936\n",
      "Run 10 test metrics for A2C with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 66.03%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2720\n",
      "  Mean improvement over greedy: -0.2456\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for A2C with (+vr_i -_1):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 69.45% ± 5.60%\n",
      "  #opt: 4.80 ± 2.79\n",
      "  Mean percentage error: 0.2443 ± 0.0459\n",
      "  Mean improvement over greedy: -0.2269 ± 0.0476\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 58.69% ± 9.46%\n",
      "  #opt: 0.80 ± 0.60\n",
      "  Mean percentage error: 0.3559 ± 0.0772\n",
      "  Mean improvement over greedy: -0.3367 ± 0.0811\n",
      "\n",
      "Experiment 7/27: Testing A2C with (+_1 -w_i)\n",
      "Positive reward: _1, Negative reward: w_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -8.0\n",
      "Run 1 training metrics for A2C with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 67.91%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2482\n",
      "  Mean improvement over greedy: -0.2234\n",
      "Run 1 test metrics for A2C with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 52.65%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3927\n",
      "  Mean improvement over greedy: -0.3561\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -44.28947368421053\n",
      "Run 2 training metrics for A2C with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 70.51%\n",
      "  #opt: 8/25\n",
      "  Mean percentage error: 0.2175\n",
      "  Mean improvement over greedy: -0.1974\n",
      "Run 2 test metrics for A2C with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 68.05%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.1933\n",
      "  Mean improvement over greedy: -0.1933\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -41.75\n",
      "Run 3 training metrics for A2C with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 65.49%\n",
      "  #opt: 1/25\n",
      "  Mean percentage error: 0.2998\n",
      "  Mean improvement over greedy: -0.2864\n",
      "Run 3 test metrics for A2C with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 75.10%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2119\n",
      "  Mean improvement over greedy: -0.1921\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -53.34285714285714\n",
      "Run 4 training metrics for A2C with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 61.26%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.3112\n",
      "  Mean improvement over greedy: -0.2897\n",
      "Run 4 test metrics for A2C with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 59.61%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3649\n",
      "  Mean improvement over greedy: -0.3455\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -50.21951219512195\n",
      "Run 5 training metrics for A2C with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 68.14%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.2742\n",
      "  Mean improvement over greedy: -0.2523\n",
      "Run 5 test metrics for A2C with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 47.85%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3787\n",
      "  Mean improvement over greedy: -0.3410\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -44.75\n",
      "Run 6 training metrics for A2C with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 68.57%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2130\n",
      "  Mean improvement over greedy: -0.1978\n",
      "Run 6 test metrics for A2C with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 51.28%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4610\n",
      "  Mean improvement over greedy: -0.4518\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -26.25\n",
      "Run 7 training metrics for A2C with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 61.27%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.3212\n",
      "  Mean improvement over greedy: -0.3094\n",
      "Run 7 test metrics for A2C with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 63.22%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2348\n",
      "  Mean improvement over greedy: -0.2218\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -46.54545454545455\n",
      "Run 8 training metrics for A2C with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 63.63%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2777\n",
      "  Mean improvement over greedy: -0.2595\n",
      "Run 8 test metrics for A2C with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 71.52%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3015\n",
      "  Mean improvement over greedy: -0.2820\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -37.0\n",
      "Run 9 training metrics for A2C with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 72.93%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2339\n",
      "  Mean improvement over greedy: -0.2180\n",
      "Run 9 test metrics for A2C with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 45.09%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5144\n",
      "  Mean improvement over greedy: -0.5036\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -44.125\n",
      "Run 10 training metrics for A2C with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 79.02%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.1854\n",
      "  Mean improvement over greedy: -0.1748\n",
      "Run 10 test metrics for A2C with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 47.10%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4731\n",
      "  Mean improvement over greedy: -0.4467\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for A2C with (+_1 -w_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 67.87% ± 5.18%\n",
      "  #opt: 4.70 ± 1.73\n",
      "  Mean percentage error: 0.2582 ± 0.0434\n",
      "  Mean improvement over greedy: -0.2409 ± 0.0431\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 58.15% ± 10.34%\n",
      "  #opt: 0.70 ± 0.64\n",
      "  Mean percentage error: 0.3526 ± 0.1080\n",
      "  Mean improvement over greedy: -0.3334 ± 0.1055\n",
      "\n",
      "Experiment 8/27: Testing A2C with (+_1 -wr_i)\n",
      "Positive reward: _1, Negative reward: wr_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 0.7522184300341297\n",
      "Run 1 training metrics for A2C with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 68.35%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2421\n",
      "  Mean improvement over greedy: -0.2173\n",
      "Run 1 test metrics for A2C with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 53.04%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4147\n",
      "  Mean improvement over greedy: -0.3782\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.48377219840783825\n",
      "Run 2 training metrics for A2C with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 77.09%\n",
      "  #opt: 8/25\n",
      "  Mean percentage error: 0.1528\n",
      "  Mean improvement over greedy: -0.1328\n",
      "Run 2 test metrics for A2C with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 54.42%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2693\n",
      "  Mean improvement over greedy: -0.2693\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 0.0276515151515151\n",
      "Run 3 training metrics for A2C with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 63.28%\n",
      "  #opt: 0/25\n",
      "  Mean percentage error: 0.3344\n",
      "  Mean improvement over greedy: -0.3211\n",
      "Run 3 test metrics for A2C with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 73.62%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3196\n",
      "  Mean improvement over greedy: -0.2997\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -1.2920410783055198\n",
      "Run 4 training metrics for A2C with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 64.00%\n",
      "  #opt: 8/25\n",
      "  Mean percentage error: 0.2621\n",
      "  Mean improvement over greedy: -0.2406\n",
      "Run 4 test metrics for A2C with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 60.30%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3541\n",
      "  Mean improvement over greedy: -0.3347\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.6193548387096774\n",
      "Run 5 training metrics for A2C with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 66.49%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.2974\n",
      "  Mean improvement over greedy: -0.2756\n",
      "Run 5 test metrics for A2C with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 51.45%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4243\n",
      "  Mean improvement over greedy: -0.3866\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.35122282608695654\n",
      "Run 6 training metrics for A2C with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 61.48%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2993\n",
      "  Mean improvement over greedy: -0.2841\n",
      "Run 6 test metrics for A2C with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 41.29%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5668\n",
      "  Mean improvement over greedy: -0.5577\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 0.34158415841584155\n",
      "Run 7 training metrics for A2C with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 65.05%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2707\n",
      "  Mean improvement over greedy: -0.2590\n",
      "Run 7 test metrics for A2C with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 45.85%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4169\n",
      "  Mean improvement over greedy: -0.4039\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.16544117647058823\n",
      "Run 8 training metrics for A2C with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 65.44%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2711\n",
      "  Mean improvement over greedy: -0.2529\n",
      "Run 8 test metrics for A2C with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 60.78%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3515\n",
      "  Mean improvement over greedy: -0.3320\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 0.10641711229946525\n",
      "Run 9 training metrics for A2C with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 73.82%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.2457\n",
      "  Mean improvement over greedy: -0.2299\n",
      "Run 9 test metrics for A2C with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 53.96%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4617\n",
      "  Mean improvement over greedy: -0.4509\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.3037878787878788\n",
      "Run 10 training metrics for A2C with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 77.34%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2132\n",
      "  Mean improvement over greedy: -0.2025\n",
      "Run 10 test metrics for A2C with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 51.81%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4314\n",
      "  Mean improvement over greedy: -0.4050\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for A2C with (+_1 -wr_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 68.24% ± 5.49%\n",
      "  #opt: 4.70 ± 2.33\n",
      "  Mean percentage error: 0.2589 ± 0.0479\n",
      "  Mean improvement over greedy: -0.2416 ± 0.0488\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 54.65% ± 8.41%\n",
      "  #opt: 0.50 ± 0.67\n",
      "  Mean percentage error: 0.4010 ± 0.0786\n",
      "  Mean improvement over greedy: -0.3818 ± 0.0780\n",
      "\n",
      "Experiment 9/27: Testing A2C with (+_1 -_1)\n",
      "Positive reward: _1, Negative reward: _1\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 0.6\n",
      "Run 1 training metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 67.24%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2424\n",
      "  Mean improvement over greedy: -0.2176\n",
      "Run 1 test metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 59.89%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2518\n",
      "  Mean improvement over greedy: -0.2153\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.7894736842105263\n",
      "Run 2 training metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 69.94%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2201\n",
      "  Mean improvement over greedy: -0.2001\n",
      "Run 2 test metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 56.44%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2654\n",
      "  Mean improvement over greedy: -0.2654\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.7222222222222222\n",
      "Run 3 training metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 67.80%\n",
      "  #opt: 0/25\n",
      "  Mean percentage error: 0.2840\n",
      "  Mean improvement over greedy: -0.2706\n",
      "Run 3 test metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 74.81%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3144\n",
      "  Mean improvement over greedy: -0.2945\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.8536585365853658\n",
      "Run 4 training metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 62.58%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2748\n",
      "  Mean improvement over greedy: -0.2533\n",
      "Run 4 test metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 51.96%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3322\n",
      "  Mean improvement over greedy: -0.3128\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.8048780487804879\n",
      "Run 5 training metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 67.35%\n",
      "  #opt: 2/25\n",
      "  Mean percentage error: 0.2996\n",
      "  Mean improvement over greedy: -0.2777\n",
      "Run 5 test metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 44.57%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5270\n",
      "  Mean improvement over greedy: -0.4893\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.625\n",
      "Run 6 training metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 66.05%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2633\n",
      "  Mean improvement over greedy: -0.2481\n",
      "Run 6 test metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 41.89%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5657\n",
      "  Mean improvement over greedy: -0.5565\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 0.0\n",
      "Run 7 training metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 66.90%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2673\n",
      "  Mean improvement over greedy: -0.2555\n",
      "Run 7 test metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 45.33%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4105\n",
      "  Mean improvement over greedy: -0.3975\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.5454545454545454\n",
      "Run 8 training metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 62.80%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2943\n",
      "  Mean improvement over greedy: -0.2761\n",
      "Run 8 test metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 67.03%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.2945\n",
      "  Mean improvement over greedy: -0.2749\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.45454545454545453\n",
      "Run 9 training metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 69.90%\n",
      "  #opt: 2/25\n",
      "  Mean percentage error: 0.2828\n",
      "  Mean improvement over greedy: -0.2669\n",
      "Run 9 test metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 48.85%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5249\n",
      "  Mean improvement over greedy: -0.5140\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackA2C.KnapsackA2C'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.2\n",
      "Run 10 training metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 77.60%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2104\n",
      "  Mean improvement over greedy: -0.1998\n",
      "Run 10 test metrics for A2C with (+_1 -_1):\n",
      "  Val/Opt Ratio: 63.86%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2298\n",
      "  Mean improvement over greedy: -0.2034\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for A2C with (+_1 -_1):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 67.82% ± 4.02%\n",
      "  #opt: 4.20 ± 2.04\n",
      "  Mean percentage error: 0.2639 ± 0.0289\n",
      "  Mean improvement over greedy: -0.2466 ± 0.0286\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 55.46% ± 10.30%\n",
      "  #opt: 0.80 ± 0.87\n",
      "  Mean percentage error: 0.3716 ± 0.1197\n",
      "  Mean improvement over greedy: -0.3524 ± 0.1217\n",
      "\n",
      "Experiment 10/27: Testing DQN with (+v_i -w_i)\n",
      "Positive reward: v_i, Negative reward: w_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 19.6\n",
      "Run 1 training metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 69.57%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2270\n",
      "  Mean improvement over greedy: -0.2022\n",
      "Run 1 test metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 70.11%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2298\n",
      "  Mean improvement over greedy: -0.1933\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -39.689655172413794\n",
      "Run 2 training metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 78.15%\n",
      "  #opt: 8/25\n",
      "  Mean percentage error: 0.1634\n",
      "  Mean improvement over greedy: -0.1434\n",
      "Run 2 test metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 61.34%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2318\n",
      "  Mean improvement over greedy: -0.2318\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -31.416666666666668\n",
      "Run 3 training metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 66.34%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.2859\n",
      "  Mean improvement over greedy: -0.2725\n",
      "Run 3 test metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 70.89%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2612\n",
      "  Mean improvement over greedy: -0.2413\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -47.31707317073171\n",
      "Run 4 training metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 64.41%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2648\n",
      "  Mean improvement over greedy: -0.2433\n",
      "Run 4 test metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 56.26%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3111\n",
      "  Mean improvement over greedy: -0.2917\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -1.6666666666666667\n",
      "Run 5 training metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 68.45%\n",
      "  #opt: 2/25\n",
      "  Mean percentage error: 0.2746\n",
      "  Mean improvement over greedy: -0.2528\n",
      "Run 5 test metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 57.29%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3478\n",
      "  Mean improvement over greedy: -0.3101\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -37.25\n",
      "Run 6 training metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 63.64%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2575\n",
      "  Mean improvement over greedy: -0.2423\n",
      "Run 6 test metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 44.72%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5111\n",
      "  Mean improvement over greedy: -0.5019\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -13.0\n",
      "Run 7 training metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 66.31%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2691\n",
      "  Mean improvement over greedy: -0.2574\n",
      "Run 7 test metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 49.82%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4131\n",
      "  Mean improvement over greedy: -0.4001\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -28.818181818181817\n",
      "Run 8 training metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 68.32%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2613\n",
      "  Mean improvement over greedy: -0.2431\n",
      "Run 8 test metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 68.37%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2841\n",
      "  Mean improvement over greedy: -0.2645\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -20.90909090909091\n",
      "Run 9 training metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 73.08%\n",
      "  #opt: 2/25\n",
      "  Mean percentage error: 0.2515\n",
      "  Mean improvement over greedy: -0.2357\n",
      "Run 9 test metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 44.48%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4994\n",
      "  Mean improvement over greedy: -0.4886\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 50.666666666666664\n",
      "Run 10 training metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 74.83%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2070\n",
      "  Mean improvement over greedy: -0.1964\n",
      "Run 10 test metrics for DQN with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 58.38%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3577\n",
      "  Mean improvement over greedy: -0.3313\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for DQN with (+v_i -w_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 69.31% ± 4.46%\n",
      "  #opt: 4.20 ± 1.66\n",
      "  Mean percentage error: 0.2462 ± 0.0352\n",
      "  Mean improvement over greedy: -0.2289 ± 0.0361\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 58.16% ± 9.28%\n",
      "  #opt: 0.90 ± 0.54\n",
      "  Mean percentage error: 0.3447 ± 0.0971\n",
      "  Mean improvement over greedy: -0.3255 ± 0.1009\n",
      "\n",
      "Experiment 11/27: Testing DQN with (+v_i -wr_i)\n",
      "Positive reward: v_i, Negative reward: wr_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 28.385665529010236\n",
      "Run 1 training metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 67.46%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2763\n",
      "  Mean improvement over greedy: -0.2515\n",
      "Run 1 test metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 64.20%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2507\n",
      "  Mean improvement over greedy: -0.2141\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 2.6584507042253516\n",
      "Run 2 training metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 77.49%\n",
      "  #opt: 8/25\n",
      "  Mean percentage error: 0.1653\n",
      "  Mean improvement over greedy: -0.1452\n",
      "Run 2 test metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 63.15%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2195\n",
      "  Mean improvement over greedy: -0.2195\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 12.899368686868687\n",
      "Run 3 training metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 69.47%\n",
      "  #opt: 1/25\n",
      "  Mean percentage error: 0.2851\n",
      "  Mean improvement over greedy: -0.2717\n",
      "Run 3 test metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 68.81%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3964\n",
      "  Mean improvement over greedy: -0.3766\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 6.653508771929825\n",
      "Run 4 training metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 63.35%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2669\n",
      "  Mean improvement over greedy: -0.2454\n",
      "Run 4 test metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 61.42%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3182\n",
      "  Mean improvement over greedy: -0.2988\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 2.7757671125098367\n",
      "Run 5 training metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 66.82%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.2911\n",
      "  Mean improvement over greedy: -0.2692\n",
      "Run 5 test metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 50.29%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4530\n",
      "  Mean improvement over greedy: -0.4153\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 7.65625\n",
      "Run 6 training metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 65.42%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2520\n",
      "  Mean improvement over greedy: -0.2368\n",
      "Run 6 test metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 44.33%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4770\n",
      "  Mean improvement over greedy: -0.4679\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 5.71039603960396\n",
      "Run 7 training metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 70.38%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2347\n",
      "  Mean improvement over greedy: -0.2230\n",
      "Run 7 test metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 48.30%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4056\n",
      "  Mean improvement over greedy: -0.3926\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 6.839691558441557\n",
      "Run 8 training metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 69.39%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2415\n",
      "  Mean improvement over greedy: -0.2233\n",
      "Run 8 test metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 67.27%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3151\n",
      "  Mean improvement over greedy: -0.2955\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 17.485026737967914\n",
      "Run 9 training metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 76.65%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2071\n",
      "  Mean improvement over greedy: -0.1912\n",
      "Run 9 test metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 47.97%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4736\n",
      "  Mean improvement over greedy: -0.4628\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 7.514015151515152\n",
      "Run 10 training metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 80.07%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.1750\n",
      "  Mean improvement over greedy: -0.1643\n",
      "Run 10 test metrics for DQN with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 35.28%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.5212\n",
      "  Mean improvement over greedy: -0.4949\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for DQN with (+v_i -wr_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 70.65% ± 5.29%\n",
      "  #opt: 4.40 ± 1.69\n",
      "  Mean percentage error: 0.2395 ± 0.0421\n",
      "  Mean improvement over greedy: -0.2222 ± 0.0406\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 55.10% ± 10.74%\n",
      "  #opt: 0.60 ± 0.66\n",
      "  Mean percentage error: 0.3830 ± 0.0974\n",
      "  Mean improvement over greedy: -0.3638 ± 0.0967\n",
      "\n",
      "Experiment 12/27: Testing DQN with (+v_i -_1)\n",
      "Positive reward: v_i, Negative reward: _1\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 18.4\n",
      "Run 1 training metrics for DQN with (+v_i -_1):\n",
      "  Val/Opt Ratio: 65.53%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2649\n",
      "  Mean improvement over greedy: -0.2401\n",
      "Run 1 test metrics for DQN with (+v_i -_1):\n",
      "  Val/Opt Ratio: 44.31%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3701\n",
      "  Mean improvement over greedy: -0.3336\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 10.461538461538462\n",
      "Run 2 training metrics for DQN with (+v_i -_1):\n",
      "  Val/Opt Ratio: 73.21%\n",
      "  #opt: 11/25\n",
      "  Mean percentage error: 0.1816\n",
      "  Mean improvement over greedy: -0.1616\n",
      "Run 2 test metrics for DQN with (+v_i -_1):\n",
      "  Val/Opt Ratio: 44.78%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.3504\n",
      "  Mean improvement over greedy: -0.3504\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 14.428571428571429\n",
      "Run 3 training metrics for DQN with (+v_i -_1):\n",
      "  Val/Opt Ratio: 61.00%\n",
      "  #opt: 0/25\n",
      "  Mean percentage error: 0.3494\n",
      "  Mean improvement over greedy: -0.3360\n",
      "Run 3 test metrics for DQN with (+v_i -_1):\n",
      "  Val/Opt Ratio: 59.95%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3792\n",
      "  Mean improvement over greedy: -0.3593\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 1.7560975609756098\n",
      "Run 4 training metrics for DQN with (+v_i -_1):\n",
      "  Val/Opt Ratio: 66.04%\n",
      "  #opt: 7/25\n",
      "  Mean percentage error: 0.2445\n",
      "  Mean improvement over greedy: -0.2230\n",
      "Run 4 test metrics for DQN with (+v_i -_1):\n",
      "  Val/Opt Ratio: 76.60%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.1816\n",
      "  Mean improvement over greedy: -0.1622\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 0.1951219512195122\n",
      "Run 5 training metrics for DQN with (+v_i -_1):\n",
      "  Val/Opt Ratio: 66.42%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2943\n",
      "  Mean improvement over greedy: -0.2724\n",
      "Run 5 test metrics for DQN with (+v_i -_1):\n",
      "  Val/Opt Ratio: 53.19%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4222\n",
      "  Mean improvement over greedy: -0.3845\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 40.4\n",
      "Run 6 training metrics for DQN with (+v_i -_1):\n",
      "  Val/Opt Ratio: 67.07%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2442\n",
      "  Mean improvement over greedy: -0.2290\n",
      "Run 6 test metrics for DQN with (+v_i -_1):\n",
      "  Val/Opt Ratio: 51.63%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5058\n",
      "  Mean improvement over greedy: -0.4966\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 5.5\n",
      "Run 7 training metrics for DQN with (+v_i -_1):\n",
      "  Val/Opt Ratio: 64.19%\n",
      "  #opt: 7/25\n",
      "  Mean percentage error: 0.2775\n",
      "  Mean improvement over greedy: -0.2657\n",
      "Run 7 test metrics for DQN with (+v_i -_1):\n",
      "  Val/Opt Ratio: 36.20%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.5082\n",
      "  Mean improvement over greedy: -0.4952\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 9.318181818181818\n",
      "Run 8 training metrics for DQN with (+v_i -_1):\n",
      "  Val/Opt Ratio: 69.53%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2615\n",
      "  Mean improvement over greedy: -0.2433\n",
      "Run 8 test metrics for DQN with (+v_i -_1):\n",
      "  Val/Opt Ratio: 61.02%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3998\n",
      "  Mean improvement over greedy: -0.3802\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 16.454545454545453\n",
      "Run 9 training metrics for DQN with (+v_i -_1):\n",
      "  Val/Opt Ratio: 71.59%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2363\n",
      "  Mean improvement over greedy: -0.2205\n",
      "Run 9 test metrics for DQN with (+v_i -_1):\n",
      "  Val/Opt Ratio: 54.13%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4200\n",
      "  Mean improvement over greedy: -0.4092\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 12.208333333333334\n",
      "Run 10 training metrics for DQN with (+v_i -_1):\n",
      "  Val/Opt Ratio: 74.89%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2147\n",
      "  Mean improvement over greedy: -0.2041\n",
      "Run 10 test metrics for DQN with (+v_i -_1):\n",
      "  Val/Opt Ratio: 61.10%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3255\n",
      "  Mean improvement over greedy: -0.2991\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for DQN with (+v_i -_1):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 67.95% ± 4.08%\n",
      "  #opt: 5.20 ± 2.71\n",
      "  Mean percentage error: 0.2569 ± 0.0432\n",
      "  Mean improvement over greedy: -0.2396 ± 0.0438\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 54.29% ± 10.71%\n",
      "  #opt: 0.80 ± 0.60\n",
      "  Mean percentage error: 0.3863 ± 0.0889\n",
      "  Mean improvement over greedy: -0.3670 ± 0.0914\n",
      "\n",
      "Experiment 13/27: Testing DQN with (+vr_i -w_i)\n",
      "Positive reward: vr_i, Negative reward: w_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -17.19871635759008\n",
      "Run 1 training metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 68.78%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2645\n",
      "  Mean improvement over greedy: -0.2396\n",
      "Run 1 test metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 56.80%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3289\n",
      "  Mean improvement over greedy: -0.2923\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -44.12635069352471\n",
      "Run 2 training metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 77.27%\n",
      "  #opt: 8/25\n",
      "  Mean percentage error: 0.1674\n",
      "  Mean improvement over greedy: -0.1474\n",
      "Run 2 test metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 58.68%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2649\n",
      "  Mean improvement over greedy: -0.2649\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -41.82800947387339\n",
      "Run 3 training metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 68.29%\n",
      "  #opt: 0/25\n",
      "  Mean percentage error: 0.2800\n",
      "  Mean improvement over greedy: -0.2667\n",
      "Run 3 test metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 62.15%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3237\n",
      "  Mean improvement over greedy: -0.3039\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -51.55933400505769\n",
      "Run 4 training metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 65.71%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2540\n",
      "  Mean improvement over greedy: -0.2325\n",
      "Run 4 test metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 64.69%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2679\n",
      "  Mean improvement over greedy: -0.2485\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -50.215871142582394\n",
      "Run 5 training metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 63.75%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.3157\n",
      "  Mean improvement over greedy: -0.2938\n",
      "Run 5 test metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 51.06%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4685\n",
      "  Mean improvement over greedy: -0.4308\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -45.06018607113697\n",
      "Run 6 training metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 64.37%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2544\n",
      "  Mean improvement over greedy: -0.2392\n",
      "Run 6 test metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 50.11%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4916\n",
      "  Mean improvement over greedy: -0.4824\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -27.748359105573478\n",
      "Run 7 training metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 61.47%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.3215\n",
      "  Mean improvement over greedy: -0.3097\n",
      "Run 7 test metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 53.36%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3942\n",
      "  Mean improvement over greedy: -0.3812\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -49.394258564711144\n",
      "Run 8 training metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 64.53%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2664\n",
      "  Mean improvement over greedy: -0.2483\n",
      "Run 8 test metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 71.10%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.2847\n",
      "  Mean improvement over greedy: -0.2652\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -38.3586066132541\n",
      "Run 9 training metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 72.01%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2285\n",
      "  Mean improvement over greedy: -0.2126\n",
      "Run 9 test metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 51.86%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4606\n",
      "  Mean improvement over greedy: -0.4497\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -44.53312603818469\n",
      "Run 10 training metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 74.69%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2157\n",
      "  Mean improvement over greedy: -0.2050\n",
      "Run 10 test metrics for DQN with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 34.65%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.5142\n",
      "  Mean improvement over greedy: -0.4879\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for DQN with (+vr_i -w_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 68.09% ± 4.88%\n",
      "  #opt: 4.60 ± 2.01\n",
      "  Mean percentage error: 0.2568 ± 0.0434\n",
      "  Mean improvement over greedy: -0.2395 ± 0.0438\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 55.45% ± 9.41%\n",
      "  #opt: 0.70 ± 0.64\n",
      "  Mean percentage error: 0.3799 ± 0.0926\n",
      "  Mean improvement over greedy: -0.3607 ± 0.0911\n",
      "\n",
      "Experiment 14/27: Testing DQN with (+vr_i -wr_i)\n",
      "Positive reward: vr_i, Negative reward: wr_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.04680122243024061\n",
      "Run 1 training metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 67.68%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2801\n",
      "  Mean improvement over greedy: -0.2553\n",
      "Run 1 test metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 64.64%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2658\n",
      "  Mean improvement over greedy: -0.2292\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.6383910660363984\n",
      "Run 2 training metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 74.94%\n",
      "  #opt: 9/25\n",
      "  Mean percentage error: 0.1808\n",
      "  Mean improvement over greedy: -0.1607\n",
      "Run 2 test metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 62.67%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2309\n",
      "  Mean improvement over greedy: -0.2309\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.09358830555043504\n",
      "Run 3 training metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 68.79%\n",
      "  #opt: 0/25\n",
      "  Mean percentage error: 0.2928\n",
      "  Mean improvement over greedy: -0.2795\n",
      "Run 3 test metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 83.24%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.1262\n",
      "  Mean improvement over greedy: -0.1064\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -1.354203598426962\n",
      "Run 4 training metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 65.37%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2636\n",
      "  Mean improvement over greedy: -0.2421\n",
      "Run 4 test metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 60.73%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.2897\n",
      "  Mean improvement over greedy: -0.2703\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -1.7207172139633105\n",
      "Run 5 training metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 66.35%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2911\n",
      "  Mean improvement over greedy: -0.2693\n",
      "Run 5 test metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 48.71%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5390\n",
      "  Mean improvement over greedy: -0.5013\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.5125069058998868\n",
      "Run 6 training metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 69.28%\n",
      "  #opt: 7/25\n",
      "  Mean percentage error: 0.2442\n",
      "  Mean improvement over greedy: -0.2289\n",
      "Run 6 test metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 55.32%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4157\n",
      "  Mean improvement over greedy: -0.4065\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.18484598459845986\n",
      "Run 7 training metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 65.96%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2662\n",
      "  Mean improvement over greedy: -0.2544\n",
      "Run 7 test metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 45.80%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3852\n",
      "  Mean improvement over greedy: -0.3722\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.32266825269433613\n",
      "Run 8 training metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 72.86%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2199\n",
      "  Mean improvement over greedy: -0.2017\n",
      "Run 8 test metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 68.06%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3433\n",
      "  Mean improvement over greedy: -0.3237\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.1500504635214843\n",
      "Run 9 training metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 71.15%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2369\n",
      "  Mean improvement over greedy: -0.2211\n",
      "Run 9 test metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 51.29%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4676\n",
      "  Mean improvement over greedy: -0.4568\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.36140477354187034\n",
      "Run 10 training metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 76.40%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2169\n",
      "  Mean improvement over greedy: -0.2063\n",
      "Run 10 test metrics for DQN with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 48.73%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4283\n",
      "  Mean improvement over greedy: -0.4019\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for DQN with (+vr_i -wr_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 69.88% ± 3.65%\n",
      "  #opt: 4.80 ± 2.18\n",
      "  Mean percentage error: 0.2493 ± 0.0345\n",
      "  Mean improvement over greedy: -0.2319 ± 0.0340\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 58.92% ± 10.85%\n",
      "  #opt: 0.70 ± 0.64\n",
      "  Mean percentage error: 0.3492 ± 0.1167\n",
      "  Mean improvement over greedy: -0.3299 ± 0.1148\n",
      "\n",
      "Experiment 15/27: Testing DQN with (+vr_i -_1)\n",
      "Positive reward: vr_i, Negative reward: _1\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.1984508242504909\n",
      "Run 1 training metrics for DQN with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 70.85%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2236\n",
      "  Mean improvement over greedy: -0.1988\n",
      "Run 1 test metrics for DQN with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 54.59%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3327\n",
      "  Mean improvement over greedy: -0.2962\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.8932895490734327\n",
      "Run 2 training metrics for DQN with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 74.42%\n",
      "  #opt: 7/25\n",
      "  Mean percentage error: 0.1949\n",
      "  Mean improvement over greedy: -0.1748\n",
      "Run 2 test metrics for DQN with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 52.40%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2938\n",
      "  Mean improvement over greedy: -0.2938\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.7615396149346373\n",
      "Run 3 training metrics for DQN with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 61.82%\n",
      "  #opt: 0/25\n",
      "  Mean percentage error: 0.3530\n",
      "  Mean improvement over greedy: -0.3397\n",
      "Run 3 test metrics for DQN with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 75.70%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.2935\n",
      "  Mean improvement over greedy: -0.2737\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.762137630171686\n",
      "Run 4 training metrics for DQN with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 64.24%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2850\n",
      "  Mean improvement over greedy: -0.2635\n",
      "Run 4 test metrics for DQN with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 72.60%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2343\n",
      "  Mean improvement over greedy: -0.2149\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.9121044234635896\n",
      "Run 5 training metrics for DQN with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 66.41%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2834\n",
      "  Mean improvement over greedy: -0.2615\n",
      "Run 5 test metrics for DQN with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 52.61%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5049\n",
      "  Mean improvement over greedy: -0.4671\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.8086609299516908\n",
      "Run 6 training metrics for DQN with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 68.54%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2435\n",
      "  Mean improvement over greedy: -0.2283\n",
      "Run 6 test metrics for DQN with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 64.45%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2923\n",
      "  Mean improvement over greedy: -0.2832\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.49865876122495967\n",
      "Run 7 training metrics for DQN with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 61.83%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.3140\n",
      "  Mean improvement over greedy: -0.3023\n",
      "Run 7 test metrics for DQN with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 61.14%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2747\n",
      "  Mean improvement over greedy: -0.2617\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.8004019134618408\n",
      "Run 8 training metrics for DQN with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 67.64%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2757\n",
      "  Mean improvement over greedy: -0.2575\n",
      "Run 8 test metrics for DQN with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 84.52%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.1598\n",
      "  Mean improvement over greedy: -0.1402\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.5408340091334612\n",
      "Run 9 training metrics for DQN with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 71.97%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2220\n",
      "  Mean improvement over greedy: -0.2061\n",
      "Run 9 test metrics for DQN with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 62.09%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3980\n",
      "  Mean improvement over greedy: -0.3871\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.774643085787452\n",
      "Run 10 training metrics for DQN with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 68.96%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.2909\n",
      "  Mean improvement over greedy: -0.2802\n",
      "Run 10 test metrics for DQN with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 60.73%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3510\n",
      "  Mean improvement over greedy: -0.3246\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for DQN with (+vr_i -_1):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 67.67% ± 3.98%\n",
      "  #opt: 4.20 ± 1.78\n",
      "  Mean percentage error: 0.2686 ± 0.0453\n",
      "  Mean improvement over greedy: -0.2513 ± 0.0477\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 64.08% ± 10.04%\n",
      "  #opt: 0.80 ± 0.60\n",
      "  Mean percentage error: 0.3135 ± 0.0884\n",
      "  Mean improvement over greedy: -0.2943 ± 0.0843\n",
      "\n",
      "Experiment 16/27: Testing DQN with (+_1 -w_i)\n",
      "Positive reward: _1, Negative reward: w_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -14.8\n",
      "Run 1 training metrics for DQN with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 65.62%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2672\n",
      "  Mean improvement over greedy: -0.2424\n",
      "Run 1 test metrics for DQN with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 61.38%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2835\n",
      "  Mean improvement over greedy: -0.2470\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -44.3421052631579\n",
      "Run 2 training metrics for DQN with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 75.24%\n",
      "  #opt: 10/25\n",
      "  Mean percentage error: 0.1947\n",
      "  Mean improvement over greedy: -0.1747\n",
      "Run 2 test metrics for DQN with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 52.72%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.3010\n",
      "  Mean improvement over greedy: -0.3010\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -38.625\n",
      "Run 3 training metrics for DQN with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 62.15%\n",
      "  #opt: 0/25\n",
      "  Mean percentage error: 0.3406\n",
      "  Mean improvement over greedy: -0.3272\n",
      "Run 3 test metrics for DQN with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 69.70%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3591\n",
      "  Mean improvement over greedy: -0.3393\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -48.31578947368421\n",
      "Run 4 training metrics for DQN with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 60.96%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.3080\n",
      "  Mean improvement over greedy: -0.2865\n",
      "Run 4 test metrics for DQN with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 59.78%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2839\n",
      "  Mean improvement over greedy: -0.2645\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -36.75\n",
      "Run 5 training metrics for DQN with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 65.46%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.2994\n",
      "  Mean improvement over greedy: -0.2775\n",
      "Run 5 test metrics for DQN with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 54.35%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4711\n",
      "  Mean improvement over greedy: -0.4334\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -44.875\n",
      "Run 6 training metrics for DQN with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 59.40%\n",
      "  #opt: 7/25\n",
      "  Mean percentage error: 0.2826\n",
      "  Mean improvement over greedy: -0.2673\n",
      "Run 6 test metrics for DQN with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 42.55%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5761\n",
      "  Mean improvement over greedy: -0.5669\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -34.25\n",
      "Run 7 training metrics for DQN with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 60.30%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.3135\n",
      "  Mean improvement over greedy: -0.3018\n",
      "Run 7 test metrics for DQN with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 39.91%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4437\n",
      "  Mean improvement over greedy: -0.4307\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -49.45454545454545\n",
      "Run 8 training metrics for DQN with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 62.65%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.3017\n",
      "  Mean improvement over greedy: -0.2836\n",
      "Run 8 test metrics for DQN with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 61.57%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3639\n",
      "  Mean improvement over greedy: -0.3443\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -36.18181818181818\n",
      "Run 9 training metrics for DQN with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 73.55%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.2350\n",
      "  Mean improvement over greedy: -0.2192\n",
      "Run 9 test metrics for DQN with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 42.21%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.5424\n",
      "  Mean improvement over greedy: -0.5316\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -44.125\n",
      "Run 10 training metrics for DQN with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 75.61%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.1971\n",
      "  Mean improvement over greedy: -0.1865\n",
      "Run 10 test metrics for DQN with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 37.77%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.5032\n",
      "  Mean improvement over greedy: -0.4768\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for DQN with (+_1 -w_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 66.09% ± 6.02%\n",
      "  #opt: 4.70 ± 2.61\n",
      "  Mean percentage error: 0.2740 ± 0.0473\n",
      "  Mean improvement over greedy: -0.2567 ± 0.0474\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 52.19% ± 10.45%\n",
      "  #opt: 0.80 ± 0.60\n",
      "  Mean percentage error: 0.4128 ± 0.1035\n",
      "  Mean improvement over greedy: -0.3935 ± 0.1054\n",
      "\n",
      "Experiment 17/27: Testing DQN with (+_1 -wr_i)\n",
      "Positive reward: _1, Negative reward: wr_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 0.7638225255972697\n",
      "Run 1 training metrics for DQN with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 59.85%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.3402\n",
      "  Mean improvement over greedy: -0.3154\n",
      "Run 1 test metrics for DQN with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 64.70%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2682\n",
      "  Mean improvement over greedy: -0.2316\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.5441741357234317\n",
      "Run 2 training metrics for DQN with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 74.17%\n",
      "  #opt: 8/25\n",
      "  Mean percentage error: 0.1837\n",
      "  Mean improvement over greedy: -0.1636\n",
      "Run 2 test metrics for DQN with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 49.15%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.3199\n",
      "  Mean improvement over greedy: -0.3199\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 0.011489898989898998\n",
      "Run 3 training metrics for DQN with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 64.37%\n",
      "  #opt: 0/25\n",
      "  Mean percentage error: 0.3471\n",
      "  Mean improvement over greedy: -0.3337\n",
      "Run 3 test metrics for DQN with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 60.84%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3680\n",
      "  Mean improvement over greedy: -0.3481\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -1.3080872913992299\n",
      "Run 4 training metrics for DQN with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 58.38%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.3273\n",
      "  Mean improvement over greedy: -0.3058\n",
      "Run 4 test metrics for DQN with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 57.20%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3809\n",
      "  Mean improvement over greedy: -0.3615\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -1.0483870967741935\n",
      "Run 5 training metrics for DQN with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 62.62%\n",
      "  #opt: 2/25\n",
      "  Mean percentage error: 0.3341\n",
      "  Mean improvement over greedy: -0.3122\n",
      "Run 5 test metrics for DQN with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 57.67%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4433\n",
      "  Mean improvement over greedy: -0.4056\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.43274456521739135\n",
      "Run 6 training metrics for DQN with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 67.38%\n",
      "  #opt: 2/25\n",
      "  Mean percentage error: 0.3017\n",
      "  Mean improvement over greedy: -0.2865\n",
      "Run 6 test metrics for DQN with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 52.89%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4635\n",
      "  Mean improvement over greedy: -0.4543\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 0.2103960396039604\n",
      "Run 7 training metrics for DQN with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 64.95%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2938\n",
      "  Mean improvement over greedy: -0.2821\n",
      "Run 7 test metrics for DQN with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 51.64%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3803\n",
      "  Mean improvement over greedy: -0.3673\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.14732142857142855\n",
      "Run 8 training metrics for DQN with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 61.79%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.3242\n",
      "  Mean improvement over greedy: -0.3060\n",
      "Run 8 test metrics for DQN with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 73.65%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.2619\n",
      "  Mean improvement over greedy: -0.2423\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 0.2994652406417112\n",
      "Run 9 training metrics for DQN with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 70.84%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2533\n",
      "  Mean improvement over greedy: -0.2374\n",
      "Run 9 test metrics for DQN with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 49.80%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4629\n",
      "  Mean improvement over greedy: -0.4521\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.24999999999999997\n",
      "Run 10 training metrics for DQN with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 62.45%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.3214\n",
      "  Mean improvement over greedy: -0.3108\n",
      "Run 10 test metrics for DQN with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 54.21%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3758\n",
      "  Mean improvement over greedy: -0.3494\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for DQN with (+_1 -wr_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 64.68% ± 4.65%\n",
      "  #opt: 3.80 ± 2.09\n",
      "  Mean percentage error: 0.3027 ± 0.0474\n",
      "  Mean improvement over greedy: -0.2854 ± 0.0475\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 57.18% ± 7.20%\n",
      "  #opt: 0.70 ± 0.64\n",
      "  Mean percentage error: 0.3725 ± 0.0689\n",
      "  Mean improvement over greedy: -0.3532 ± 0.0716\n",
      "\n",
      "Experiment 18/27: Testing DQN with (+_1 -_1)\n",
      "Positive reward: _1, Negative reward: _1\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 0.6\n",
      "Run 1 training metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 58.22%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.3471\n",
      "  Mean improvement over greedy: -0.3223\n",
      "Run 1 test metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 67.24%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2334\n",
      "  Mean improvement over greedy: -0.1969\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.7714285714285715\n",
      "Run 2 training metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 68.26%\n",
      "  #opt: 8/25\n",
      "  Mean percentage error: 0.2356\n",
      "  Mean improvement over greedy: -0.2156\n",
      "Run 2 test metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 58.95%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2637\n",
      "  Mean improvement over greedy: -0.2637\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.1111111111111111\n",
      "Run 3 training metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 62.55%\n",
      "  #opt: 1/25\n",
      "  Mean percentage error: 0.3528\n",
      "  Mean improvement over greedy: -0.3394\n",
      "Run 3 test metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 79.26%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.1800\n",
      "  Mean improvement over greedy: -0.1601\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.25\n",
      "Run 4 training metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 55.54%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.3684\n",
      "  Mean improvement over greedy: -0.3469\n",
      "Run 4 test metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 52.17%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3385\n",
      "  Mean improvement over greedy: -0.3191\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 1.0\n",
      "Run 5 training metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 60.50%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.3517\n",
      "  Mean improvement over greedy: -0.3298\n",
      "Run 5 test metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 59.34%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3797\n",
      "  Mean improvement over greedy: -0.3420\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.75\n",
      "Run 6 training metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 65.92%\n",
      "  #opt: 2/25\n",
      "  Mean percentage error: 0.3190\n",
      "  Mean improvement over greedy: -0.3037\n",
      "Run 6 test metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 48.37%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4987\n",
      "  Mean improvement over greedy: -0.4895\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 0.0\n",
      "Run 7 training metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 62.34%\n",
      "  #opt: 2/25\n",
      "  Mean percentage error: 0.3450\n",
      "  Mean improvement over greedy: -0.3332\n",
      "Run 7 test metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 55.29%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3746\n",
      "  Mean improvement over greedy: -0.3616\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.6363636363636364\n",
      "Run 8 training metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 60.28%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.3391\n",
      "  Mean improvement over greedy: -0.3210\n",
      "Run 8 test metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 73.53%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.2719\n",
      "  Mean improvement over greedy: -0.2524\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.09090909090909091\n",
      "Run 9 training metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 65.18%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.3123\n",
      "  Mean improvement over greedy: -0.2965\n",
      "Run 9 test metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 49.70%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4597\n",
      "  Mean improvement over greedy: -0.4489\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackQLearning.KnapsackDQN'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.4166666666666667\n",
      "Run 10 training metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 62.47%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.3472\n",
      "  Mean improvement over greedy: -0.3366\n",
      "Run 10 test metrics for DQN with (+_1 -_1):\n",
      "  Val/Opt Ratio: 57.02%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3530\n",
      "  Mean improvement over greedy: -0.3267\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for DQN with (+_1 -_1):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 62.13% ± 3.55%\n",
      "  #opt: 3.80 ± 1.94\n",
      "  Mean percentage error: 0.3318 ± 0.0356\n",
      "  Mean improvement over greedy: -0.3145 ± 0.0362\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 60.09% ± 9.70%\n",
      "  #opt: 0.70 ± 0.64\n",
      "  Mean percentage error: 0.3353 ± 0.0947\n",
      "  Mean improvement over greedy: -0.3161 ± 0.0979\n",
      "\n",
      "Experiment 19/27: Testing PPO with (+v_i -w_i)\n",
      "Positive reward: v_i, Negative reward: w_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 19.6\n",
      "Run 1 training metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 66.22%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2566\n",
      "  Mean improvement over greedy: -0.2318\n",
      "Run 1 test metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 63.76%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2908\n",
      "  Mean improvement over greedy: -0.2542\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -13.257425742574258\n",
      "Run 2 training metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 79.83%\n",
      "  #opt: 7/25\n",
      "  Mean percentage error: 0.1507\n",
      "  Mean improvement over greedy: -0.1306\n",
      "Run 2 test metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 56.44%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2747\n",
      "  Mean improvement over greedy: -0.2747\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -32.85\n",
      "Run 3 training metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 66.90%\n",
      "  #opt: 2/25\n",
      "  Mean percentage error: 0.2886\n",
      "  Mean improvement over greedy: -0.2752\n",
      "Run 3 test metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 67.91%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3853\n",
      "  Mean improvement over greedy: -0.3655\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -21.48235294117647\n",
      "Run 4 training metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 63.58%\n",
      "  #opt: 8/25\n",
      "  Mean percentage error: 0.2640\n",
      "  Mean improvement over greedy: -0.2425\n",
      "Run 4 test metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 53.59%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3085\n",
      "  Mean improvement over greedy: -0.2891\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -46.80487804878049\n",
      "Run 5 training metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 70.41%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2740\n",
      "  Mean improvement over greedy: -0.2522\n",
      "Run 5 test metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 56.63%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3822\n",
      "  Mean improvement over greedy: -0.3445\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -32.8125\n",
      "Run 6 training metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 68.11%\n",
      "  #opt: 2/25\n",
      "  Mean percentage error: 0.2630\n",
      "  Mean improvement over greedy: -0.2477\n",
      "Run 6 test metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 46.07%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4615\n",
      "  Mean improvement over greedy: -0.4523\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -20.75\n",
      "Run 7 training metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 66.68%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2565\n",
      "  Mean improvement over greedy: -0.2447\n",
      "Run 7 test metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 34.69%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4696\n",
      "  Mean improvement over greedy: -0.4566\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -37.72727272727273\n",
      "Run 8 training metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 62.46%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2880\n",
      "  Mean improvement over greedy: -0.2698\n",
      "Run 8 test metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 65.39%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3459\n",
      "  Mean improvement over greedy: -0.3264\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -23.0\n",
      "Run 9 training metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 74.65%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2233\n",
      "  Mean improvement over greedy: -0.2074\n",
      "Run 9 test metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 50.85%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4720\n",
      "  Mean improvement over greedy: -0.4612\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -33.53333333333333\n",
      "Run 10 training metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 79.34%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.1781\n",
      "  Mean improvement over greedy: -0.1674\n",
      "Run 10 test metrics for PPO with (+v_i -w_i):\n",
      "  Val/Opt Ratio: 49.09%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4652\n",
      "  Mean improvement over greedy: -0.4388\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for PPO with (+v_i -w_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 69.82% ± 5.85%\n",
      "  #opt: 5.00 ± 1.84\n",
      "  Mean percentage error: 0.2443 ± 0.0440\n",
      "  Mean improvement over greedy: -0.2270 ± 0.0436\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 54.44% ± 9.48%\n",
      "  #opt: 0.90 ± 0.54\n",
      "  Mean percentage error: 0.3856 ± 0.0745\n",
      "  Mean improvement over greedy: -0.3663 ± 0.0767\n",
      "\n",
      "Experiment 20/27: Testing PPO with (+v_i -wr_i)\n",
      "Positive reward: v_i, Negative reward: wr_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 28.385665529010236\n",
      "Run 1 training metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 65.88%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2673\n",
      "  Mean improvement over greedy: -0.2425\n",
      "Run 1 test metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 53.92%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3828\n",
      "  Mean improvement over greedy: -0.3463\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 15.280985915492957\n",
      "Run 2 training metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 78.99%\n",
      "  #opt: 8/25\n",
      "  Mean percentage error: 0.1605\n",
      "  Mean improvement over greedy: -0.1405\n",
      "Run 2 test metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 46.06%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.3171\n",
      "  Mean improvement over greedy: -0.3171\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 9.104419191919192\n",
      "Run 3 training metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 65.56%\n",
      "  #opt: 0/25\n",
      "  Mean percentage error: 0.3233\n",
      "  Mean improvement over greedy: -0.3100\n",
      "Run 3 test metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 75.52%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3554\n",
      "  Mean improvement over greedy: -0.3356\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -3.3430367955286444\n",
      "Run 4 training metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 61.04%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2877\n",
      "  Mean improvement over greedy: -0.2661\n",
      "Run 4 test metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 55.66%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3803\n",
      "  Mean improvement over greedy: -0.3609\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -2.0093378607809846\n",
      "Run 5 training metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 65.04%\n",
      "  #opt: 2/25\n",
      "  Mean percentage error: 0.3296\n",
      "  Mean improvement over greedy: -0.3078\n",
      "Run 5 test metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 58.41%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4371\n",
      "  Mean improvement over greedy: -0.3994\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -20.601352913968547\n",
      "Run 6 training metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 66.62%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2475\n",
      "  Mean improvement over greedy: -0.2323\n",
      "Run 6 test metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 43.59%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5714\n",
      "  Mean improvement over greedy: -0.5622\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 19.09158415841584\n",
      "Run 7 training metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 67.15%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2559\n",
      "  Mean improvement over greedy: -0.2442\n",
      "Run 7 test metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 67.50%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2144\n",
      "  Mean improvement over greedy: -0.2014\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.7880022321428573\n",
      "Run 8 training metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 63.80%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2987\n",
      "  Mean improvement over greedy: -0.2805\n",
      "Run 8 test metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 58.59%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4176\n",
      "  Mean improvement over greedy: -0.3981\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -18.76971677559913\n",
      "Run 9 training metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 74.36%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2179\n",
      "  Mean improvement over greedy: -0.2021\n",
      "Run 9 test metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 49.49%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4472\n",
      "  Mean improvement over greedy: -0.4364\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -2.9339991846718307\n",
      "Run 10 training metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 76.35%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.1961\n",
      "  Mean improvement over greedy: -0.1854\n",
      "Run 10 test metrics for PPO with (+v_i -wr_i):\n",
      "  Val/Opt Ratio: 43.57%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4971\n",
      "  Mean improvement over greedy: -0.4707\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for PPO with (+v_i -wr_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 68.48% ± 5.63%\n",
      "  #opt: 4.40 ± 2.06\n",
      "  Mean percentage error: 0.2585 ± 0.0520\n",
      "  Mean improvement over greedy: -0.2411 ± 0.0512\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 55.23% ± 9.87%\n",
      "  #opt: 0.70 ± 0.78\n",
      "  Mean percentage error: 0.4020 ± 0.0931\n",
      "  Mean improvement over greedy: -0.3828 ± 0.0920\n",
      "\n",
      "Experiment 21/27: Testing PPO with (+v_i -_1)\n",
      "Positive reward: v_i, Negative reward: _1\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -134.72727272727272\n",
      "Run 1 training metrics for PPO with (+v_i -_1):\n",
      "  Val/Opt Ratio: 67.55%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2462\n",
      "  Mean improvement over greedy: -0.2214\n",
      "Run 1 test metrics for PPO with (+v_i -_1):\n",
      "  Val/Opt Ratio: 61.66%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2481\n",
      "  Mean improvement over greedy: -0.2115\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -2.409937888198758\n",
      "Run 2 training metrics for PPO with (+v_i -_1):\n",
      "  Val/Opt Ratio: 77.25%\n",
      "  #opt: 10/25\n",
      "  Mean percentage error: 0.1588\n",
      "  Mean improvement over greedy: -0.1388\n",
      "Run 2 test metrics for PPO with (+v_i -_1):\n",
      "  Val/Opt Ratio: 56.82%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2629\n",
      "  Mean improvement over greedy: -0.2629\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.0851063829787234\n",
      "Run 3 training metrics for PPO with (+v_i -_1):\n",
      "  Val/Opt Ratio: 65.47%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.3019\n",
      "  Mean improvement over greedy: -0.2886\n",
      "Run 3 test metrics for PPO with (+v_i -_1):\n",
      "  Val/Opt Ratio: 56.80%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4742\n",
      "  Mean improvement over greedy: -0.4544\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 2.2127659574468086\n",
      "Run 4 training metrics for PPO with (+v_i -_1):\n",
      "  Val/Opt Ratio: 65.26%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2549\n",
      "  Mean improvement over greedy: -0.2334\n",
      "Run 4 test metrics for PPO with (+v_i -_1):\n",
      "  Val/Opt Ratio: 62.88%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3566\n",
      "  Mean improvement over greedy: -0.3372\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -1.9542483660130718\n",
      "Run 5 training metrics for PPO with (+v_i -_1):\n",
      "  Val/Opt Ratio: 65.82%\n",
      "  #opt: 2/25\n",
      "  Mean percentage error: 0.3128\n",
      "  Mean improvement over greedy: -0.2909\n",
      "Run 5 test metrics for PPO with (+v_i -_1):\n",
      "  Val/Opt Ratio: 53.54%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4830\n",
      "  Mean improvement over greedy: -0.4453\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -11.701357466063348\n",
      "Run 6 training metrics for PPO with (+v_i -_1):\n",
      "  Val/Opt Ratio: 65.49%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2515\n",
      "  Mean improvement over greedy: -0.2362\n",
      "Run 6 test metrics for PPO with (+v_i -_1):\n",
      "  Val/Opt Ratio: 37.64%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5919\n",
      "  Mean improvement over greedy: -0.5827\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: 15.25\n",
      "Run 7 training metrics for PPO with (+v_i -_1):\n",
      "  Val/Opt Ratio: 67.70%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2446\n",
      "  Mean improvement over greedy: -0.2328\n",
      "Run 7 test metrics for PPO with (+v_i -_1):\n",
      "  Val/Opt Ratio: 62.60%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2881\n",
      "  Mean improvement over greedy: -0.2751\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -3.3933333333333335\n",
      "Run 8 training metrics for PPO with (+v_i -_1):\n",
      "  Val/Opt Ratio: 68.01%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2578\n",
      "  Mean improvement over greedy: -0.2396\n",
      "Run 8 test metrics for PPO with (+v_i -_1):\n",
      "  Val/Opt Ratio: 75.47%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2649\n",
      "  Mean improvement over greedy: -0.2454\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -22.583333333333332\n",
      "Run 9 training metrics for PPO with (+v_i -_1):\n",
      "  Val/Opt Ratio: 71.64%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2385\n",
      "  Mean improvement over greedy: -0.2227\n",
      "Run 9 test metrics for PPO with (+v_i -_1):\n",
      "  Val/Opt Ratio: 50.17%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4615\n",
      "  Mean improvement over greedy: -0.4507\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -2.554054054054054\n",
      "Run 10 training metrics for PPO with (+v_i -_1):\n",
      "  Val/Opt Ratio: 76.99%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2007\n",
      "  Mean improvement over greedy: -0.1901\n",
      "Run 10 test metrics for PPO with (+v_i -_1):\n",
      "  Val/Opt Ratio: 59.19%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3117\n",
      "  Mean improvement over greedy: -0.2853\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for PPO with (+v_i -_1):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 69.12% ± 4.39%\n",
      "  #opt: 5.20 ± 2.04\n",
      "  Mean percentage error: 0.2468 ± 0.0419\n",
      "  Mean improvement over greedy: -0.2294 ± 0.0416\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 57.68% ± 9.29%\n",
      "  #opt: 0.60 ± 0.66\n",
      "  Mean percentage error: 0.3743 ± 0.1135\n",
      "  Mean improvement over greedy: -0.3550 ± 0.1148\n",
      "\n",
      "Experiment 22/27: Testing PPO with (+vr_i -w_i)\n",
      "Positive reward: vr_i, Negative reward: w_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -149.9998634422968\n",
      "Run 1 training metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 67.06%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2604\n",
      "  Mean improvement over greedy: -0.2356\n",
      "Run 1 test metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 61.16%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2970\n",
      "  Mean improvement over greedy: -0.2605\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -47.99161193634179\n",
      "Run 2 training metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 73.56%\n",
      "  #opt: 7/25\n",
      "  Mean percentage error: 0.2091\n",
      "  Mean improvement over greedy: -0.1890\n",
      "Run 2 test metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 65.81%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2197\n",
      "  Mean improvement over greedy: -0.2197\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -32.59682912455344\n",
      "Run 3 training metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 68.53%\n",
      "  #opt: 2/25\n",
      "  Mean percentage error: 0.2827\n",
      "  Mean improvement over greedy: -0.2693\n",
      "Run 3 test metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 64.11%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4422\n",
      "  Mean improvement over greedy: -0.4223\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -49.62132604237867\n",
      "Run 4 training metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 64.70%\n",
      "  #opt: 8/25\n",
      "  Mean percentage error: 0.2471\n",
      "  Mean improvement over greedy: -0.2256\n",
      "Run 4 test metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 49.42%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3904\n",
      "  Mean improvement over greedy: -0.3710\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -50.2216482394026\n",
      "Run 5 training metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 70.12%\n",
      "  #opt: 2/25\n",
      "  Mean percentage error: 0.2852\n",
      "  Mean improvement over greedy: -0.2634\n",
      "Run 5 test metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 56.75%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4068\n",
      "  Mean improvement over greedy: -0.3691\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -45.43563092251951\n",
      "Run 6 training metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 68.36%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2396\n",
      "  Mean improvement over greedy: -0.2243\n",
      "Run 6 test metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 35.64%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.6182\n",
      "  Mean improvement over greedy: -0.6090\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -58.42168552251\n",
      "Run 7 training metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 66.84%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2479\n",
      "  Mean improvement over greedy: -0.2361\n",
      "Run 7 test metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 40.27%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4705\n",
      "  Mean improvement over greedy: -0.4575\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -49.61881027268862\n",
      "Run 8 training metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 68.85%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.2495\n",
      "  Mean improvement over greedy: -0.2314\n",
      "Run 8 test metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 68.91%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3225\n",
      "  Mean improvement over greedy: -0.3030\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -9.007124149540344\n",
      "Run 9 training metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 73.42%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2234\n",
      "  Mean improvement over greedy: -0.2076\n",
      "Run 9 test metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 52.13%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4705\n",
      "  Mean improvement over greedy: -0.4597\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -44.36419807215922\n",
      "Run 10 training metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 79.09%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.1775\n",
      "  Mean improvement over greedy: -0.1669\n",
      "Run 10 test metrics for PPO with (+vr_i -w_i):\n",
      "  Val/Opt Ratio: 43.89%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4883\n",
      "  Mean improvement over greedy: -0.4619\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for PPO with (+vr_i -w_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 70.05% ± 4.00%\n",
      "  #opt: 5.10 ± 1.97\n",
      "  Mean percentage error: 0.2422 ± 0.0309\n",
      "  Mean improvement over greedy: -0.2249 ± 0.0295\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 53.81% ± 10.84%\n",
      "  #opt: 0.60 ± 0.66\n",
      "  Mean percentage error: 0.4126 ± 0.1071\n",
      "  Mean improvement over greedy: -0.3934 ± 0.1085\n",
      "\n",
      "Experiment 23/27: Testing PPO with (+vr_i -wr_i)\n",
      "Positive reward: vr_i, Negative reward: wr_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -0.04680122243024061\n",
      "Run 1 training metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 67.43%\n",
      "  #opt: 7/25\n",
      "  Mean percentage error: 0.2430\n",
      "  Mean improvement over greedy: -0.2182\n",
      "Run 1 test metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 70.83%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2529\n",
      "  Mean improvement over greedy: -0.2163\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -2.402657843481045\n",
      "Run 2 training metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 72.22%\n",
      "  #opt: 8/25\n",
      "  Mean percentage error: 0.2005\n",
      "  Mean improvement over greedy: -0.1805\n",
      "Run 2 test metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 44.09%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.3341\n",
      "  Mean improvement over greedy: -0.3341\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -3.578337278140866\n",
      "Run 3 training metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 68.80%\n",
      "  #opt: 2/25\n",
      "  Mean percentage error: 0.2858\n",
      "  Mean improvement over greedy: -0.2724\n",
      "Run 3 test metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 69.52%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3900\n",
      "  Mean improvement over greedy: -0.3701\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -2.6565288654161354\n",
      "Run 4 training metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 65.86%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2439\n",
      "  Mean improvement over greedy: -0.2224\n",
      "Run 4 test metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 60.69%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3091\n",
      "  Mean improvement over greedy: -0.2898\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -5.35342891278375\n",
      "Run 5 training metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 67.55%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.3027\n",
      "  Mean improvement over greedy: -0.2808\n",
      "Run 5 test metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 58.41%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3419\n",
      "  Mean improvement over greedy: -0.3042\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -6.856195828993222\n",
      "Run 6 training metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 66.50%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2538\n",
      "  Mean improvement over greedy: -0.2386\n",
      "Run 6 test metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 59.76%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3120\n",
      "  Mean improvement over greedy: -0.3028\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -47.2804183656517\n",
      "Run 7 training metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 66.64%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2607\n",
      "  Mean improvement over greedy: -0.2489\n",
      "Run 7 test metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 42.88%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4679\n",
      "  Mean improvement over greedy: -0.4549\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -1.486036072323666\n",
      "Run 8 training metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 64.18%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.2806\n",
      "  Mean improvement over greedy: -0.2624\n",
      "Run 8 test metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 63.39%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3759\n",
      "  Mean improvement over greedy: -0.3564\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -18.667914574113667\n",
      "Run 9 training metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 73.51%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.2254\n",
      "  Mean improvement over greedy: -0.2096\n",
      "Run 9 test metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 52.88%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4443\n",
      "  Mean improvement over greedy: -0.4335\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -2.531542505165621\n",
      "Run 10 training metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 79.11%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.1759\n",
      "  Mean improvement over greedy: -0.1652\n",
      "Run 10 test metrics for PPO with (+vr_i -wr_i):\n",
      "  Val/Opt Ratio: 55.98%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3779\n",
      "  Mean improvement over greedy: -0.3515\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for PPO with (+vr_i -wr_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 69.18% ± 4.27%\n",
      "  #opt: 4.60 ± 1.85\n",
      "  Mean percentage error: 0.2472 ± 0.0370\n",
      "  Mean improvement over greedy: -0.2299 ± 0.0362\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 57.84% ± 8.88%\n",
      "  #opt: 0.80 ± 0.60\n",
      "  Mean percentage error: 0.3606 ± 0.0613\n",
      "  Mean improvement over greedy: -0.3414 ± 0.0661\n",
      "\n",
      "Experiment 24/27: Testing PPO with (+vr_i -_1)\n",
      "Positive reward: vr_i, Negative reward: _1\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -99.43174524759033\n",
      "Run 1 training metrics for PPO with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 63.76%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2861\n",
      "  Mean improvement over greedy: -0.2613\n",
      "Run 1 test metrics for PPO with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 54.09%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3730\n",
      "  Mean improvement over greedy: -0.3364\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -3.7658297119724775\n",
      "Run 2 training metrics for PPO with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 72.84%\n",
      "  #opt: 9/25\n",
      "  Mean percentage error: 0.1965\n",
      "  Mean improvement over greedy: -0.1765\n",
      "Run 2 test metrics for PPO with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 47.44%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.3263\n",
      "  Mean improvement over greedy: -0.3263\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -3.820386571268286\n",
      "Run 3 training metrics for PPO with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 73.27%\n",
      "  #opt: 2/25\n",
      "  Mean percentage error: 0.2366\n",
      "  Mean improvement over greedy: -0.2232\n",
      "Run 3 test metrics for PPO with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 55.73%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4844\n",
      "  Mean improvement over greedy: -0.4646\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -1.2128145599107487\n",
      "Run 4 training metrics for PPO with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 62.10%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2775\n",
      "  Mean improvement over greedy: -0.2560\n",
      "Run 4 test metrics for PPO with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 56.26%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3419\n",
      "  Mean improvement over greedy: -0.3225\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -5.059254244826414\n",
      "Run 5 training metrics for PPO with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 65.68%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.3188\n",
      "  Mean improvement over greedy: -0.2969\n",
      "Run 5 test metrics for PPO with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 59.84%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3556\n",
      "  Mean improvement over greedy: -0.3179\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -12.118297033215972\n",
      "Run 6 training metrics for PPO with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 65.33%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2623\n",
      "  Mean improvement over greedy: -0.2470\n",
      "Run 6 test metrics for PPO with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 48.07%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5276\n",
      "  Mean improvement over greedy: -0.5184\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -38.79005731218283\n",
      "Run 7 training metrics for PPO with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 66.82%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2549\n",
      "  Mean improvement over greedy: -0.2431\n",
      "Run 7 test metrics for PPO with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 49.35%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3677\n",
      "  Mean improvement over greedy: -0.3547\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -9.075654728623348\n",
      "Run 8 training metrics for PPO with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 68.14%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2483\n",
      "  Mean improvement over greedy: -0.2301\n",
      "Run 8 test metrics for PPO with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 72.74%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.2782\n",
      "  Mean improvement over greedy: -0.2586\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -44.50605826234603\n",
      "Run 9 training metrics for PPO with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 72.37%\n",
      "  #opt: 2/25\n",
      "  Mean percentage error: 0.2540\n",
      "  Mean improvement over greedy: -0.2382\n",
      "Run 9 test metrics for PPO with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 47.70%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4904\n",
      "  Mean improvement over greedy: -0.4796\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -11.951081493603295\n",
      "Run 10 training metrics for PPO with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 80.90%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.1689\n",
      "  Mean improvement over greedy: -0.1582\n",
      "Run 10 test metrics for PPO with (+vr_i -_1):\n",
      "  Val/Opt Ratio: 45.15%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4442\n",
      "  Mean improvement over greedy: -0.4178\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for PPO with (+vr_i -_1):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 69.12% ± 5.39%\n",
      "  #opt: 4.60 ± 1.96\n",
      "  Mean percentage error: 0.2504 ± 0.0407\n",
      "  Mean improvement over greedy: -0.2330 ± 0.0383\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 53.64% ± 7.81%\n",
      "  #opt: 0.70 ± 0.64\n",
      "  Mean percentage error: 0.3989 ± 0.0781\n",
      "  Mean improvement over greedy: -0.3797 ± 0.0806\n",
      "\n",
      "Experiment 25/27: Testing PPO with (+_1 -w_i)\n",
      "Positive reward: _1, Negative reward: w_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -137.0359712230216\n",
      "Run 1 training metrics for PPO with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 66.39%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2816\n",
      "  Mean improvement over greedy: -0.2568\n",
      "Run 1 test metrics for PPO with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 65.64%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2700\n",
      "  Mean improvement over greedy: -0.2335\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -15.089430894308943\n",
      "Run 2 training metrics for PPO with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 82.20%\n",
      "  #opt: 9/25\n",
      "  Mean percentage error: 0.1213\n",
      "  Mean improvement over greedy: -0.1012\n",
      "Run 2 test metrics for PPO with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 51.65%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2892\n",
      "  Mean improvement over greedy: -0.2892\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -10.33993399339934\n",
      "Run 3 training metrics for PPO with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 70.93%\n",
      "  #opt: 1/25\n",
      "  Mean percentage error: 0.2708\n",
      "  Mean improvement over greedy: -0.2575\n",
      "Run 3 test metrics for PPO with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 70.83%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2435\n",
      "  Mean improvement over greedy: -0.2237\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -11.492537313432836\n",
      "Run 4 training metrics for PPO with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 67.51%\n",
      "  #opt: 8/25\n",
      "  Mean percentage error: 0.2417\n",
      "  Mean improvement over greedy: -0.2202\n",
      "Run 4 test metrics for PPO with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 44.43%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5135\n",
      "  Mean improvement over greedy: -0.4942\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -14.831395348837209\n",
      "Run 5 training metrics for PPO with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 63.82%\n",
      "  #opt: 2/25\n",
      "  Mean percentage error: 0.3297\n",
      "  Mean improvement over greedy: -0.3078\n",
      "Run 5 test metrics for PPO with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 69.85%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2641\n",
      "  Mean improvement over greedy: -0.2264\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -22.617283950617285\n",
      "Run 6 training metrics for PPO with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 67.16%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2376\n",
      "  Mean improvement over greedy: -0.2223\n",
      "Run 6 test metrics for PPO with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 52.54%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4543\n",
      "  Mean improvement over greedy: -0.4451\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -13.540816326530612\n",
      "Run 7 training metrics for PPO with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 65.32%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2586\n",
      "  Mean improvement over greedy: -0.2469\n",
      "Run 7 test metrics for PPO with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 56.44%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3677\n",
      "  Mean improvement over greedy: -0.3547\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -27.142857142857142\n",
      "Run 8 training metrics for PPO with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 64.80%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2741\n",
      "  Mean improvement over greedy: -0.2559\n",
      "Run 8 test metrics for PPO with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 75.17%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2704\n",
      "  Mean improvement over greedy: -0.2508\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -36.227053140096615\n",
      "Run 9 training metrics for PPO with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 70.23%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2440\n",
      "  Mean improvement over greedy: -0.2281\n",
      "Run 9 test metrics for PPO with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 47.66%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5154\n",
      "  Mean improvement over greedy: -0.5046\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -10.654804270462634\n",
      "Run 10 training metrics for PPO with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 78.98%\n",
      "  #opt: 7/25\n",
      "  Mean percentage error: 0.1920\n",
      "  Mean improvement over greedy: -0.1814\n",
      "Run 10 test metrics for PPO with (+_1 -w_i):\n",
      "  Val/Opt Ratio: 57.84%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3520\n",
      "  Mean improvement over greedy: -0.3256\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for PPO with (+_1 -w_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 69.73% ± 5.87%\n",
      "  #opt: 5.10 ± 2.34\n",
      "  Mean percentage error: 0.2451 ± 0.0533\n",
      "  Mean improvement over greedy: -0.2278 ± 0.0525\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 59.20% ± 10.03%\n",
      "  #opt: 0.80 ± 0.60\n",
      "  Mean percentage error: 0.3540 ± 0.1001\n",
      "  Mean improvement over greedy: -0.3348 ± 0.1051\n",
      "\n",
      "Experiment 26/27: Testing PPO with (+_1 -wr_i)\n",
      "Positive reward: _1, Negative reward: wr_i\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -105.50631545170793\n",
      "Run 1 training metrics for PPO with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 68.55%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2464\n",
      "  Mean improvement over greedy: -0.2216\n",
      "Run 1 test metrics for PPO with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 57.02%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3244\n",
      "  Mean improvement over greedy: -0.2878\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -4.606238658947549\n",
      "Run 2 training metrics for PPO with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 78.59%\n",
      "  #opt: 7/25\n",
      "  Mean percentage error: 0.1627\n",
      "  Mean improvement over greedy: -0.1426\n",
      "Run 2 test metrics for PPO with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 45.95%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.3476\n",
      "  Mean improvement over greedy: -0.3476\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -5.592750783699058\n",
      "Run 3 training metrics for PPO with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 64.66%\n",
      "  #opt: 0/25\n",
      "  Mean percentage error: 0.3199\n",
      "  Mean improvement over greedy: -0.3065\n",
      "Run 3 test metrics for PPO with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 64.05%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3277\n",
      "  Mean improvement over greedy: -0.3078\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -6.748927875243666\n",
      "Run 4 training metrics for PPO with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 65.25%\n",
      "  #opt: 7/25\n",
      "  Mean percentage error: 0.2518\n",
      "  Mean improvement over greedy: -0.2303\n",
      "Run 4 test metrics for PPO with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 51.35%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4391\n",
      "  Mean improvement over greedy: -0.4197\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -1.7672620634497462\n",
      "Run 5 training metrics for PPO with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 72.63%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.2594\n",
      "  Mean improvement over greedy: -0.2375\n",
      "Run 5 test metrics for PPO with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 53.96%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4483\n",
      "  Mean improvement over greedy: -0.4106\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -8.712721984078383\n",
      "Run 6 training metrics for PPO with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 70.95%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2113\n",
      "  Mean improvement over greedy: -0.1961\n",
      "Run 6 test metrics for PPO with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 44.50%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5581\n",
      "  Mean improvement over greedy: -0.5489\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -35.343742066514345\n",
      "Run 7 training metrics for PPO with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 69.82%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2400\n",
      "  Mean improvement over greedy: -0.2283\n",
      "Run 7 test metrics for PPO with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 35.99%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.5012\n",
      "  Mean improvement over greedy: -0.4882\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -1.911955691367456\n",
      "Run 8 training metrics for PPO with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 67.03%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2567\n",
      "  Mean improvement over greedy: -0.2385\n",
      "Run 8 test metrics for PPO with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 70.31%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.2943\n",
      "  Mean improvement over greedy: -0.2748\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -25.119569015725098\n",
      "Run 9 training metrics for PPO with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 74.66%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2091\n",
      "  Mean improvement over greedy: -0.1933\n",
      "Run 9 test metrics for PPO with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 49.66%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4906\n",
      "  Mean improvement over greedy: -0.4798\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -2.395096418732782\n",
      "Run 10 training metrics for PPO with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 76.30%\n",
      "  #opt: 3/25\n",
      "  Mean percentage error: 0.2035\n",
      "  Mean improvement over greedy: -0.1928\n",
      "Run 10 test metrics for PPO with (+_1 -wr_i):\n",
      "  Val/Opt Ratio: 29.76%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.6095\n",
      "  Mean improvement over greedy: -0.5831\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for PPO with (+_1 -wr_i):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 70.84% ± 4.45%\n",
      "  #opt: 4.40 ± 2.01\n",
      "  Mean percentage error: 0.2361 ± 0.0402\n",
      "  Mean improvement over greedy: -0.2187 ± 0.0404\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 50.26% ± 11.53%\n",
      "  #opt: 0.60 ± 0.66\n",
      "  Mean percentage error: 0.4341 ± 0.1022\n",
      "  Mean improvement over greedy: -0.4148 ± 0.1038\n",
      "\n",
      "Experiment 27/27: Testing PPO with (+_1 -_1)\n",
      "Positive reward: _1, Negative reward: _1\n",
      "Running 10 times and averaging results...\n",
      "\n",
      "Run 1/10 (seed=42):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -87.53731343283582\n",
      "Run 1 training metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 68.40%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.2440\n",
      "  Mean improvement over greedy: -0.2192\n",
      "Run 1 test metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 48.07%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4395\n",
      "  Mean improvement over greedy: -0.4030\n",
      "\n",
      "Run 2/10 (seed=1042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -1.452991452991453\n",
      "Run 2 training metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 76.54%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.1892\n",
      "  Mean improvement over greedy: -0.1691\n",
      "Run 2 test metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 55.43%\n",
      "  #opt: 2/5\n",
      "  Mean percentage error: 0.2891\n",
      "  Mean improvement over greedy: -0.2891\n",
      "\n",
      "Run 3/10 (seed=2042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -44.285714285714285\n",
      "Run 3 training metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 66.82%\n",
      "  #opt: 1/25\n",
      "  Mean percentage error: 0.2826\n",
      "  Mean improvement over greedy: -0.2693\n",
      "Run 3 test metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 70.89%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3801\n",
      "  Mean improvement over greedy: -0.3602\n",
      "\n",
      "Run 4/10 (seed=3042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -5.6473988439306355\n",
      "Run 4 training metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 65.57%\n",
      "  #opt: 7/25\n",
      "  Mean percentage error: 0.2636\n",
      "  Mean improvement over greedy: -0.2421\n",
      "Run 4 test metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 59.27%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.2781\n",
      "  Mean improvement over greedy: -0.2587\n",
      "\n",
      "Run 5/10 (seed=4042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -2.012987012987013\n",
      "Run 5 training metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 66.46%\n",
      "  #opt: 5/25\n",
      "  Mean percentage error: 0.3020\n",
      "  Mean improvement over greedy: -0.2802\n",
      "Run 5 test metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 64.71%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.3690\n",
      "  Mean improvement over greedy: -0.3313\n",
      "\n",
      "Run 6/10 (seed=5042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -15.043103448275861\n",
      "Run 6 training metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 69.34%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.2259\n",
      "  Mean improvement over greedy: -0.2106\n",
      "Run 6 test metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 39.46%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.5820\n",
      "  Mean improvement over greedy: -0.5728\n",
      "\n",
      "Run 7/10 (seed=6042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -15.836538461538462\n",
      "Run 7 training metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 69.44%\n",
      "  #opt: 7/25\n",
      "  Mean percentage error: 0.2277\n",
      "  Mean improvement over greedy: -0.2159\n",
      "Run 7 test metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 48.30%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.4019\n",
      "  Mean improvement over greedy: -0.3889\n",
      "\n",
      "Run 8/10 (seed=7042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -17.502463054187192\n",
      "Run 8 training metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 68.21%\n",
      "  #opt: 4/25\n",
      "  Mean percentage error: 0.2537\n",
      "  Mean improvement over greedy: -0.2355\n",
      "Run 8 test metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 64.36%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3259\n",
      "  Mean improvement over greedy: -0.3064\n",
      "\n",
      "Run 9/10 (seed=8042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -12.114754098360656\n",
      "Run 9 training metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 69.93%\n",
      "  #opt: 2/25\n",
      "  Mean percentage error: 0.2789\n",
      "  Mean improvement over greedy: -0.2631\n",
      "Run 9 test metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 56.43%\n",
      "  #opt: 0/5\n",
      "  Mean percentage error: 0.4174\n",
      "  Mean improvement over greedy: -0.4066\n",
      "\n",
      "Run 10/10 (seed=9042):\n",
      "Computing DP optimal solutions for training instances...\n",
      "Computing Greedy solutions for training instances...\n",
      "Computing DP optimal solutions for test instances...\n",
      "Computing Greedy solutions for test instances...\n",
      "Running Model <class 'models.KnapsackPPO.KnapsackPPOSolver'>\n",
      "Training on 25 KP Instances, with N=50, t_max=100\n",
      "Iteration [0/100], Training KP Instance 0, Reward: -10.440993788819876\n",
      "Run 10 training metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 81.35%\n",
      "  #opt: 6/25\n",
      "  Mean percentage error: 0.1616\n",
      "  Mean improvement over greedy: -0.1509\n",
      "Run 10 test metrics for PPO with (+_1 -_1):\n",
      "  Val/Opt Ratio: 53.53%\n",
      "  #opt: 1/5\n",
      "  Mean percentage error: 0.3687\n",
      "  Mean improvement over greedy: -0.3423\n",
      "\n",
      "AVERAGED RESULTS (10 runs) for PPO with (+_1 -_1):\n",
      "Training metrics:\n",
      "  Val/Opt Ratio: 70.21% ± 4.69%\n",
      "  #opt: 4.90 ± 1.92\n",
      "  Mean percentage error: 0.2429 ± 0.0412\n",
      "  Mean improvement over greedy: -0.2256 ± 0.0397\n",
      "Test metrics:\n",
      "  Val/Opt Ratio: 56.04% ± 8.83%\n",
      "  #opt: 0.70 ± 0.64\n",
      "  Mean percentage error: 0.3852 ± 0.0823\n",
      "  Mean improvement over greedy: -0.3659 ± 0.0831\n",
      "\n",
      "Summary of Results:\n",
      "   Model Reward Function Train Val/Opt (%)   Train #opt        Train MPE  \\\n",
      "0    A2C     (+v_i -w_i)      64.40 ± 4.72  4.50 ± 1.86  0.2843 ± 0.0449   \n",
      "1    A2C    (+v_i -wr_i)      69.71 ± 4.67  4.90 ± 2.21  0.2409 ± 0.0442   \n",
      "2    A2C      (+v_i -_1)      69.64 ± 4.05  4.20 ± 2.04  0.2500 ± 0.0297   \n",
      "3    A2C    (+vr_i -w_i)      69.18 ± 5.56  4.90 ± 1.97  0.2548 ± 0.0476   \n",
      "4    A2C   (+vr_i -wr_i)      68.98 ± 5.35  4.80 ± 1.33  0.2506 ± 0.0392   \n",
      "5    A2C     (+vr_i -_1)      69.45 ± 5.60  4.80 ± 2.79  0.2443 ± 0.0459   \n",
      "6    A2C      (+_1 -w_i)      67.87 ± 5.18  4.70 ± 1.73  0.2582 ± 0.0434   \n",
      "7    A2C     (+_1 -wr_i)      68.24 ± 5.49  4.70 ± 2.33  0.2589 ± 0.0479   \n",
      "8    A2C       (+_1 -_1)      67.82 ± 4.02  4.20 ± 2.04  0.2639 ± 0.0289   \n",
      "9    DQN     (+v_i -w_i)      69.31 ± 4.46  4.20 ± 1.66  0.2462 ± 0.0352   \n",
      "10   DQN    (+v_i -wr_i)      70.65 ± 5.29  4.40 ± 1.69  0.2395 ± 0.0421   \n",
      "11   DQN      (+v_i -_1)      67.95 ± 4.08  5.20 ± 2.71  0.2569 ± 0.0432   \n",
      "12   DQN    (+vr_i -w_i)      68.09 ± 4.88  4.60 ± 2.01  0.2568 ± 0.0434   \n",
      "13   DQN   (+vr_i -wr_i)      69.88 ± 3.65  4.80 ± 2.18  0.2493 ± 0.0345   \n",
      "14   DQN     (+vr_i -_1)      67.67 ± 3.98  4.20 ± 1.78  0.2686 ± 0.0453   \n",
      "15   DQN      (+_1 -w_i)      66.09 ± 6.02  4.70 ± 2.61  0.2740 ± 0.0473   \n",
      "16   DQN     (+_1 -wr_i)      64.68 ± 4.65  3.80 ± 2.09  0.3027 ± 0.0474   \n",
      "17   DQN       (+_1 -_1)      62.13 ± 3.55  3.80 ± 1.94  0.3318 ± 0.0356   \n",
      "18   PPO     (+v_i -w_i)      69.82 ± 5.85  5.00 ± 1.84  0.2443 ± 0.0440   \n",
      "19   PPO    (+v_i -wr_i)      68.48 ± 5.63  4.40 ± 2.06  0.2585 ± 0.0520   \n",
      "20   PPO      (+v_i -_1)      69.12 ± 4.39  5.20 ± 2.04  0.2468 ± 0.0419   \n",
      "21   PPO    (+vr_i -w_i)      70.05 ± 4.00  5.10 ± 1.97  0.2422 ± 0.0309   \n",
      "22   PPO   (+vr_i -wr_i)      69.18 ± 4.27  4.60 ± 1.85  0.2472 ± 0.0370   \n",
      "23   PPO     (+vr_i -_1)      69.12 ± 5.39  4.60 ± 1.96  0.2504 ± 0.0407   \n",
      "24   PPO      (+_1 -w_i)      69.73 ± 5.87  5.10 ± 2.34  0.2451 ± 0.0533   \n",
      "25   PPO     (+_1 -wr_i)      70.84 ± 4.45  4.40 ± 2.01  0.2361 ± 0.0402   \n",
      "26   PPO       (+_1 -_1)      70.21 ± 4.69  4.90 ± 1.92  0.2429 ± 0.0412   \n",
      "\n",
      "    Train Imp/Greedy Test Val/Opt (%)    Test #opt         Test MPE  \\\n",
      "0   -0.2670 ± 0.0456     58.91 ± 8.42  0.80 ± 0.60  0.3585 ± 0.1048   \n",
      "1   -0.2236 ± 0.0453    57.71 ± 12.68  0.70 ± 0.64  0.3656 ± 0.1271   \n",
      "2   -0.2326 ± 0.0298    57.09 ± 12.79  0.70 ± 0.64  0.3577 ± 0.0994   \n",
      "3   -0.2375 ± 0.0478     54.10 ± 9.25  1.10 ± 0.54  0.3712 ± 0.0992   \n",
      "4   -0.2333 ± 0.0398    53.77 ± 10.35  0.80 ± 0.75  0.3990 ± 0.1155   \n",
      "5   -0.2269 ± 0.0476     58.69 ± 9.46  0.80 ± 0.60  0.3559 ± 0.0772   \n",
      "6   -0.2409 ± 0.0431    58.15 ± 10.34  0.70 ± 0.64  0.3526 ± 0.1080   \n",
      "7   -0.2416 ± 0.0488     54.65 ± 8.41  0.50 ± 0.67  0.4010 ± 0.0786   \n",
      "8   -0.2466 ± 0.0286    55.46 ± 10.30  0.80 ± 0.87  0.3716 ± 0.1197   \n",
      "9   -0.2289 ± 0.0361     58.16 ± 9.28  0.90 ± 0.54  0.3447 ± 0.0971   \n",
      "10  -0.2222 ± 0.0406    55.10 ± 10.74  0.60 ± 0.66  0.3830 ± 0.0974   \n",
      "11  -0.2396 ± 0.0438    54.29 ± 10.71  0.80 ± 0.60  0.3863 ± 0.0889   \n",
      "12  -0.2395 ± 0.0438     55.45 ± 9.41  0.70 ± 0.64  0.3799 ± 0.0926   \n",
      "13  -0.2319 ± 0.0340    58.92 ± 10.85  0.70 ± 0.64  0.3492 ± 0.1167   \n",
      "14  -0.2513 ± 0.0477    64.08 ± 10.04  0.80 ± 0.60  0.3135 ± 0.0884   \n",
      "15  -0.2567 ± 0.0474    52.19 ± 10.45  0.80 ± 0.60  0.4128 ± 0.1035   \n",
      "16  -0.2854 ± 0.0475     57.18 ± 7.20  0.70 ± 0.64  0.3725 ± 0.0689   \n",
      "17  -0.3145 ± 0.0362     60.09 ± 9.70  0.70 ± 0.64  0.3353 ± 0.0947   \n",
      "18  -0.2270 ± 0.0436     54.44 ± 9.48  0.90 ± 0.54  0.3856 ± 0.0745   \n",
      "19  -0.2411 ± 0.0512     55.23 ± 9.87  0.70 ± 0.78  0.4020 ± 0.0931   \n",
      "20  -0.2294 ± 0.0416     57.68 ± 9.29  0.60 ± 0.66  0.3743 ± 0.1135   \n",
      "21  -0.2249 ± 0.0295    53.81 ± 10.84  0.60 ± 0.66  0.4126 ± 0.1071   \n",
      "22  -0.2299 ± 0.0362     57.84 ± 8.88  0.80 ± 0.60  0.3606 ± 0.0613   \n",
      "23  -0.2330 ± 0.0383     53.64 ± 7.81  0.70 ± 0.64  0.3989 ± 0.0781   \n",
      "24  -0.2278 ± 0.0525    59.20 ± 10.03  0.80 ± 0.60  0.3540 ± 0.1001   \n",
      "25  -0.2187 ± 0.0404    50.26 ± 11.53  0.60 ± 0.66  0.4341 ± 0.1022   \n",
      "26  -0.2256 ± 0.0397     56.04 ± 8.83  0.70 ± 0.64  0.3852 ± 0.0823   \n",
      "\n",
      "     Test Imp/Greedy Training Time (s)  \n",
      "0   -0.3393 ± 0.1052              0.37  \n",
      "1   -0.3463 ± 0.1271              0.35  \n",
      "2   -0.3384 ± 0.1035              0.35  \n",
      "3   -0.3519 ± 0.1010              0.32  \n",
      "4   -0.3798 ± 0.1170              0.34  \n",
      "5   -0.3367 ± 0.0811              0.34  \n",
      "6   -0.3334 ± 0.1055              0.31  \n",
      "7   -0.3818 ± 0.0780              0.34  \n",
      "8   -0.3524 ± 0.1217              0.35  \n",
      "9   -0.3255 ± 0.1009              0.20  \n",
      "10  -0.3638 ± 0.0967              0.22  \n",
      "11  -0.3670 ± 0.0914              0.24  \n",
      "12  -0.3607 ± 0.0911              0.26  \n",
      "13  -0.3299 ± 0.1148              0.28  \n",
      "14  -0.2943 ± 0.0843              0.30  \n",
      "15  -0.3935 ± 0.1054              0.33  \n",
      "16  -0.3532 ± 0.0716              0.34  \n",
      "17  -0.3161 ± 0.0979              0.36  \n",
      "18  -0.3663 ± 0.0767              0.92  \n",
      "19  -0.3828 ± 0.0920              1.40  \n",
      "20  -0.3550 ± 0.1148              1.69  \n",
      "21  -0.3934 ± 0.1085              0.84  \n",
      "22  -0.3414 ± 0.0661              1.81  \n",
      "23  -0.3797 ± 0.0806              1.85  \n",
      "24  -0.3348 ± 0.1051              1.89  \n",
      "25  -0.4148 ± 0.1038              1.87  \n",
      "26  -0.3659 ± 0.0831              1.87  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO integrate the instance generator in this code\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "\n",
    "    N = 50\n",
    "    M = 25\n",
    "    gamma = 0.99\n",
    "    t_max = 100\n",
    "    # t_max = None\n",
    "\n",
    "    env:KnapsackEnv = KnapsackEnv(problem_instance=None, N=N)\n",
    "    gen = KnapsackInstanceGenerator(seed=42)\n",
    "\n",
    "    problem_instances = gen.generate('RI', M=M, N=N, R=100)\n",
    "    print(problem_instances)\n",
    "\n",
    "    KPSolver_A2C = KnapsackA2C(N=N, gamma=gamma, lr_policy=0.001, lr_value=0.001, verbose=False)\n",
    "    KPSolver_PPO = KnapsackPPOSolver(N=N, gamma=gamma, policy_lr=0.001, value_lr=0.001, verbose=False)\n",
    "    KPSolver_DQN = KnapsackDQN(N=N, gamma=gamma, lr=0.001, verbose=False)\n",
    "\n",
    "    # DP_sol_items, DP_value, DP_weight = solve_KP_instances_with_DP(problem_instances)\n",
    "    # Greedy_value_total, Greedy_selected, Greedy_weight_total = solve_problem_instances_greedy(problem_instances)\n",
    "    \n",
    "    \n",
    "    # A2C_Results = run_KPSolver(env=env, KPSolver=KPSolver_A2C, training_problem_instances=problem_instances, t_max=t_max)\n",
    "    # PPO_Results = run_KPSolver(env=env, KPSolver=KPSolver_PPO, training_problem_instances=problem_instances, t_max=t_max)\n",
    "    # DQN_Results = run_KPSolver(env=env, KPSolver=KPSolver_DQN, training_problem_instances=problem_instances, t_max=t_max)\n",
    "\n",
    "\n",
    "    results = test_reward_functions(\n",
    "        KPSolver_A2C=KPSolver_A2C,\n",
    "        KPSolver_PPO=KPSolver_PPO,\n",
    "        KPSolver_DQN=KPSolver_DQN,\n",
    "        M=M,\n",
    "        instance_type=\"RI\",\n",
    "        N=N,\n",
    "        r_range=100,\n",
    "        seed=42,\n",
    "        t_max=t_max,\n",
    "        use_state_aggregation=False,\n",
    "        n_test_instances=5,\n",
    "        verbose=True,\n",
    "        n_runs=10\n",
    "    )\n",
    "    \n",
    "    # Print summary table\n",
    "    print(\"\\nSummary of Results:\")\n",
    "    print(results['summary'])\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_results_with_error_bars(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
